{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666dc1ec",
   "metadata": {},
   "source": [
    "\n",
    "# Offer Engagement Prediction\n",
    "\n",
    "## 1. Business Objective (The \"Why\")\n",
    "In a high-volume e-commerce environment, users are bombarded with offers. Indiscriminate targeting leads to:\n",
    "*   **User Fatigue**: Users ignore notifications or churn.\n",
    "*   **Wasted Budget**: Incentives are given to users who wouldn't convert or aren't interested.\n",
    "*   **Missed Revenue**: High-intent users miss relevant offers buried in noise.\n",
    "\n",
    "**The Goal**: Move from \"Broadcast\" to \"Precision\" targeting. We aim to build an AI model that predicts the **exact probability** (`0.0` to `1.0`) that a specific user will click on a specific offer.\n",
    "\n",
    "## 2. Technical Approach (The \"How\")\n",
    "To solve this, we treat the problem as a **Binary Classification** task (`is_clicked` = 1 vs 0).\n",
    "\n",
    "*   **Session-Awareness**: We don't just look at \"who the user is\" (demographics), but \"what they are doing right now\". We link **Retail** behavior (browsing items) with **Offer** impressions in real-time.\n",
    "*   **Point-in-Time Correctness**: We strictly observe the timeline. We only use information available *before* the offer was shown to prevent data leakage.\n",
    "*   **Gradient Boosting**: We use **LightGBM**, a state-of-the-art algorithm for tabular data, optimized for speed and accuracy on large datasets.\n",
    "\n",
    "## 3. Success Metrics\n",
    "We will evaluate the model not just on accuracy, but on **Business Impact**:\n",
    "*   **Lift at Top 10%**: If we only target the top 10% of users ranked by the model, how many clicks do we capture compared to random guessing?\n",
    "*   **Calibration (Log Loss)**: Are the predicted probabilities real? (e.g., if we predict 20% risk, does it happen 20% of the time?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install dependencies if needed\n",
    "# !pip install lightgbm shap polars\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import log_loss, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration\n",
    "CLEANED_DATA_DIR = \"cleaned_data\"\n",
    "OUTPUT_DIR = \"models/offer_ctr_model\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "SEED = 42\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0175b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data():\n",
    "    print(\"Loading datasets...\")\n",
    "    # Load Users\n",
    "    users = pd.read_parquet(os.path.join(CLEANED_DATA_DIR, 'users_clean.parquet'))\n",
    "    \n",
    "    # Load Retail Events (Context)\n",
    "    # We need this to understand what the user was doing *before* the offer.\n",
    "    retail_events = pd.read_parquet(os.path.join(CLEANED_DATA_DIR, 'retail_events_clean.parquet'))\n",
    "    retail_events = retail_events[['user_id', 'timestamp', 'item_id', 'subdomain']].sort_values('timestamp')\n",
    "    \n",
    "    # Load Offers Events (Target)\n",
    "    offers_events = pd.read_parquet(os.path.join(CLEANED_DATA_DIR, 'offers_events_clean.parquet'))\n",
    "    offers_events = offers_events.sort_values('timestamp')\n",
    "    \n",
    "    print(f\"Users: {len(users):,}\")\n",
    "    print(f\"Retail Events: {len(retail_events):,}\")\n",
    "    print(f\"Offers Events: {len(offers_events):,}\")\n",
    "    \n",
    "    return users, retail_events, offers_events\n",
    "\n",
    "users, retail_events, offers_events = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28409dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_target(df):\n",
    "    print(\"Defining Target Variable...\")\n",
    "    # We define 'Engagement' as an explicit CLICK or CONVERSION.\n",
    "    # Positive (1): 'redirect_to_partner', 'like' (Actual Clicks)\n",
    "    # Negative (0): 'seen', 'offer_shown' (Impressions/Views without click)\n",
    "    \n",
    "    # NOTE: We exclude 'offer_shown' from positive class because it is just an impression.\n",
    "    # We want to predict who will actually CLICK.\n",
    "    \n",
    "    positive_actions = ['redirect_to_partner', 'like']\n",
    "    df['is_clicked'] = df['action_type'].isin(positive_actions).astype(int)\n",
    "    \n",
    "    ctr = df['is_clicked'].mean()\n",
    "    print(f\"Global CTR (Strict Click-Through): {ctr:.2%}\")\n",
    "    return df\n",
    "\n",
    "offers_events = define_target(offers_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba513c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_features(offers, retail, users):\n",
    "    print(\"Building Features...\")\n",
    "    \n",
    "    # 1. Temporal Features\n",
    "    # Note: 'timestamp' is a Timedelta (duration), not a Datetime.\n",
    "    # We extract the hour of the day (0-23) and a cyclic day index (0-6).\n",
    "    offers['hour'] = (offers['timestamp'].dt.seconds // 3600).astype(int)\n",
    "    offers['day_of_week'] = (offers['timestamp'].dt.days % 7).astype(int)\n",
    "    \n",
    "    # 2. Item Features (CRITICAL: The model needs to know WHICH offer is shown)\n",
    "    # Convert item_id to categorical for LightGBM\n",
    "    print(\"  Encoding Offer IDs...\")\n",
    "    offers['item_id'] = offers['item_id'].astype('category')\n",
    "    \n",
    "    # Offer Popularity (Expanding Count)\n",
    "    # How many times has this offer been shown before?\n",
    "    print(\"  Computing Offer Popularity...\")\n",
    "    offers['offer_popularity'] = offers.groupby('item_id')['timestamp'].transform(\n",
    "        lambda x: x.expanding().count()\n",
    "    )\n",
    "    \n",
    "    # 3. Historical CTR (Expanding Mean)\n",
    "    print(\"  Computing Historical CTR...\")\n",
    "    offers['user_hist_ctr'] = offers.groupby('user_id')['is_clicked'].transform(\n",
    "        lambda x: x.shift().expanding().mean()\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # 4. Retail Context (Merge Asof)\n",
    "    print(\"  Merging Retail Context (asof)...\")\n",
    "    retail_sorted = retail.sort_values('timestamp')\n",
    "    offers_sorted = offers.sort_values('timestamp')\n",
    "    \n",
    "    merged = pd.merge_asof(\n",
    "        offers_sorted,\n",
    "        retail_sorted[['user_id', 'timestamp', 'subdomain']],\n",
    "        on='timestamp',\n",
    "        by='user_id',\n",
    "        direction='backward',\n",
    "        suffixes=('', '_retail')\n",
    "    )\n",
    "    \n",
    "    # Feature: How recently did they interact with retail?\n",
    "    merged['seconds_since_retail'] = (merged['timestamp'] - merged['timestamp_retail']).dt.total_seconds()\n",
    "    merged['seconds_since_retail'] = merged['seconds_since_retail'].fillna(-1)\n",
    "    merged['has_retail_activity'] = (merged['seconds_since_retail'] != -1).astype(int)\n",
    "    \n",
    "    # Feature: What category did they see last?\n",
    "    merged['last_retail_subdomain'] = merged['subdomain'].fillna('none')\n",
    "    merged['last_retail_subdomain'] = merged['last_retail_subdomain'].astype('category').cat.codes\n",
    "    \n",
    "    # 5. Demographics\n",
    "    print(\"  Merging Demographics...\")\n",
    "    final_df = merged.merge(users[['user_id', 'socdem_cluster', 'region']], on='user_id', how='left')\n",
    "    final_df['socdem_cluster'] = final_df['socdem_cluster'].fillna(-1)\n",
    "    final_df['region'] = final_df['region'].fillna(-1)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "full_dataset = build_features(offers_events, retail_events, users)\n",
    "\n",
    "# Garbage Collection\n",
    "del offers_events, retail_events\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73650e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_and_downsample(df):\n",
    "    print(\"Splitting and Downsampling...\")\n",
    "    \n",
    "    # Strict Time-Based Split to simulate production reality\n",
    "    times = df['timestamp'].sort_values()\n",
    "    n = len(times)\n",
    "    train_cutoff = times.iloc[int(0.7 * n)]\n",
    "    val_cutoff = times.iloc[int(0.85 * n)]\n",
    "    \n",
    "    train = df[df['timestamp'] < train_cutoff]\n",
    "    val = df[(df['timestamp'] >= train_cutoff) & (df['timestamp'] < val_cutoff)]\n",
    "    test = df[df['timestamp'] >= val_cutoff]\n",
    "    \n",
    "    # Downsample Negatives in TRAIN only\n",
    "    # This balances the dataset for the model to learn patterns better,\n",
    "    # without biasing the Validation/Test sets (which must remain real-world).\n",
    "    print(\"  Downsampling Train Negatives...\")\n",
    "    train_pos = train[train['is_clicked'] == 1]\n",
    "    train_neg = train[train['is_clicked'] == 0]\n",
    "    \n",
    "    train_neg_sampled = train_neg.sample(frac=0.2, random_state=SEED)\n",
    "    train_balanced = pd.concat([train_pos, train_neg_sampled]).sample(frac=1, random_state=SEED)\n",
    "    \n",
    "    print(f\"Train Balanced: {len(train_balanced):,} rows\")\n",
    "    return train_balanced, val, test\n",
    "\n",
    "train_df, val_df, test_df = split_and_downsample(full_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(train, val):\n",
    "    print(\"Training LightGBM Model...\")\n",
    "    \n",
    "    features = [\n",
    "        'item_id', 'offer_popularity', # NEW: Item Features\n",
    "        'hour', 'day_of_week', 'user_hist_ctr', \n",
    "        'seconds_since_retail', 'has_retail_activity', 'last_retail_subdomain',\n",
    "        'socdem_cluster', 'region'\n",
    "    ]\n",
    "    target = 'is_clicked'\n",
    "    \n",
    "    dtrain = lgb.Dataset(train[features], label=train[target])\n",
    "    dval = lgb.Dataset(val[features], label=val[target], reference=dtrain)\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': SEED\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[dtrain, dval],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(50)]\n",
    "    )\n",
    "    \n",
    "    return model, features\n",
    "\n",
    "model, feature_names = train_model(train_df, val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6548d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_lift_curve(y_true, y_pred, step=0.1):\n",
    "    # Create a DataFrame for analysis\n",
    "    data = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
    "    data = data.sort_values('y_pred', ascending=False)\n",
    "    \n",
    "    # Calculate cumulative metrics\n",
    "    data['cum_users'] = np.arange(len(data)) + 1\n",
    "    data['cum_pos'] = data['y_true'].cumsum()\n",
    "    data['percentile'] = data['cum_users'] / len(data)\n",
    "    \n",
    "    # Global CTR\n",
    "    global_ctr = data['y_true'].mean()\n",
    "    \n",
    "    # Calculate Lift at each percentile\n",
    "    # Lift = (Cumulative CTR at percentile) / Global CTR\n",
    "    data['cum_ctr'] = data['cum_pos'] / data['cum_users']\n",
    "    data['lift'] = data['cum_ctr'] / global_ctr\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(data['percentile'], data['lift'], label='Model Lift')\n",
    "    plt.axhline(1.0, color='r', linestyle='--', label='Random Guessing (Lift=1.0)')\n",
    "    plt.xlabel('Percentile of Users Targeted (Top X%)')\n",
    "    plt.ylabel('Lift (x times better than random)')\n",
    "    plt.title('Lift Curve: Business Impact of Targeting')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def evaluate_and_visualize(model, test_df, features):\n",
    "    print(\"Evaluating Model...\")\n",
    "    \n",
    "    X_test = test_df[features]\n",
    "    y_test = test_df['is_clicked']\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 1. ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Lift Curve (Business Metric)\n",
    "    lift_data = plot_lift_curve(y_test, y_pred)\n",
    "    \n",
    "    # 3. Key Metrics for Conclusion\n",
    "    top_10_lift = lift_data[lift_data['percentile'] >= 0.1].iloc[0]['lift']\n",
    "    top_20_lift = lift_data[lift_data['percentile'] >= 0.2].iloc[0]['lift']\n",
    "    \n",
    "    return y_pred, auc, top_10_lift, top_20_lift\n",
    "\n",
    "y_pred, auc_score, lift_10, lift_20 = evaluate_and_visualize(model, test_df, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_model(model, val_df, features):\n",
    "    print(\"Generating SHAP Explanations...\")\n",
    "    X_sample = val_df[features].sample(1000, random_state=SEED)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    \n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values[1], X_sample, plot_type=\"bar\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values[1], X_sample)\n",
    "    plt.show()\n",
    "\n",
    "explain_model(model, val_df, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1492bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_conclusion(auc, lift_10, lift_20):\n",
    "    print(\"=\"*60)\n",
    "    print(\"FINAL CONCLUSION & BUSINESS IMPACT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"1. Model Performance (AUC: {auc:.3f})\")\n",
    "    if auc > 0.7:\n",
    "        print(\"   -> The model has STRONG predictive power.\")\n",
    "    elif auc > 0.6:\n",
    "        print(\"   -> The model has MODERATE predictive power.\")\n",
    "    else:\n",
    "        print(\"   -> The model is WEAK (close to random guessing).\")\n",
    "        \n",
    "    print(f\"\\n2. Business Impact (Lift)\")\n",
    "    print(f\"   -> Top 10% Targeting: {lift_10:.2f}x more effective than random.\")\n",
    "    print(f\"   -> Top 20% Targeting: {lift_20:.2f}x more effective than random.\")\n",
    "    \n",
    "    print(\"\\n3. Verdict\")\n",
    "    if lift_10 > 2.0:\n",
    "        print(\"   SUCCESS. The AI significantly outperforms random guessing.\")\n",
    "        print(\"   Recommendation: Deploy to production for A/B testing on a small traffic slice.\")\n",
    "    else:\n",
    "        print(\"   UNCERTAIN. Lift is marginal.\")\n",
    "        print(\"   Recommendation: Investigate more features (e.g., item embeddings, deeper history).\")\n",
    "\n",
    "print_conclusion(auc_score, lift_10, lift_20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9df4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def interactive_demo(model, test_df, features):\n",
    "    print(\"=\"*60)\n",
    "    print(\"INTERACTIVE PRODUCTION SIMULATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Select a User ID to see how the model predicts their behavior on 'Live' (Test) data.\")\n",
    "    \n",
    "    # Get a list of users who have at least one interaction in the test set\n",
    "    sample_users = test_df['user_id'].unique()[:100] # Take first 100 for dropdown\n",
    "    \n",
    "    user_dropdown = widgets.Dropdown(\n",
    "        options=sample_users,\n",
    "        description='User ID:',\n",
    "        disabled=False,\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_user_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            user_id = change['new']\n",
    "            with output:\n",
    "                clear_output()\n",
    "                \n",
    "                # Get User Data\n",
    "                user_data = test_df[test_df['user_id'] == user_id].copy()\n",
    "                \n",
    "                if len(user_data) == 0:\n",
    "                    print(\"No data found for this user.\")\n",
    "                    return\n",
    "                \n",
    "                # User Profile (Static)\n",
    "                print(f\"--- User Profile ({user_id}) ---\")\n",
    "                print(f\"Region: {user_data['region'].iloc[0]}\")\n",
    "                print(f\"SocDem Cluster: {user_data['socdem_cluster'].iloc[0]}\")\n",
    "                print(f\"Historical CTR: {user_data['user_hist_ctr'].iloc[-1]:.2%}\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "                # Predict\n",
    "                X_user = user_data[features]\n",
    "                user_data['predicted_prob'] = model.predict(X_user)\n",
    "                \n",
    "                # Format for Display\n",
    "                display_cols = [\n",
    "                    'timestamp', 'item_id', 'offer_popularity', # Added Item Info\n",
    "                    'hour', 'last_retail_subdomain', \n",
    "                    'seconds_since_retail', 'is_clicked', 'predicted_prob'\n",
    "                ]\n",
    "                \n",
    "                display_df = user_data[display_cols].copy()\n",
    "                display_df['is_clicked'] = display_df['is_clicked'].map({1: 'CLICKED', 0: 'Ignored'})\n",
    "                display_df['predicted_prob'] = display_df['predicted_prob'].map('{:.1%}'.format)\n",
    "                display_df['seconds_since_retail'] = display_df['seconds_since_retail'].apply(lambda x: f\"{x:.0f}s\" if x != -1 else \"N/A\")\n",
    "                display_df['offer_popularity'] = display_df['offer_popularity'].astype(int)\n",
    "                \n",
    "                print(f\"\\nRecent Offer Interactions ({len(display_df)}):\")\n",
    "                display(display_df)\n",
    "\n",
    "    user_dropdown.observe(on_user_change)\n",
    "    display(user_dropdown, output)\n",
    "    \n",
    "    # Trigger first load\n",
    "    if len(sample_users) > 0:\n",
    "        user_dropdown.value = sample_users[0]\n",
    "\n",
    "interactive_demo(model, test_df, feature_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
