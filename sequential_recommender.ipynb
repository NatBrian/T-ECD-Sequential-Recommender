{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995b0fb6",
   "metadata": {
    "id": "995b0fb6"
   },
   "source": [
    "# Unified Sequential Recommender System (SASRec)\n",
    "\n",
    "## 1. Introduction & Theory (The \"Why\")\n",
    "\n",
    "### 1.1 Why Transformers for Recommendation?\n",
    "\n",
    "In traditional recommendation systems, we treat user preferences as static profiles. But **user behavior is temporal** - what a user clicked 5 minutes ago is more relevant than what they clicked 5 weeks ago.\n",
    "\n",
    "**SASRec (Self-Attentive Sequential Recommendation)** treats user histories like sentences:\n",
    "- **Items = Words/Tokens** in a vocabulary\n",
    "- **User History = Sentence** to be \"understood\"\n",
    "- **Next-Item Prediction = Language Model** predicting the next word\n",
    "\n",
    "This paradigm shift allows us to leverage the power of **Transformers**, the same architecture behind GPT and BERT.\n",
    "\n",
    "### 1.2 Core Concepts\n",
    "\n",
    "#### Causal (Autoregressive) Masking\n",
    "\n",
    "**The Problem**: During training, we must prevent the model from \"cheating\" by looking at future items.\n",
    "\n",
    "**The Solution**: Apply a triangular mask to the attention matrix so position `i` can only attend to positions `0, 1, ..., i`.\n",
    "\n",
    "```\n",
    "Attention Mask (for sequence length 5):\n",
    "      pos_0  pos_1  pos_2  pos_3  pos_4\n",
    "pos_0   ✓      ✗      ✗      ✗      ✗\n",
    "pos_1   ✓      ✓      ✗      ✗      ✗\n",
    "pos_2   ✓      ✓      ✓      ✗      ✗\n",
    "pos_3   ✓      ✓      ✓      ✓      ✗\n",
    "pos_4   ✓      ✓      ✓      ✓      ✓\n",
    "```\n",
    "\n",
    "This ensures the model learns to predict based only on past context.\n",
    "\n",
    "#### Self-Attention for Long-Range Dependencies\n",
    "\n",
    "Traditional RNNs struggle with long sequences due to vanishing gradients. Self-Attention computes relationships between **all items directly**:\n",
    "\n",
    "```\n",
    "Attention(Q, K, V) = softmax(QK^T / √d) V\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `Q` (Query): \"What am I looking for?\"\n",
    "- `K` (Key): \"What do I contain?\"  \n",
    "- `V` (Value): \"What information do I provide?\"\n",
    "- `√d`: Scaling factor to prevent exploding gradients\n",
    "\n",
    "### 1.3 Business Value\n",
    "\n",
    "1. **Discovery**: Recommend items users wouldn't explicitly search for, but might find interesting based on their behavioral patterns.\n",
    "\n",
    "2. **Cross-Selling**: Bridge Retail (FMCG) and Marketplace domains. A user buying baby formula → suggest strollers from Marketplace.\n",
    "\n",
    "3. **Session Awareness**: Capture \"in-session intent\" - if a user views 3 laptops in a row, they're laptop shopping NOW.\n",
    "\n",
    "### 1.4 Our Data\n",
    "\n",
    "We have **9.2 million events** from **286,000 users** across **316,000 items**:\n",
    "- Retail: 4.1M events (FMCG products)\n",
    "- Marketplace: 5.1M events (General merchandise)\n",
    "- Pre-trained embeddings: 456K items with 128-dimensional vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef85ca79",
   "metadata": {
    "id": "ef85ca79"
   },
   "source": [
    "---\n",
    "## 2. Configuration & Imports\n",
    "\n",
    "We configure all hyperparameters upfront with memory-conscious defaults for Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "983dfc1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11909,
     "status": "ok",
     "timestamp": 1766467761283,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "983dfc1d",
    "outputId": "524ab9be-4d57-4718-b9dd-a333d2a04494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA cache flushed.\n",
      "GPU: Tesla T4\n",
      "GPU Memory: 15.8 GB\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if needed (uncomment in Colab)\n",
    "# !pip install torch pandas numpy matplotlib seaborn tqdm\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "CLEANED_DATA_DIR = \"cleaned_data\"\n",
    "EMBEDDINGS_DIR = \"models/item_embeddings\"\n",
    "OUTPUT_DIR = \"models/sequential_recommender\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Hyperparameters (Colab-optimized)\n",
    "MAX_SEQ_LENGTH = 50       # Covers 95th percentile of sequence lengths\n",
    "EMBEDDING_DIM = 128       # Match pre-trained embeddings\n",
    "NUM_LAYERS = 2            # Small enough for Colab, deep enough to learn\n",
    "NUM_HEADS = 2             # Must divide EMBEDDING_DIM evenly\n",
    "HIDDEN_DIM = 256          # Feedforward dimension\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 128          # Memory-friendly\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 3            # Sufficient for demonstration\n",
    "SEED = 42\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    # Flush the GPU CUDA memory\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"CUDA cache flushed.\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd485e3",
   "metadata": {
    "id": "2bd485e3"
   },
   "source": [
    "---\n",
    "## 3. Data Preparation (Memory-Optimized)\n",
    "\n",
    "### Memory Optimization Strategies:\n",
    "1. **int32 for IDs**: Saves 50% RAM compared to int64\n",
    "2. **Load only required columns**: Skip `action_type`, `subdomain`, `os`\n",
    "3. **Generator-based Dataset**: Build sequences on-demand\n",
    "4. **Sequence length cap**: Truncate to 50 items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b55b9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19389,
     "status": "ok",
     "timestamp": 1766467780674,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "d8b55b9f",
    "outputId": "a952cecd-2a22-420b-c6f1-f0573f4ce0d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING DATA\n",
      "============================================================\n",
      "\n",
      "1. Loading item vocabulary...\n",
      "   Vocabulary size: 456,187 items (including padding)\n",
      "\n",
      "2. Loading event streams...\n",
      "   Retail events: 4,128,330\n",
      "   Marketplace events: 5,081,920\n",
      "\n",
      "3. Combining and sorting events...\n",
      "   Combined events: 9,210,250\n",
      "\n",
      "4. Mapping items to vocabulary indices...\n",
      "   Unmapped items (not in vocabulary): 1,009,396 (11.0%)\n",
      "   Events after filtering: 8,200,854\n",
      "\n",
      "5. Building user sequences...\n",
      "   Users with >=2 events: 266,371\n",
      "\n",
      "   Sequence Length Statistics:\n",
      "     Min:    2\n",
      "     Median: 8\n",
      "     Max:    47649\n",
      "     Mean:   30.71\n"
     ]
    }
   ],
   "source": [
    "def load_and_prepare_data():\n",
    "    \"\"\"\n",
    "    Load retail and marketplace events, map to vocabulary indices.\n",
    "\n",
    "    Memory-Optimized Implementation:\n",
    "    - Load only required columns (user_id, item_id, timestamp)\n",
    "    - Use int32 for indices (saves 50% memory)\n",
    "    - Remove unmapped items immediately\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 1. Load Item Vocabulary (from item_embeddings.ipynb)\n",
    "    print(\"\\n1. Loading item vocabulary...\")\n",
    "    vocab_path = os.path.join(EMBEDDINGS_DIR, \"item_vocabulary.parquet\")\n",
    "    vocab_df = pd.read_parquet(vocab_path)\n",
    "\n",
    "    # Create mapping dictionaries\n",
    "    # IMPORTANT: Shift indices by 1 because 0 is reserved for padding\n",
    "    item_to_idx = {item: idx + 1 for item, idx in zip(vocab_df['item_id'], vocab_df['index'])}\n",
    "    idx_to_item = {idx: item for item, idx in item_to_idx.items()}\n",
    "    vocab_size = len(item_to_idx) + 1  # +1 for padding token at index 0\n",
    "\n",
    "    print(f\"   Vocabulary size: {vocab_size:,} items (including padding)\")\n",
    "\n",
    "    # 2. Load Events (only required columns)\n",
    "    print(\"\\n2. Loading event streams...\")\n",
    "\n",
    "    # Retail Events\n",
    "    retail_path = os.path.join(CLEANED_DATA_DIR, \"retail_events_clean.parquet\")\n",
    "    retail = pd.read_parquet(retail_path, columns=['user_id', 'item_id', 'timestamp'])\n",
    "    print(f\"   Retail events: {len(retail):,}\")\n",
    "\n",
    "    # Marketplace Events\n",
    "    marketplace_path = os.path.join(CLEANED_DATA_DIR, \"marketplace_events_clean.parquet\")\n",
    "    marketplace = pd.read_parquet(marketplace_path, columns=['user_id', 'item_id', 'timestamp'])\n",
    "    print(f\"   Marketplace events: {len(marketplace):,}\")\n",
    "\n",
    "    # 3. Combine and sort\n",
    "    print(\"\\n3. Combining and sorting events...\")\n",
    "    events = pd.concat([retail, marketplace], ignore_index=True)\n",
    "    del retail, marketplace  # Free memory\n",
    "    gc.collect()\n",
    "\n",
    "    events = events.sort_values(['user_id', 'timestamp'])\n",
    "    print(f\"   Combined events: {len(events):,}\")\n",
    "\n",
    "    # 4. Map item_id to vocabulary index\n",
    "    print(\"\\n4. Mapping items to vocabulary indices...\")\n",
    "    events['item_idx'] = events['item_id'].map(item_to_idx)\n",
    "\n",
    "    # Count how many items couldn't be mapped\n",
    "    unmapped = events['item_idx'].isna().sum()\n",
    "    print(f\"   Unmapped items (not in vocabulary): {unmapped:,} ({unmapped/len(events)*100:.1f}%)\")\n",
    "\n",
    "    # Remove unmapped items and convert to int32\n",
    "    events = events.dropna(subset=['item_idx'])\n",
    "    events['item_idx'] = events['item_idx'].astype(np.int32)\n",
    "    print(f\"   Events after filtering: {len(events):,}\")\n",
    "\n",
    "    # 5. Build user sequences\n",
    "    print(\"\\n5. Building user sequences...\")\n",
    "    user_sequences = events.groupby('user_id')['item_idx'].apply(list).to_dict()\n",
    "\n",
    "    # Filter users with at least 2 interactions (minimum for next-item prediction)\n",
    "    user_sequences = {uid: seq for uid, seq in user_sequences.items() if len(seq) >= 2}\n",
    "    print(f\"   Users with >=2 events: {len(user_sequences):,}\")\n",
    "\n",
    "    # Sequence length statistics\n",
    "    seq_lengths = [len(seq) for seq in user_sequences.values()]\n",
    "    print(f\"\\n   Sequence Length Statistics:\")\n",
    "    print(f\"     Min:    {min(seq_lengths)}\")\n",
    "    print(f\"     Median: {np.median(seq_lengths):.0f}\")\n",
    "    print(f\"     Max:    {max(seq_lengths)}\")\n",
    "    print(f\"     Mean:   {np.mean(seq_lengths):.2f}\")\n",
    "\n",
    "    del events  # Free memory\n",
    "    gc.collect()\n",
    "\n",
    "    return user_sequences, item_to_idx, idx_to_item, vocab_size\n",
    "\n",
    "# Load data\n",
    "user_sequences, item_to_idx, idx_to_item, vocab_size = load_and_prepare_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e31214",
   "metadata": {
    "id": "a3e31214"
   },
   "source": [
    "### 3.1 PyTorch Dataset\n",
    "\n",
    "We implement a custom Dataset that:\n",
    "1. **Left-pads** sequences to `MAX_SEQ_LENGTH` (so the last item is always at the same position)\n",
    "2. Returns `(input_sequence, target_item)` pairs\n",
    "3. Uses on-demand sequence building (no full tensor in RAM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c3b839",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1103,
     "status": "ok",
     "timestamp": 1766467781779,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "29c3b839",
    "outputId": "0bd2bb0a-efc2-48fa-92c3-fdfcc870af45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data splits:\n",
      "  Train: 213,096 users\n",
      "  Val:   26,637 users\n",
      "  Test:  26,638 users\n",
      "Created dataset with 6,385,368 samples\n",
      "Created dataset with 793,053 samples\n",
      "Created dataset with 736,659 samples\n",
      "\n",
      "Data loaders created:\n",
      "  Train batches: 49,886\n",
      "  Val batches:   6,196\n",
      "  Test batches:  5,756\n"
     ]
    }
   ],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for sequential recommendation.\n",
    "\n",
    "    For each user, we create training samples using sliding window:\n",
    "    - Input: items[0:i] for i in range(2, len(items)+1)\n",
    "    - Target: items[i] (next item to predict)\n",
    "\n",
    "    Optimization: We left-pad sequences so that the prediction target\n",
    "    is always at the last position of the sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, user_sequences: Dict[int, List[int]], max_len: int = MAX_SEQ_LENGTH):\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Convert dict to list for efficient indexing\n",
    "        # self.sequences[i] is the sequence for the i-th user\n",
    "        self.sequences = list(user_sequences.values())\n",
    "\n",
    "        # Create an index mapping: dataset_idx -> (sequence_idx, target_pos)\n",
    "        # This avoids storing 9M separate list objects, saving massive RAM\n",
    "        self.index_map = []\n",
    "        for seq_idx, seq in enumerate(self.sequences):\n",
    "            # We predict from position 1 to len-1\n",
    "            # Input: seq[:i], Target: seq[i]\n",
    "            for i in range(1, len(seq)):\n",
    "                self.index_map.append((seq_idx, i))\n",
    "\n",
    "        print(f\"Created dataset with {len(self.index_map):,} samples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_idx, target_pos = self.index_map[idx]\n",
    "        seq = self.sequences[seq_idx]\n",
    "\n",
    "        # Get input sequence (window)\n",
    "        start_pos = max(0, target_pos - self.max_len)\n",
    "        input_seq = seq[start_pos:target_pos]\n",
    "        target = seq[target_pos]\n",
    "\n",
    "        # Left-pad sequence to max_len (pad with 0, which we'll use as padding idx)\n",
    "        # This ensures the most recent item is always at the last position\n",
    "        pad_len = self.max_len - len(input_seq)\n",
    "        padded = [0] * pad_len + input_seq\n",
    "\n",
    "        return torch.tensor(padded, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "\n",
    "def create_data_splits(user_sequences: Dict[int, List[int]],\n",
    "                       train_ratio=0.8, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split users into train/val/test sets.\n",
    "\n",
    "    We split by USER (not by sample) to avoid data leakage:\n",
    "    - User A's sequences should not appear in both train and test\n",
    "    \"\"\"\n",
    "    user_ids = list(user_sequences.keys())\n",
    "    np.random.shuffle(user_ids)\n",
    "\n",
    "    n_users = len(user_ids)\n",
    "    train_end = int(n_users * train_ratio)\n",
    "    val_end = int(n_users * (train_ratio + val_ratio))\n",
    "\n",
    "    train_users = set(user_ids[:train_end])\n",
    "    val_users = set(user_ids[train_end:val_end])\n",
    "    test_users = set(user_ids[val_end:])\n",
    "\n",
    "    train_seqs = {uid: seq for uid, seq in user_sequences.items() if uid in train_users}\n",
    "    val_seqs = {uid: seq for uid, seq in user_sequences.items() if uid in val_users}\n",
    "    test_seqs = {uid: seq for uid, seq in user_sequences.items() if uid in test_users}\n",
    "\n",
    "    print(f\"\\nData splits:\")\n",
    "    print(f\"  Train: {len(train_seqs):,} users\")\n",
    "    print(f\"  Val:   {len(val_seqs):,} users\")\n",
    "    print(f\"  Test:  {len(test_seqs):,} users\")\n",
    "\n",
    "    return train_seqs, val_seqs, test_seqs\n",
    "\n",
    "\n",
    "# Create data splits\n",
    "train_seqs, val_seqs, test_seqs = create_data_splits(user_sequences)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SequenceDataset(train_seqs)\n",
    "val_dataset = SequenceDataset(val_seqs)\n",
    "test_dataset = SequenceDataset(test_seqs)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"\\nData loaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader):,}\")\n",
    "print(f\"  Val batches:   {len(val_loader):,}\")\n",
    "print(f\"  Test batches:  {len(test_loader):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05277c",
   "metadata": {
    "id": "3e05277c"
   },
   "source": [
    "---\n",
    "## 4. Model Architecture (SASRec)\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "```\n",
    "Input Sequence [batch, seq_len]\n",
    "        ↓\n",
    "Item Embedding + Position Embedding\n",
    "        ↓\n",
    "Transformer Encoder (2 layers, 2 heads)\n",
    "        ↓           ↑\n",
    "    [Causal Mask]\n",
    "        ↓\n",
    "Linear Projection → [batch, seq_len, vocab_size]\n",
    "        ↓\n",
    "Take last position → [batch, vocab_size]\n",
    "```\n",
    "\n",
    "### Key Design Decisions:\n",
    "1. **Pre-trained Embeddings**: Initialize with embeddings from `item_embeddings.ipynb`\n",
    "2. **Learnable Position Embeddings**: Unlike fixed sinusoidal, these adapt to our data\n",
    "3. **Padding Index = 0**: Reserve index 0 for padding tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8777d35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4738,
     "status": "ok",
     "timestamp": 1766467786530,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "b8777d35",
    "outputId": "81912262-20dc-41d6-e93e-0d6b3a41f99d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained embeddings...\n",
      "  Loaded embeddings: (456186, 128)\n",
      "  Initialized item embeddings with pre-trained weights\n",
      "\n",
      "Model Summary:\n",
      "  Total parameters: 117,511,675\n",
      "  Trainable parameters: 117,511,675\n",
      "  Estimated size: 470.0 MB (float32)\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_embeddings(vocab_size: int, embed_dim: int):\n",
    "    \"\"\"\n",
    "    Load pre-trained item embeddings from item_embeddings.ipynb.\n",
    "\n",
    "    Returns a numpy array of shape [vocab_size, embed_dim].\n",
    "    If embeddings file doesn't exist, returns randomly initialized weights.\n",
    "    \"\"\"\n",
    "    emb_path = os.path.join(EMBEDDINGS_DIR, \"item_embeddings.parquet\")\n",
    "\n",
    "    if os.path.exists(emb_path):\n",
    "        print(\"Loading pre-trained embeddings...\")\n",
    "        emb_df = pd.read_parquet(emb_path)\n",
    "\n",
    "        # Stack embeddings into matrix\n",
    "        pretrained = np.vstack(emb_df['embedding'].values)\n",
    "        print(f\"  Loaded embeddings: {pretrained.shape}\")\n",
    "\n",
    "        # Verify dimensions match\n",
    "        if pretrained.shape[1] != embed_dim:\n",
    "            print(f\"  Warning: Embedding dim mismatch ({pretrained.shape[1]} vs {embed_dim})\")\n",
    "            print(\"  Using random initialization instead.\")\n",
    "            return None\n",
    "\n",
    "        # Create new embedding matrix with padding at index 0\n",
    "        # Shape: [vocab_size, embed_dim] where vocab_size includes padding\n",
    "        embeddings = np.zeros((vocab_size, embed_dim))\n",
    "\n",
    "        # Copy pretrained weights to indices 1..N\n",
    "        # We assume the order in item_embeddings.parquet matches item_vocabulary.parquet\n",
    "        # (which is true based on item_embeddings.ipynb logic)\n",
    "        n_pretrained = pretrained.shape[0]\n",
    "        n_vocab_items = vocab_size - 1\n",
    "\n",
    "        n_copy = min(n_pretrained, n_vocab_items)\n",
    "        embeddings[1:n_copy+1] = pretrained[:n_copy]\n",
    "\n",
    "        return embeddings\n",
    "    else:\n",
    "        print(f\"  Pre-trained embeddings not found at {emb_path}\")\n",
    "        print(\"  Using random initialization.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "    \"\"\"\n",
    "    Self-Attentive Sequential Recommendation (SASRec) Model.\n",
    "\n",
    "    Paper: \"Self-Attentive Sequential Recommendation\" (Kang & McAuley, 2018)\n",
    "\n",
    "    Architecture:\n",
    "    - Item Embedding (optionally pre-trained)\n",
    "    - Learnable Position Embedding\n",
    "    - Transformer Encoder with Causal Masking\n",
    "    - Linear Prediction Head\n",
    "\n",
    "    Args:\n",
    "        vocab_size: Number of items in vocabulary\n",
    "        embed_dim: Embedding dimension\n",
    "        max_len: Maximum sequence length\n",
    "        num_layers: Number of transformer layers\n",
    "        num_heads: Number of attention heads\n",
    "        hidden_dim: Feedforward network dimension\n",
    "        dropout: Dropout rate\n",
    "        pretrained_emb: Optional pre-trained embedding weights\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size: int, embed_dim: int = 128, max_len: int = 50,\n",
    "                 num_layers: int = 2, num_heads: int = 2, hidden_dim: int = 256,\n",
    "                 dropout: float = 0.1, pretrained_emb: Optional[np.ndarray] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Item Embedding (with padding_idx=0)\n",
    "        self.item_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "\n",
    "        # Initialize with pre-trained weights if available\n",
    "        if pretrained_emb is not None:\n",
    "            self.item_embedding.weight.data.copy_(torch.tensor(pretrained_emb, dtype=torch.float32))\n",
    "            print(f\"  Initialized item embeddings with pre-trained weights\")\n",
    "\n",
    "        # Position Embedding (learnable)\n",
    "        self.pos_embedding = nn.Embedding(max_len, embed_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,  # [batch, seq, features]\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Layer Normalization\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Prediction Head\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize position embeddings and FC layer.\"\"\"\n",
    "        nn.init.xavier_uniform_(self.pos_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            seq: [batch, seq_len] - Item indices (0 = padding)\n",
    "\n",
    "        Returns:\n",
    "            logits: [batch, seq_len, vocab_size] - Prediction logits for each position\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = seq.shape\n",
    "\n",
    "        # Create position indices [0, 1, 2, ..., seq_len-1]\n",
    "        positions = torch.arange(seq_len, device=seq.device).unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "        # Get embeddings\n",
    "        item_emb = self.item_embedding(seq)  # [batch, seq_len, embed_dim]\n",
    "        pos_emb = self.pos_embedding(positions)  # [batch, seq_len, embed_dim]\n",
    "\n",
    "        # Combine and apply dropout\n",
    "        x = self.dropout(item_emb + pos_emb)\n",
    "\n",
    "        # Create causal mask (upper triangular = masked)\n",
    "        causal_mask = nn.Transformer.generate_square_subsequent_mask(\n",
    "            seq_len, device=seq.device\n",
    "        )\n",
    "\n",
    "        # Create padding mask (True = masked/padded position)\n",
    "        padding_mask = (seq == 0)\n",
    "\n",
    "        # Apply transformer\n",
    "        x = self.transformer(x, mask=causal_mask, src_key_padding_mask=padding_mask)\n",
    "\n",
    "        # Layer norm\n",
    "        x = self.ln(x)\n",
    "\n",
    "\n",
    "        # OPTIMIZATION: Only compute logits for the last position\n",
    "        # We only need to predict the next item after the sequence end\n",
    "        # This reduces output size from [batch, seq_len, vocab] to [batch, vocab]\n",
    "        # saving massive amount of memory (11GB -> 200MB)\n",
    "        x_last = x[:, -1, :]  # [batch, embed_dim]\n",
    "\n",
    "        # Project to vocabulary\n",
    "        logits = self.fc(x_last)  # [batch, vocab_size]\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def predict(self, seq: torch.Tensor, k: int = 10) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict top-k next items.\n",
    "\n",
    "        Args:\n",
    "            seq: [batch, seq_len] - Item indices\n",
    "            k: Number of top items to return\n",
    "\n",
    "        Returns:\n",
    "            top_k_items: [batch, k] - Top-k predicted item indices\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(seq)  # [batch, vocab_size]\n",
    "            # Get top-k\n",
    "            _, top_k = torch.topk(logits, k, dim=1)\n",
    "        return top_k\n",
    "\n",
    "\n",
    "# Load pre-trained embeddings\n",
    "pretrained_emb = load_pretrained_embeddings(vocab_size, EMBEDDING_DIM)\n",
    "\n",
    "# Create model\n",
    "model = SASRec(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=EMBEDDING_DIM,\n",
    "    max_len=MAX_SEQ_LENGTH,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_emb=pretrained_emb\n",
    ").to(device)\n",
    "\n",
    "# Print model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Estimated size: {total_params * 4 / 1e6:.1f} MB (float32)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32f595",
   "metadata": {
    "id": "db32f595"
   },
   "source": [
    "---\n",
    "## 5. Training\n",
    "\n",
    "### Training Strategy:\n",
    "1. **Loss**: CrossEntropyLoss (standard for multi-class classification)\n",
    "2. **Optimizer**: AdamW (Adam with weight decay, recommended for Transformers)\n",
    "3. **Learning Rate**: 1e-3 with ReduceLROnPlateau scheduler\n",
    "4. **Memory Monitoring**: Print GPU usage every 1000 batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "684cd9c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12110194,
     "status": "ok",
     "timestamp": 1766479896725,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "684cd9c0",
    "outputId": "70d2e306-6745-4bd1-c12e-e8bd87ce0519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING\n",
      "============================================================\n",
      "Epochs: 3\n",
      "Batch size: 128\n",
      "Learning rate: 0.001\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 1002/49886 [01:21<1:04:05, 12.71it/s, loss=7.7663]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1000: Loss=8.3272, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 2002/49886 [02:41<1:03:09, 12.64it/s, loss=7.5489]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2000: Loss=7.9541, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 3002/49886 [04:00<1:01:13, 12.76it/s, loss=7.6065]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3000: Loss=7.5392, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 4002/49886 [05:19<1:01:09, 12.50it/s, loss=6.9849]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 4000: Loss=7.6115, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 5002/49886 [06:38<59:05, 12.66it/s, loss=7.3017]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 5000: Loss=7.0686, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 6002/49886 [07:58<57:15, 12.77it/s, loss=7.3905]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 6000: Loss=6.9717, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 7002/49886 [09:17<56:25, 12.67it/s, loss=7.2354]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 7000: Loss=7.4891, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 8002/49886 [10:36<55:27, 12.59it/s, loss=7.0046]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 8000: Loss=7.8836, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 9002/49886 [11:56<53:45, 12.68it/s, loss=7.3089]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 9000: Loss=6.8102, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 10002/49886 [13:15<52:50, 12.58it/s, loss=7.2034]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 10000: Loss=7.3076, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 11002/49886 [14:34<51:05, 12.68it/s, loss=7.0933]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 11000: Loss=7.1617, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 12002/49886 [15:53<49:44, 12.69it/s, loss=6.8827]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 12000: Loss=6.8593, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 13002/49886 [17:13<48:41, 12.62it/s, loss=6.5326]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 13000: Loss=6.9518, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 14002/49886 [18:33<47:23, 12.62it/s, loss=7.1093]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 14000: Loss=6.8507, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 15002/49886 [19:53<45:49, 12.69it/s, loss=6.0914]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 15000: Loss=6.9345, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 16002/49886 [21:12<44:21, 12.73it/s, loss=7.2267]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 16000: Loss=6.9237, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|███▍      | 17002/49886 [22:32<43:21, 12.64it/s, loss=7.3309]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 17000: Loss=6.7086, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▌      | 18002/49886 [23:51<41:54, 12.68it/s, loss=6.5161]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 18000: Loss=6.9373, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 19002/49886 [25:11<40:44, 12.63it/s, loss=7.0592]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 19000: Loss=6.8306, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 20002/49886 [26:30<39:19, 12.66it/s, loss=6.7736]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 20000: Loss=6.6062, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 21002/49886 [27:49<38:06, 12.63it/s, loss=6.5789]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 21000: Loss=7.2505, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▍     | 22002/49886 [29:08<36:42, 12.66it/s, loss=7.0190]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 22000: Loss=6.9135, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▌     | 23002/49886 [30:28<35:33, 12.60it/s, loss=7.1842]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 23000: Loss=7.4409, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 24002/49886 [31:47<34:11, 12.62it/s, loss=6.9002]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 24000: Loss=6.5812, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 25002/49886 [33:06<32:55, 12.60it/s, loss=6.4049]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 25000: Loss=7.4190, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 26002/49886 [34:25<31:11, 12.76it/s, loss=6.6091]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 26000: Loss=6.7574, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▍    | 27002/49886 [35:44<30:00, 12.71it/s, loss=7.1094]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 27000: Loss=6.7695, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▌    | 28002/49886 [37:03<29:17, 12.45it/s, loss=6.7800]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 28000: Loss=7.1112, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 29002/49886 [38:23<27:59, 12.44it/s, loss=6.9077]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 29000: Loss=6.5476, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 30002/49886 [39:43<26:06, 12.69it/s, loss=7.0351]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 30000: Loss=6.6958, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 31002/49886 [41:02<25:22, 12.40it/s, loss=6.8610]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 31000: Loss=6.4185, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 32002/49886 [42:22<23:32, 12.66it/s, loss=7.0884]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 32000: Loss=6.9007, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 33002/49886 [43:41<22:59, 12.24it/s, loss=6.5301]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 33000: Loss=6.8538, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 34002/49886 [45:00<20:55, 12.65it/s, loss=6.8682]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 34000: Loss=6.5330, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 35002/49886 [46:20<19:53, 12.47it/s, loss=6.5118]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 35000: Loss=6.1329, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 36002/49886 [47:39<18:14, 12.68it/s, loss=6.4832]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 36000: Loss=6.8130, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 37002/49886 [48:58<17:20, 12.39it/s, loss=6.2672]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 37000: Loss=6.7438, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|███████▌  | 38002/49886 [50:17<15:48, 12.54it/s, loss=6.5746]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 38000: Loss=6.6312, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 39002/49886 [51:37<14:59, 12.09it/s, loss=6.6312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 39000: Loss=7.0651, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 40002/49886 [52:56<12:58, 12.70it/s, loss=6.8932]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 40000: Loss=6.5577, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|████████▏ | 41002/49886 [54:15<12:12, 12.13it/s, loss=7.0748]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 41000: Loss=6.6809, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 42002/49886 [55:34<10:17, 12.76it/s, loss=6.6723]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 42000: Loss=6.5433, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|████████▌ | 43002/49886 [56:53<09:19, 12.31it/s, loss=6.3167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 43000: Loss=6.8373, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 44002/49886 [58:12<07:43, 12.69it/s, loss=7.0537]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 44000: Loss=6.5633, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 45002/49886 [59:31<06:36, 12.32it/s, loss=6.7960]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 45000: Loss=6.6537, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|█████████▏| 46002/49886 [1:00:50<05:05, 12.71it/s, loss=7.0751]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 46000: Loss=6.8527, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 47002/49886 [1:02:10<03:56, 12.21it/s, loss=6.8983]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 47000: Loss=6.7891, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 48002/49886 [1:03:29<02:28, 12.73it/s, loss=6.6828]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 48000: Loss=6.5854, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 49002/49886 [1:04:48<01:13, 12.05it/s, loss=6.9034]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 49000: Loss=6.5789, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 6.9660 | Val Loss: nan\n",
      "  GPU Memory: 1.90GB / 2.60GB (peak)\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 1003/49886 [01:20<1:04:48, 12.57it/s, loss=6.1901]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1000: Loss=6.5367, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 2003/49886 [02:39<1:02:26, 12.78it/s, loss=6.7286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2000: Loss=7.0631, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 3003/49886 [03:58<1:01:46, 12.65it/s, loss=6.8449]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3000: Loss=6.5011, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 4003/49886 [05:18<1:02:39, 12.20it/s, loss=6.2566]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 4000: Loss=6.3116, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 5003/49886 [06:37<59:06, 12.66it/s, loss=6.4330]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 5000: Loss=6.9836, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 6003/49886 [07:56<59:48, 12.23it/s, loss=6.7231]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 6000: Loss=6.6610, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 7003/49886 [09:15<56:43, 12.60it/s, loss=6.7844]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 7000: Loss=6.5134, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 8003/49886 [10:35<56:50, 12.28it/s, loss=6.6072]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 8000: Loss=6.4096, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 9003/49886 [11:54<53:57, 12.63it/s, loss=7.0182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 9000: Loss=6.5433, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 10003/49886 [13:13<53:24, 12.44it/s, loss=6.5016]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 10000: Loss=6.5419, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 11003/49886 [14:32<50:56, 12.72it/s, loss=7.2090]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 11000: Loss=6.4329, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 12003/49886 [15:51<49:48, 12.68it/s, loss=6.4237]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 12000: Loss=6.5828, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 13003/49886 [17:11<48:31, 12.67it/s, loss=6.5124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 13000: Loss=6.8306, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 14003/49886 [18:31<48:04, 12.44it/s, loss=6.9906]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 14000: Loss=6.2569, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 15003/49886 [19:51<46:31, 12.50it/s, loss=7.2472]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 15000: Loss=6.4551, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 16003/49886 [21:11<44:14, 12.77it/s, loss=6.9413]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 16000: Loss=7.0669, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|███▍      | 17003/49886 [22:31<42:48, 12.80it/s, loss=6.1985]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 17000: Loss=6.7342, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▌      | 18003/49886 [23:50<41:57, 12.67it/s, loss=6.4299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 18000: Loss=6.9450, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 19003/49886 [25:10<41:00, 12.55it/s, loss=6.9246]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 19000: Loss=6.8745, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 20003/49886 [26:29<39:13, 12.70it/s, loss=6.8320]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 20000: Loss=7.0376, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 21003/49886 [27:48<38:29, 12.51it/s, loss=6.6554]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 21000: Loss=6.5623, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▍     | 22003/49886 [29:07<36:16, 12.81it/s, loss=6.3633]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 22000: Loss=6.8413, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▌     | 23003/49886 [30:27<35:46, 12.52it/s, loss=6.5398]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 23000: Loss=6.9428, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 24003/49886 [31:46<33:44, 12.79it/s, loss=6.8209]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 24000: Loss=6.8813, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 25003/49886 [33:05<33:13, 12.48it/s, loss=7.0069]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 25000: Loss=6.7320, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 26003/49886 [34:25<31:46, 12.53it/s, loss=6.8475]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 26000: Loss=6.9922, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▍    | 27003/49886 [35:45<30:39, 12.44it/s, loss=6.3654]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 27000: Loss=6.8238, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▌    | 28003/49886 [37:04<28:52, 12.63it/s, loss=6.6076]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 28000: Loss=6.5200, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 29003/49886 [38:23<27:42, 12.56it/s, loss=6.8304]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 29000: Loss=6.5838, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 30003/49886 [39:43<26:23, 12.55it/s, loss=6.2996]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 30000: Loss=6.8915, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 31003/49886 [41:02<25:49, 12.19it/s, loss=6.7137]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 31000: Loss=6.4560, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 32003/49886 [42:21<23:21, 12.76it/s, loss=6.6259]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 32000: Loss=6.2492, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 33003/49886 [43:41<22:39, 12.42it/s, loss=6.6737]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 33000: Loss=6.9019, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 34003/49886 [45:00<20:53, 12.67it/s, loss=6.8463]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 34000: Loss=6.5202, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 35003/49886 [46:20<20:50, 11.90it/s, loss=7.1408]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 35000: Loss=6.7692, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 36003/49886 [47:39<18:08, 12.75it/s, loss=6.2873]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 36000: Loss=6.3141, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 37003/49886 [48:58<17:34, 12.22it/s, loss=6.4182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 37000: Loss=6.5732, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|███████▌  | 38003/49886 [50:18<15:51, 12.49it/s, loss=6.1108]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 38000: Loss=6.7449, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 39003/49886 [51:37<14:37, 12.41it/s, loss=6.4680]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 39000: Loss=6.9062, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 40003/49886 [52:57<12:58, 12.69it/s, loss=6.6521]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 40000: Loss=6.5208, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|████████▏ | 41003/49886 [54:16<11:50, 12.51it/s, loss=6.6205]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 41000: Loss=6.8313, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 42003/49886 [55:36<10:24, 12.62it/s, loss=6.3716]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 42000: Loss=6.7098, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|████████▌ | 43003/49886 [56:55<09:08, 12.55it/s, loss=6.9137]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 43000: Loss=7.1218, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 44003/49886 [58:15<07:38, 12.82it/s, loss=6.5988]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 44000: Loss=7.0812, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 45003/49886 [59:34<06:29, 12.53it/s, loss=6.6227]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 45000: Loss=6.8498, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|█████████▏| 46003/49886 [1:00:53<05:06, 12.67it/s, loss=6.8212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 46000: Loss=6.9456, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 47003/49886 [1:02:13<03:48, 12.64it/s, loss=6.7251]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 47000: Loss=6.8769, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 48003/49886 [1:03:32<02:28, 12.69it/s, loss=6.1607]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 48000: Loss=7.0914, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 49003/49886 [1:04:52<01:09, 12.76it/s, loss=6.8283]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 49000: Loss=6.5229, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 6.6539 | Val Loss: nan [lr: 0.001000 → 0.000500]\n",
      "  GPU Memory: 1.90GB / 2.60GB (peak)\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 1003/49886 [01:20<1:04:29, 12.63it/s, loss=6.0160]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1000: Loss=6.7677, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 2003/49886 [02:40<1:02:48, 12.70it/s, loss=6.7141]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2000: Loss=6.5767, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 3003/49886 [03:59<1:01:22, 12.73it/s, loss=6.0802]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3000: Loss=6.4064, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 4003/49886 [05:18<1:00:50, 12.57it/s, loss=6.1665]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 4000: Loss=6.5095, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 5003/49886 [06:38<59:42, 12.53it/s, loss=6.6864]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 5000: Loss=6.1548, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 6003/49886 [07:58<57:51, 12.64it/s, loss=6.0623]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 6000: Loss=6.5796, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 7003/49886 [09:17<56:10, 12.72it/s, loss=6.2041]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 7000: Loss=6.6883, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 8003/49886 [10:36<55:10, 12.65it/s, loss=6.8175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 8000: Loss=6.2448, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 9003/49886 [11:55<53:55, 12.63it/s, loss=6.2171]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 9000: Loss=6.5473, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 10003/49886 [13:15<52:52, 12.57it/s, loss=6.3684]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 10000: Loss=7.1608, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 11003/49886 [14:34<50:34, 12.81it/s, loss=6.5830]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 11000: Loss=6.8144, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 12003/49886 [15:53<49:51, 12.66it/s, loss=6.6481]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 12000: Loss=6.0778, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 13003/49886 [17:12<48:55, 12.57it/s, loss=6.3125]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 13000: Loss=6.3628, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 14003/49886 [18:32<47:16, 12.65it/s, loss=6.2470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 14000: Loss=5.7254, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 15003/49886 [19:51<45:51, 12.68it/s, loss=6.8971]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 15000: Loss=6.3083, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 16003/49886 [21:10<44:24, 12.72it/s, loss=6.3620]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 16000: Loss=6.7416, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|███▍      | 17003/49886 [22:30<43:06, 12.71it/s, loss=6.7926]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 17000: Loss=6.5104, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▌      | 18003/49886 [23:49<42:03, 12.63it/s, loss=6.4333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 18000: Loss=6.2494, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 19003/49886 [25:08<40:27, 12.72it/s, loss=7.0401]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 19000: Loss=6.4911, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 20003/49886 [26:28<39:10, 12.71it/s, loss=6.8260]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 20000: Loss=6.1543, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 21003/49886 [27:47<37:59, 12.67it/s, loss=6.5436]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 21000: Loss=6.6087, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▍     | 22003/49886 [29:06<36:15, 12.82it/s, loss=6.1889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 22000: Loss=6.5083, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▌     | 23003/49886 [30:26<36:36, 12.24it/s, loss=6.1843]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 23000: Loss=6.1256, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 24003/49886 [31:45<34:22, 12.55it/s, loss=6.4194]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 24000: Loss=6.7049, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 25003/49886 [33:04<33:41, 12.31it/s, loss=6.5931]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 25000: Loss=6.4338, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 26003/49886 [34:24<31:18, 12.71it/s, loss=6.2281]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 26000: Loss=6.2855, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▍    | 27003/49886 [35:43<31:09, 12.24it/s, loss=6.7143]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 27000: Loss=7.1027, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▌    | 28003/49886 [37:03<28:42, 12.70it/s, loss=6.3250]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 28000: Loss=6.7031, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 29003/49886 [38:22<28:32, 12.19it/s, loss=6.3926]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 29000: Loss=6.3599, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 30003/49886 [39:41<26:12, 12.65it/s, loss=6.1687]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 30000: Loss=6.6198, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 31003/49886 [41:01<25:37, 12.29it/s, loss=6.4317]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 31000: Loss=6.6284, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 32003/49886 [42:20<23:27, 12.71it/s, loss=6.4387]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 32000: Loss=6.0590, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 33003/49886 [43:40<22:58, 12.25it/s, loss=6.4373]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 33000: Loss=6.5308, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 34003/49886 [44:59<20:56, 12.64it/s, loss=6.5083]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 34000: Loss=6.9076, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 35003/49886 [46:19<20:14, 12.25it/s, loss=7.2504]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 35000: Loss=6.0202, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 36003/49886 [47:38<18:06, 12.78it/s, loss=6.4948]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 36000: Loss=6.5840, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 37003/49886 [48:58<17:32, 12.24it/s, loss=7.2109]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 37000: Loss=6.6970, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|███████▌  | 38003/49886 [50:17<15:45, 12.56it/s, loss=6.6639]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 38000: Loss=6.7175, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 39003/49886 [51:37<14:32, 12.47it/s, loss=6.7189]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 39000: Loss=6.8660, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 40003/49886 [52:56<13:07, 12.55it/s, loss=6.7837]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 40000: Loss=6.3375, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|████████▏ | 41003/49886 [54:16<11:42, 12.64it/s, loss=6.5980]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 41000: Loss=6.3251, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 42003/49886 [55:35<10:24, 12.63it/s, loss=6.9857]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 42000: Loss=7.2310, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|████████▌ | 43003/49886 [56:54<09:10, 12.51it/s, loss=7.2535]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 43000: Loss=6.2141, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 44003/49886 [58:14<07:44, 12.67it/s, loss=6.1371]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 44000: Loss=6.2024, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 45003/49886 [59:33<06:28, 12.58it/s, loss=6.6450]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 45000: Loss=6.2822, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|█████████▏| 46003/49886 [1:00:53<05:06, 12.68it/s, loss=6.5457]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 46000: Loss=7.0686, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 47003/49886 [1:02:12<03:49, 12.58it/s, loss=7.0179]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 47000: Loss=6.7409, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 48003/49886 [1:03:32<02:29, 12.62it/s, loss=6.5483]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 48000: Loss=6.4323, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 49003/49886 [1:04:51<01:09, 12.67it/s, loss=6.2931]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 49000: Loss=6.7700, GPU Memory=2.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 6.4474 | Val Loss: nan\n",
      "  GPU Memory: 1.90GB / 2.60GB (peak)\n",
      "\n",
      "Best validation loss: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for batch_idx, (seq, target) in enumerate(pbar):\n",
    "        seq = seq.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(seq)  # [batch, vocab_size]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits, target)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping (prevents exploding gradients)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        # Print GPU memory every 1000 batches\n",
    "        if batch_idx > 0 and batch_idx % 1000 == 0 and torch.cuda.is_available():\n",
    "            gpu_mem = torch.cuda.memory_allocated() / 1e9\n",
    "            print(f\"  Batch {batch_idx}: Loss={loss.item():.4f}, GPU Memory={gpu_mem:.2f}GB\")\n",
    "\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"Evaluate model on validation/test set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, target in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            seq = seq.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            logits = model(seq)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "# Training setup\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "# Training history\n",
    "history = {'train_loss': [], 'val_loss': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    history['train_loss'].append(train_loss)\n",
    "\n",
    "    # Validate\n",
    "    val_loss = evaluate(model, val_loader, device)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_model.pt'))\n",
    "        saved_marker = \" (saved)\"\n",
    "    else:\n",
    "        saved_marker = \"\"\n",
    "\n",
    "    # Print summary\n",
    "    lr_change = f\" [lr: {old_lr:.6f} → {new_lr:.6f}]\" if old_lr != new_lr else \"\"\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}{lr_change}{saved_marker}\")\n",
    "\n",
    "    # GPU memory\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f}GB / {torch.cuda.max_memory_allocated() / 1e9:.2f}GB (peak)\")\n",
    "    print()\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oFP8C4WtbWg9",
   "metadata": {
    "executionInfo": {
     "elapsed": 8018,
     "status": "ok",
     "timestamp": 1766480267645,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "oFP8C4WtbWg9"
   },
   "outputs": [],
   "source": [
    "# Add this after training to save current model\n",
    "torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_model.pt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86802c43",
   "metadata": {
    "id": "86802c43"
   },
   "source": [
    "---\n",
    "## 6. Advanced Statistical Evaluation\n",
    "\n",
    "While Recommender Systems typically rely on Rank Metrics (HR/NDCG), we can adapt standard classification metrics to diagnose model behavior:\n",
    "\n",
    "### 1. Statistical Ranking Metrics\n",
    "* **MRR (Mean Reciprocal Rank):** The \"Average Accuracy\" of our ranking.\n",
    "  * *Formula:* $1 / \\text{Rank}$. If the correct item is at #1, score is 1.0. If at #10, score is 0.1.\n",
    "  * *Interpretation:* Indicates how far down the user typically has to scroll to find the result.\n",
    "\n",
    "### 2. Classification Diagnostics\n",
    "* **Category Confusion Matrix**: Since an item-level matrix ($450k \\times 450k$) is computationally infeasible, we aggregate predictions to the **Category Level** ($20 \\times 20$).\n",
    "  * *Purpose:* Identifies domain confusion (e.g., distinguishing between *Skin Care* and *Makeup*).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead020d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109145,
     "status": "ok",
     "timestamp": 1766480388672,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "ead020d4",
    "outputId": "6ea4c73f-1bc3-4024-b60e-05dffe654573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION ON TEST SET\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|██████████| 5756/5756 [01:48<00:00, 52.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Technical Metrics:\n",
      "  HR@5:   0.0319 (3.19%)\n",
      "  HR@10:  0.0500 (5.00%)\n",
      "  HR@20:  0.0768 (7.68%)\n",
      "  NDCG@10: 0.0266\n",
      "\n",
      "Business Metrics:\n",
      "  Catalog Coverage: 12,354 / 456,187 items (2.7%)\n",
      "\n",
      "Comparison to Random Baseline:\n",
      "  Random HR@10: 0.0022%\n",
      "  Model HR@10:  5.00%\n",
      "  Lift: 2278.7x better than random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(model, data_loader, device, k_values=[5, 10, 20]):\n",
    "    \"\"\"\n",
    "    Calculate HR@K and NDCG@K for multiple K values.\n",
    "\n",
    "    Also tracks:\n",
    "    - All recommended items (for coverage)\n",
    "    - Correctly predicted items (for analysis)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    metrics = {k: {'hits': 0, 'ndcg': 0} for k in k_values}\n",
    "    total_samples = 0\n",
    "    recommended_items = set()\n",
    "    max_k = max(k_values)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, target in tqdm(data_loader, desc=\"Computing metrics\"):\n",
    "            seq = seq.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            logits = model(seq)  # [batch, vocab_size]\n",
    "\n",
    "            # Get top-k predictions\n",
    "            _, top_k_items = torch.topk(logits, max_k, dim=1)  # [batch, max_k]\n",
    "\n",
    "            # Track recommended items\n",
    "            recommended_items.update(top_k_items.cpu().numpy().flatten().tolist())\n",
    "\n",
    "            # Calculate metrics for each K\n",
    "            for k in k_values:\n",
    "                top_k = top_k_items[:, :k]  # [batch, k]\n",
    "\n",
    "                # Hit Rate: Is target in top-k?\n",
    "                hits = (top_k == target.unsqueeze(1)).any(dim=1).float()\n",
    "                metrics[k]['hits'] += hits.sum().item()\n",
    "\n",
    "                # NDCG: Account for rank position\n",
    "                # DCG = 1 / log2(rank + 1) if hit, else 0\n",
    "                ranks = (top_k == target.unsqueeze(1)).nonzero()[:, 1] + 1  # 1-indexed ranks\n",
    "                if len(ranks) > 0:\n",
    "                    dcg = (1.0 / torch.log2(ranks.float() + 1)).sum().item()\n",
    "                    metrics[k]['ndcg'] += dcg\n",
    "\n",
    "            total_samples += len(target)\n",
    "\n",
    "    # Calculate final metrics\n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        results[f'HR@{k}'] = metrics[k]['hits'] / total_samples\n",
    "        results[f'NDCG@{k}'] = metrics[k]['ndcg'] / total_samples\n",
    "\n",
    "    results['num_items_recommended'] = len(recommended_items)\n",
    "    results['total_samples'] = total_samples\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, 'best_model.pt')))\n",
    "\n",
    "# Calculate metrics on test set\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_metrics = calculate_metrics(model, test_loader, device)\n",
    "\n",
    "print(f\"\\nTechnical Metrics:\")\n",
    "print(f\"  HR@5:   {test_metrics['HR@5']:.4f} ({test_metrics['HR@5']*100:.2f}%)\")\n",
    "print(f\"  HR@10:  {test_metrics['HR@10']:.4f} ({test_metrics['HR@10']*100:.2f}%)\")\n",
    "print(f\"  HR@20:  {test_metrics['HR@20']:.4f} ({test_metrics['HR@20']*100:.2f}%)\")\n",
    "print(f\"  NDCG@10: {test_metrics['NDCG@10']:.4f}\")\n",
    "\n",
    "# Catalog Coverage\n",
    "coverage = test_metrics['num_items_recommended'] / vocab_size * 100\n",
    "print(f\"\\nBusiness Metrics:\")\n",
    "print(f\"  Catalog Coverage: {test_metrics['num_items_recommended']:,} / {vocab_size:,} items ({coverage:.1f}%)\")\n",
    "\n",
    "# Random baseline comparison\n",
    "random_hr10 = 10 / vocab_size * 100\n",
    "print(f\"\\nComparison to Random Baseline:\")\n",
    "print(f\"  Random HR@10: {random_hr10:.4f}%\")\n",
    "print(f\"  Model HR@10:  {test_metrics['HR@10']*100:.2f}%\")\n",
    "print(f\"  Lift: {test_metrics['HR@10']*100 / random_hr10:.1f}x better than random\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64721f38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1766480389111,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "64721f38",
    "outputId": "91b5b319-d924-470c-f32d-7f19303eb0b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAh1RJREFUeJzs3Xd8jef/x/HXyY5IYtQIIrEFselX1apZau/alCpqddFWraKoSlFao6hV1KxStPaOVXvV3ltsknN+f9w/adMYCYn7TvJ+Ph7n0Z773Pd9Picfp/rOfd3XZXM4HA5EREREREREJM45mV2AiIiIiIiISGKl0C0iIiIiIiISTxS6RUREREREROKJQreIiIiIiIhIPFHoFhEREREREYknCt0iIiIiIiIi8UShW0RERERERCSeKHSLiIiIiIiIxBOFbhEREREREZF4otAtIiIi9OnTB5vN9lzHTpo0CZvNxvHjx+O2qHhis9no06eP2WWIiEgSodAtIiKWtHv3burVq0dAQAAeHh5kzJiRihUrMnLkyCce06BBA2w2G5988skT9zl+/DitWrUiW7ZseHh4kD59ekqXLk3v3r2j7Fe2bFlsNlvkw9PTk/z58xMSEoLdbo+zz/ksgYGBUep40mPSpEkvrSYrefTLgsuXLz/29cDAQN56660Xfp/p06cTEhLywucREZGkx+ZwOBxmFyEiIvJvGzZsoFy5cmTOnJkWLVqQPn16Tp06xaZNm/j77785cuRItGPCwsJIly4d6dOnJyIighMnTkS7cnvkyBGKFSuGp6cnrVu3JjAwkHPnzrF9+3aWLFnCvXv3IvctW7Ysf//9N4MGDQLg8uXLTJ8+ndDQUD799FMGDBgQvz+E/zd//nxu3boV+Xzx4sXMmDGD4cOH88orr0Ruf+2118iaNetzv094eDjh4eF4eHjE+tiIiAgePnyIu7v7c18tf159+vShb9++XLp0KcrP45HAwEDy5cvHokWLIrfdu3cPFxcXXFxcYvw+b731Fnv27EkwV/NFRMQ6Yv63jYiIyEsyYMAAfH19CQ0NJUWKFFFeu3jx4mOPmTNnDhEREfz444+88cYbrFmzhjJlykTZZ/jw4dy6dYudO3cSEBDwzPP6+vrStGnTyOft27cnd+7cjBw5kn79+uHs7PycnzDmatWqFeX5+fPnmTFjBrVq1SIwMPCJx92+fRsvL68Yv09sQ+i/OTs7v5SfRVx5nl8sxIfw8HDsdjtubm5mlyIiIvFIw8tFRMRy/v77b/LmzRstcAOkTZv2scdMmzaNihUrUq5cOYKCgpg2bdpjz5spU6Zogftp5/03Dw8PihUrxs2bN6OF9KlTp1KkSBE8PT1JlSoVjRo14tSpU9HOsXnzZqpWrUrKlCnx8vIif/78fPvtt89876dp2bIlyZMn5++//6Zq1ap4e3vTpEkTANauXUv9+vXJnDkz7u7u+Pv7061bN+7evRvlHI+7p9tms9GpUyfmz59Pvnz5cHd3J2/evPz+++9R9nvcPd2PhnWvW7eO4sWL4+HhQdasWfnpp5+i1b9r1y7KlCmDp6cnmTJl4ssvv2TixInxdp/4f+/pvnnzJl27diUwMBB3d3fSpk1LxYoV2b59O2CMevjtt98iR0/YbLYov/C4ePEibdq0IV26dHh4eFCgQAEmT54c5T2PHz+OzWbj66+/JiQkhGzZsuHu7s6WLVvw8vKiS5cu0eo8ffo0zs7OkaMtREQkYdKVbhERsZyAgAA2btzInj17yJcv3zP3P3v2LCtXrowMOo0bN2b48OGMGjUqylXEgIAA/vjjD1asWMEbb7zxXLU9Ck///oXAgAED6NWrFw0aNOCdd97h0qVLjBw5ktKlS7Njx47IfZcvX85bb72Fn58fXbp0IX369Ozfv59FixY9NnTFRnh4OJUrV+b111/n66+/JlmyZADMnj2bO3fu8N5775E6dWq2bNnCyJEjOX36NLNnz37medetW8fcuXPp0KED3t7ejBgxgrp163Ly5ElSp0791GOPHDlCvXr1aNOmDS1atODHH3+kZcuWFClShLx58wJw5swZypUrh81mo2fPnnh5eTF+/Hjc3d1j9fmvXr362O0xuf++ffv2/PLLL3Tq1Ik8efJw5coV1q1bx/79+ylcuDCfffYZN27c4PTp0wwfPhyA5MmTA3D37l3Kli3LkSNH6NSpE1myZGH27Nm0bNmS69evR+vrxIkTuXfvHu3atcPd3Z3MmTNTu3ZtZs6cyTfffBNlxMCMGTNwOByRv0AREZEEyiEiImIxy5Ytczg7OzucnZ0dJUqUcHz88ceOpUuXOh48ePDY/b/++muHp6enIywszOFwOByHDh1yAI558+ZF2W/Pnj0OT09PB+AoWLCgo0uXLo758+c7bt++He2cZcqUceTOndtx6dIlx6VLlxwHDhxwfPTRRw7AUa1atcj9jh8/7nB2dnYMGDAgyvG7d+92uLi4RG4PDw93ZMmSxREQEOC4du1alH3tdnuMfzZDhw51AI5jx45FbmvRooUDcPTo0SPa/nfu3Im2bdCgQQ6bzeY4ceJE5LbevXs7/vu/BYDDzc3NceTIkchtf/31lwNwjBw5MnLbxIkTo9UUEBDgABxr1qyJ3Hbx4kWHu7u744MPPojc9v777ztsNptjx44dkduuXLniSJUqVbRzPs6jup/2+He/Hn2u3r17Rz739fV1dOzY8anvU61aNUdAQEC07SEhIQ7AMXXq1MhtDx48cJQoUcKRPHnyyD+Tx44dcwAOHx8fx8WLF6OcY+nSpQ7AsWTJkijb8+fP7yhTpsxT6xIREevT8HIREbGcihUrsnHjRmrUqMFff/3FkCFDqFy5MhkzZmThwoXR9p82bRrVqlXD29sbgBw5clCkSJFoQ8zz5s3Lzp07adq0KcePH+fbb7+lVq1apEuXjnHjxkU774EDB0iTJg1p0qQhd+7cDB06lBo1akSZKXzu3LnY7XYaNGjA5cuXIx/p06cnR44crFy5EoAdO3Zw7NgxunbtGm3YfFxNPvbee+9F2+bp6Rn577dv3+by5cu89tprOBwOduzY8cxzVqhQgWzZskU+z58/Pz4+Phw9evSZx+bJk4dSpUpFPk+TJg25cuWKcuzvv/9OiRIlKFiwYOS2VKlSxfrq7pw5c1i+fHm0R7p06Z55bIoUKdi8eTNnz56N1XuCMbFd+vTpady4ceQ2V1dXOnfuzK1bt1i9enWU/evWrUuaNGmibKtQoQIZMmSI8ud1z5497Nq1K8qcAiIikjBpeLmIiFhSsWLFmDt3Lg8ePOCvv/5i3rx5DB8+nHr16rFz507y5MkDwP79+9mxYwfNmzePMqt52bJl+e677wgLC8PHxydye86cOZkyZQoRERHs27ePRYsWMWTIENq1a0eWLFmoUKFC5L6BgYGMGzcOu93O33//zYABA7h06VKUibgOHz6Mw+EgR44cj/0crq6ugHE/ORCj4fLPw8XFhUyZMkXbfvLkSb744gsWLlzItWvXorx248aNZ543c+bM0balTJky2rme99gTJ05QokSJaPtlz579mef/t9KlSz929vKYTJo2ZMgQWrRogb+/P0WKFKFq1ao0b948RrPBnzhxghw5cuDkFPU6RlBQUOTr/5YlS5Zo53BycqJJkyaMGTOGO3fukCxZMqZNm4aHhwf169d/Zg0iImJtCt0iImJpbm5uFCtWjGLFipEzZ05atWrF7NmzI9fVnjp1KgDdunWjW7du0Y6fM2cOrVq1irbd2dmZ4OBggoODKVGiBOXKlWPatGlRQreXl1eU5yVLlqRw4cJ8+umnjBgxAjDuGbbZbCxZsuSxM3g/uvc3vrm7u0cLfhEREVSsWJGrV6/yySefkDt3bry8vDhz5gwtW7aM0f3OT5qV3BGDFUdf5NiXqUGDBpQqVYp58+axbNkyhg4dyuDBg5k7dy5vvvlmnL7Xv0ce/Fvz5s0ZOnQo8+fPp3HjxkyfPp233noLX1/fOH1/ERF5+RS6RUQkwShatCgA586dA4zwNn36dMqVK0eHDh2i7d+/f3+mTZv22ND9tPM+Sf78+WnatCk//PADH374IZkzZyZbtmw4HA6yZMlCzpw5n3jsoyHae/bsiRLk49Pu3bs5dOgQkydPpnnz5pHbly9f/lLePyYCAgIeu+7647bFJz8/Pzp06ECHDh24ePEihQsXZsCAAZGh+0m3AAQEBLBr1y7sdnuUX3ocOHAg8vWYyJcvH4UKFWLatGlkypSJkydPMnLkyBf8VCIiYgW6p1tERCxn5cqVj70aunjxYgBy5coFwPr16zl+/DitWrWiXr160R4NGzZk5cqVkffqrl27locPHz7zvE/z8ccf8/DhQ7755hsA6tSpg7OzM3379o1Ws8Ph4MqVKwAULlyYLFmyEBISwvXr16PtFx8eXWn+9/kdDscLL1EWlypXrszGjRvZuXNn5LarV68+dsm3+BARERFtmH3atGnJkCED9+/fj9zm5eX12OH4VatW5fz588ycOTNyW3h4OCNHjiR58uTR1op/mmbNmrFs2TJCQkJInTp1nF9lFxERc+hKt4iIWM7777/PnTt3qF27Nrlz5+bBgwds2LCBmTNnEhgYGHnletq0aTg7O1OtWrXHnqdGjRp89tln/Pzzz3Tv3p3Bgwezbds26tSpQ/78+QHYvn07P/30E6lSpaJr167PrC1PnjxUrVqV8ePH06tXL7Jly8aXX35Jz549OX78OLVq1cLb25tjx44xb9482rVrx4cffoiTkxNjxoyhevXqFCxYkFatWuHn58eBAwfYu3cvS5cujbOf3yO5c+cmW7ZsfPjhh5w5cwYfHx/mzJkTo/uxX5aPP/6YqVOnUrFiRd5///3IJcMyZ87M1atX42ySuSe5efMmmTJlol69ehQoUIDkyZPzxx9/EBoayrBhwyL3K1KkCDNnzqR79+4UK1aM5MmTU716ddq1a8cPP/xAy5Yt2bZtG4GBgfzyyy+sX7+ekJCQyMn9YuLtt9/m448/Zt68ebz33nuR8wGIiEjCptAtIiKW8/XXXzN79mwWL17M2LFjefDgAZkzZ6ZDhw58/vnnpEiRgocPHzJ79mxee+01UqVK9djz5MuXjyxZsjB16lS6d+/Op59+yvTp01m9ejXTpk3jzp07+Pn50ahRI3r16vXYSa4e56OPPuK3335j5MiR9OnThx49epAzZ06GDx9O3759AfD396dSpUrUqFEj8rjKlSuzcuVK+vbty7Bhw7Db7WTLlo22bdu++A/tMVxdXfn111/p3LkzgwYNwsPDg9q1a9OpUycKFCgQL+8ZW/7+/qxcuZLOnTszcOBA0qRJQ8eOHfHy8qJz584xmgjtRSRLlowOHTqwbNmyyJnos2fPzujRo6PMBt+hQwd27tzJxIkTGT58OAEBAVSvXh1PT09WrVpFjx49mDx5MmFhYeTKlYuJEyfSsmXLWNWSLl06KlWqxOLFi2nWrFkcf1IRETGLzWG12UxEREQkyevatSs//PADt27deuKEbIlR7dq12b1790u/p11EROKP7ukWERERU929ezfK8ytXrjBlyhRef/31JBW4z507x2+//aar3CIiiYyGl4uIiIipSpQoQdmyZQkKCuLChQtMmDCBsLAwevXqZXZpL8WxY8dYv34948ePx9XVlXfffdfskkREJA4pdIuIiIipqlatyi+//MLYsWOx2WwULlyYCRMmULp0abNLeylWr15Nq1atyJw5M5MnTyZ9+vRmlyQiInFI93SLiIiIiIiIxBPd0y0iIiIiIiISTxS6RUREREREROJJkrun2263c/bsWby9vbHZbGaXIyIiIiIiIgmQw+Hg5s2bZMiQASenJ1/PTnKh++zZs/j7+5tdhoiIiIiIiCQCp06dIlOmTE98PcmFbm9vb8D4wfj4+JhczZPZ7XYuXbpEmjRpnvpbEzGPemRt6o+1qT/Wpx5Zm/pjbeqP9alH1pZQ+hMWFoa/v39kxnySJBe6Hw0p9/HxsXzovnfvHj4+Ppb+g5aUqUfWpv5Ym/pjfeqRtak/1qb+WJ96ZG0JrT/Pum3Z+p9AREREREREJIFS6BYRERERERGJJwrdIiIiIiIiIvEkyd3TLSIiIiIiEp8iIiJ4+PCh2WUkWHa7nYcPH3Lv3j1T7+l2dXXF2dn5hc+j0C0iIiIiIhIHHA4H58+f5/r162aXkqA5HA7sdjs3b9585iRl8S1FihSkT5/+hepQ6BYREREREYkDjwJ32rRpSZYsmemBMaFyOByEh4fj4uJi2s/Q4XBw584dLl68CICfn99zn0uhW0RERERE5AVFREREBu7UqVObXU6CZoXQDeDp6QnAxYsXSZs27XMPNddEaiIiIiIiIi/o0T3cyZIlM7kSiUuP+vki9+grdIuIiIiIiMQRDSlPXOKinwrdIiIiIiIiIvFEoVtERERERETiTGBgICEhIWaXYRkK3RYUEQGrVsG8eR6sWmU8FxERERGRxO9RFpgxg3jPAjab7amPPn36PNd5Q0NDadeu3QvVVqFCBbp27fpC57AKzV5uMXPnQpcucPq0E5ACgEyZ4NtvoU4dU0sTEREREZF49E8W+GdbfGaBc+fORf77zJkz+eKLLzh48GDktuTJk0f+u8PhICIiAheXZ0fINGnSxG2hCZyudFvI3LlQr17ULxnAmTPG9rlzzalLRERERETilxlZIH369JEPX19fbDZb5PMDBw7g7e3NkiVLKFKkCO7u7qxbt46///6bmjVrki5dOpInT06xYsX4448/opz3v8PLbTYb48ePp3bt2iRLlowcOXKwcOHCF6p9zpw55M2bF3d3dwIDAxk2bFiU10ePHk2OHDnw8PAgXbp01KtXL/K1X375heDgYDw9PUmdOjUVKlTg9u3bL1TP0yh0W0REhPFbLYcj+muPtnXtqqHmIiIiIiIJgcMBt2/H7BEWBp07Pz0LdOli7BeT8z3uPM+rR48efPXVV+zfv5/8+fNz69Ytqlatyp9//smOHTuoUqUK1atX5+TJk089T9++fWnQoAG7du2iatWqNGnShKtXrz5XTdu2baNBgwY0atSI3bt306dPH3r16sWkSZMA2Lp1K507d6Zfv34cPHiQ33//ndKlSwPG1f3GjRvTunVr9u/fz6pVq6hTpw6OuPyh/YeGl1vE2rXRf6v1bw4HnDpl7Fe27EsrS0REREREnsOdO/Cv0dkvxOEwsoKvb8z2v3ULvLzi5r379etHxYoVI5+nSpWKAgUKRD7v378/8+bNY+HChXTq1OmJ52nZsiWNGzcGYODAgYwYMYItW7ZQpUqVWNf0zTffUL58eXr16gVAzpw52bdvH0OHDqVly5acPHkSLy8v3nrrLby9vQkICKBQoUKAEbrDw8OpU6cOAQEBAAQHB8e6htjQlW6L+NftFHGyn4iIiIiIyIsqWrRolOe3bt3iww8/JCgoiBQpUpA8eXL279//zCvd+fPnj/x3Ly8vfHx8uHjx4nPVtH//fkqWLBllW8mSJTl8+DARERFUrFiRgIAAsmbNSrNmzZg2bRp37twBoECBApQvX57g4GDq16/PuHHjuHbt2nPVEVMK3Rbh5xez/X78EY4ejd9aRERERETkxSRLZlxxjslj8eKYnXPx4pidL1myuPscXv+5ZP7hhx8yb948Bg4cyNq1a9m5cyfBwcE8ePDgqedxdXWN8txms2G32+Ou0H/x9vZm+/btzJgxAz8/P7744gsKFCjA9evXcXZ2Zvny5SxZsoQ8efIwcuRIcuXKxbFjx+KlFlDotoxSpYyZCW22p+/3xx+QOze8/z5cuPByahMRERERkdix2Ywh3jF5VKr09Cxgs4G/v7FfTM73rEzxItavX0/Lli2pXbs2wcHBpE+fnuPHj8ffGz5GUFAQ69evj1ZXzpw5cXZ2BsDFxYUKFSowZMgQdu3axfHjx1mxYgVgBP6SJUvSt29fduzYgZubG/PmzYu3enVPt0U4OxtLAdSrZ3xJ/n0f/6MvzeDBRuhetgxGjTKuenfrBh99FPP7O0RERERExFpikgVCQoz9zJYjRw7mzp1L9erVsdls9OrVK96uWF++fJmdO3dG2ebn58cHH3xAsWLF6N+/Pw0bNmTjxo2MGjWK0aNHA7Bo0SKOHj1K6dKlSZkyJYsXL8Zut5MrVy42b97Mn3/+SaVKlUibNi2bN2/m0qVLBAUFxctnAF3ptpQ6deCXXyBjxqjbM2Uytn/0ESxdCn/+CcWLG5MzDBgAWbLA0KFw9645dYuIiIiIyIt5VhaIj3W6n8c333xDypQpee2116hevTqVK1emcOHC8fJe06dPp1ChQlEe48aNo3DhwsyaNYuff/6ZfPny8cUXX9CvXz9atmwJQIoUKZg7dy5vvPEGQUFBfP/998yYMYO8efPi4+PDmjVrqFq1Kjlz5uTzzz9n2LBhvPnmm/HyGQBsjvicG92CwsLC8PX15caNG/j4+JhdzmNFRMDq1XYOHgwjVy4fypRxivZbLYcDFiyATz+F/fuNbRkyQO/e0KoV/OeWCYkHdrudixcvkjZtWpyc9Psrq1F/rE39sT71yNrUH2tTf6wvPnp07949jh07RpYsWfDw8Hju80REGCsWnTtnzPtUqpQ1rnC/TA6Hg/DwcFxcXLDF51j5GHhaX2OaLfVfAQtydjaWBatd+x5lyz7+S2azQa1asHs3TJwImTPD2bPw7ruQNy/MnAnxNMpDRERERETiyaMs0LgxT8wCkrAodCdwzs7QsiUcOmTc5/HKK3D4MDRqBEWLGsPRk9ZYBhEREREREetQ6E4k3N2hSxdjObG+fcHbG3bsgCpV4I03YNMmsysUERERERFJehS6Exlvb/jiCyN8d+9uhPFVq6BECWM4+p49ZlcoIiIiIiKSdCh0J1KvvALDhhnDzlu3BicnY+K1/PmhRQt4yUvpiYiIiIiIJEkK3Ylc5swwYYJxhbtuXeP+7p9+gpw5oXNnuHDB7ApFREREREQSL4XuJCIoyFjfb8sWqFABHj6EkSMhWzbo1Qtu3DC7QhERERERkcRHoTuJKVYMli83HkWLwu3b8OWXkDWrMRz97l2zKxQREREREUk8FLqTqAoVjKvec+ZA7txw9Sp8+CHkyAHjx0N4uNkVioiIiIiIJHwK3UmYzQZ16sDu3fDjj+DvD2fOQNu2kDcvzJ4NdrvZVYqIiIiIiJWVLVuWrl27ml2GZSl0Cy4u0KqVMdP5N98YM58fOgQNGkDx4rBsmTEBm4iIiIiIxLOICGPN3xkzjH9GRMTbW1WvXp0qVao89rW1a9dis9nYtWvXC7/PpEmTSJEixQufJ6FS6JZIHh7QrRv8/Tf07g3Jk8O2bVC5MpQvD5s3m12hiIiIiEgiNncuBAZCuXLw9tvGPwMDje3xoE2bNixfvpzTp09He23ixIkULVqU/Pnzx8t7JyUK3RKNjw/06QNHj0LXruDmBitXwv/+B7Vrw759ZlcoIiIiIpLIzJ0L9erBfwPwmTPG9ngI3m+99RZp0qRh0qRJUbbfunWL2bNn06ZNG65cuULjxo3JmDEjyZIlIzg4mBkzZsRpHSdPnqRmzZokT54cHx8fGjZsyIV/rW38119/Ua5cOby9vfHx8aFIkSJs3boVgBMnTlC9enVSpkyJl5cXefPmZfHixXFa34tS6JYnSpMGhg83hpq3agVOTjB/PgQHG89PnDC7QhERERERi3I4jKWCYvIIC4POnR9/T+ejbV26GPvF5HwxvDfUxcWF5s2bM2nSJBz/Omb27NlERETQuHFj7t27R5EiRfjtt9/Ys2cP7dq1o1mzZmzZsiUufkrY7XZq1qzJ1atXWb16NcuXL+fo0aM0adIkcp8mTZqQKVMmQkND2bZtGz169MDV1RWAjh07cv/+fdasWcPu3bsZPHgwyZMnj5Pa4oqL2QWI9QUEGBOtffghfP45zJsHkybB9Onw3nvw6aeQNq3ZVYqIiIiIWMidO8b9mnHB4TCugPv6xmz/W7fAyytGu7Zu3ZqhQ4eyevVqypYtCxhDy+vWrYuvry++vr58+OGHkfu///77LF26lFmzZlG8ePHYfpJo/vzzT3bv3s2xY8fw9/cHYPLkyeTLl4/Q0FCKFy/OyZMn+eijj8idOzcAOXLkiDz+5MmT1K1bl+DgYACyZs36wjXFNV3plhjLk8cY1bJpk3F7yYMH8O23kC2bcQ94WJjZFYqIiIiISGzkzp2b1157jR9//BGAI0eOsHbtWtq0aQNAREQE/fv3Jzg4mFSpUpE8eXKWLl3KyZMn4+T99+/fj7+/f2TgBsiTJw8pUqRg//79AHTv3p133nmHChUq8NVXX/H3339H7tu5c2e+/PJLSpYsSe/eveNk4re4ptAtsfbqq/Dnn8as5kWKGL9I69cPsmY1Zj+/d8/sCkVERERETJYsmfE/yjF5xPQe5MWLY3a+ZMliVWqbNm2YM2cON2/eZOLEiWTLlo0yZcoAMHToUL799ls++eQTVq5cyc6dO6lcuTIPHjyI7U/kufXp04e9e/dSrVo1VqxYQZ48eZg3bx4A77zzDkePHqVZs2bs3r2bokWLMnLkyJdWW0wodMtzsdmgYkUIDTXW886ZE65cgQ8+MP79xx8hPNzsKkVERERETGKzGUO8Y/KoVAkyZTKOedK5/P2N/WJyvied5wkaNGiAk5MT06dP56effqJ169bY/v8c69evp2bNmjRt2pQCBQqQNWtWDh069KI/nUhBQUGcOnWKU6dORW7bt28f169fJ0+ePJHbcubMSbdu3Vi2bBl16tRh4sSJka/5+/vTvn175s6dywcffMC4cePirL64oNAtL8RmMyZT3LsXxo83/ltx6hS0aWNMuDZnjtb4FhERERF5Kmdn475NiB6YHz0PCTH2iwfJkyenYcOG9OzZk3PnztGyZcvI13LkyMHy5cvZsGED+/fv5913340ys3hMRUREsHPnziiP/fv3U6FCBYKDg2nSpAnbt29ny5YttGjRgtKlS1O0aFHu3r1Lp06dWLVqFSdOnGD9+vWEhoYSFBQEQNeuXVm6dCnHjh1j+/btrFy5MvI1q1Doljjh4mIE7cOHYdgwSJ0aDhwwAvmrr8Iff5hdoYiIiIiIhdWpA7/8AhkzRt2eKZOxvU6deH37Nm3acO3aNSpXrkyGDBkit3/++ecULlyYypUrU7ZsWdKnT0+tWrViff5bt25RqFChKI/q1atjs9lYsGABKVOmpHTp0lSoUIGsWbMybdo0AJydnbly5QrNmzcnZ86cNGjQgDfffJO+ffsCRpjv2LEjQUFBVKlShZw5czJ69Og4+ZnEFZvDkbSuQ4aFheHr68uNGzfw8fExu5wnstvtXLx4kbRp0+LklPB+N3LjhhG+v/nGWLUAoHx5GDQIihUzt7a4ktB7lNipP9am/lifemRt6o+1qT/WFx89unfvHseOHSNLlix4eHg8/4kiImDtWjh3Dvz8oFSpeLvCbVUOh4Pw8HBcXFwih7mb5Wl9jWm21H8FJF74+hqTqx09aiw56OpqTL5WvDjUrQv/PxGhiIiIiIj8m7MzlC0LjRsb/0xigTsxUuiWeJU2rXF7yqFD0KKFcUvK3LmQLx+0bg1xtNKAiIiIiIiIJSl0y0sRGAiTJsHu3VCrFtjtMHEi5MgB3bvDpUsmFygiIiIiIhIPFLrlpcqbF+bNg40bjdEyDx7A8OHGGt99+8LNm2ZXKCIiIiIiEncUusUU//sfrFgBS5dC4cJw6xb06WOE75AQuHfP7ApFRERERERenEK3mMZmg0qVIDQUZs40hppfvgzdukGuXMbw8/Bws6sUEREREYk5u91udgkSh+Kiny5xUIfIC3FyggYNoHZt477vPn2MCdZat4ahQ2HAAOM+cJNXCxAREREReSI3NzecnJw4e/YsadKkwc3NzfTlrhIqKywZ5nA4ePDgAZcuXcLJyQk3N7fnPpdCt1iGqyu0bQtNm8J338HAgcbSYnXqGEuNDRoEb7xhdpUiIiIiItE5OTmRJUsWzp07x9mzZ80uJ0FzOBzY7XacnJxM/8VFsmTJyJw58wut567QLZbj6QkffgjvvANff21MtLZlC5QvDxUrGmG8aFGzqxQRERERicrNzY3MmTMTHh5ORESE2eUkWHa7nStXrpA6deoXCrsvytnZOU6utit0i2WlSAFffgnvv28MMf/+e1i+3HjUqwf9+0Pu3GZXKSIiIiLyD5vNhqurK66urmaXkmDZ7XZcXV3x8PAwNXTHlYT/CSTRS5cORoyAgwehWTPj3u5ffjGWH3vnHTh1yuwKRUREREREHk+hWxKMLFngp5/gr7+gRg2w22HCBGPW8w8+MGY+FxERERERsRKFbklwgoNhwQJYvx5Kl4b79+Gbb4w1vvv3N9b8FhERERERsQKFbkmwXnsNVq2CJUugYEG4eRO++MII3yNGGGFcRERERETETArdkqDZbFClCmzbBj//DNmzw6VL0KUL5MoFkyeDJo4UERERERGzmB66z5w5Q9OmTUmdOjWenp4EBwezdevWpx7z3XffERQUhKenJ7ly5eKnn356SdWKVTk5QcOGsG8f/PADZMgAJ05Ay5aQPz/Mnw8Oh9lVioiIiIhIUmNq6L527RolS5bE1dWVJUuWsG/fPoYNG0bKlCmfeMyYMWPo2bMnffr0Ye/evfTt25eOHTvy66+/vsTKxapcXaFdOzh8GAYPhpQpjSBeuzaUKGEMRxcREREREXlZTF2ne/Dgwfj7+zNx4sTIbVmyZHnqMVOmTOHdd9+lYcOGAGTNmpXQ0FAGDx5M9erV47VeSTiSJYOPPzYC+NChEBICmzdDuXJQqRIMHAhFiphdpYiIiIiIJHamXuleuHAhRYsWpX79+qRNm5ZChQoxbty4px5z//59PDw8omzz9PRky5YtPHz4MD7LlQQoRQoYMAD+/hs6dgQXF1i2DIoWNYajHzpkdoUiIiIiIpKYmXql++jRo4wZM4bu3bvz6aefEhoaSufOnXFzc6NFixaPPaZy5cqMHz+eWrVqUbhwYbZt28b48eN5+PAhly9fxs/PL8r+9+/f5/6/prEOCwsDwG63Y7fb4+/DvSC73Y7D4bB0jQlJ2rTGjOZdu0KfPjamT4dZs2zMmeOgVSvo1ctBpkyxO6d6ZG3qj7WpP9anHlmb+mNt6o/1qUfWllD6E9P6bA6HedNLubm5UbRoUTZs2BC5rXPnzoSGhrJx48bHHnP37l06duzIlClTcDgcpEuXjqZNmzJkyBDOnz9PunTpouzfp08f+vbtG+08hw4dwtvbO24/UByy2+3cuHEDX19fnJxMn+8u0dm3z4WvvkrO8uXGqAl3dwetW9+hU6dbpEoVs6+EemRt6o+1qT/Wpx5Zm/pjbeqP9alH1pZQ+nPz5k1y5szJjRs38PHxeeJ+pobugIAAKlasyPjx4yO3jRkzhi+//JIzZ8489diHDx9y4cIF/Pz8GDt2LJ988gnXr1+P1pTHXen29/fn2rVrT/3BmM1ut3Pp0iXSpElj6T9oCd369fDppzbWrbMB4OPj4MMPHXTpAsmTP/1Y9cja1B9rU3+sTz2yNvXH2tQf61OPrC2h9CcsLIyUKVM+M3SbOry8ZMmSHDx4MMq2Q4cOERAQ8MxjXV1dyfT/44F//vln3nrrrcc2xN3dHXd392jbnZycLN1AAJvNliDqTMhKlYI1a2DJEujZE3btsvHFFzZGjYJevYyJ2Nzcnny8emRt6o+1qT/Wpx5Zm/pjbeqP9alH1pYQ+hPT2kz9BN26dWPTpk0MHDiQI0eOMH36dMaOHUvHjh0j9+nZsyfNmzePfH7o0CGmTp3K4cOH2bJlC40aNWLPnj0MHDjQjI8giYDNBlWrwo4dMH06ZMsGFy/C++9DrlwwZQpERJhdpYiIiIiIJESmhu5ixYoxb948ZsyYQb58+ejfvz8hISE0adIkcp9z585x8uTJyOcREREMGzaMAgUKULFiRe7du8eGDRsIDAw04RNIYuLkBI0bw/79MGYMpE8Px49D8+ZQsCAsXAjm3YwhIiIiIiIJkanDywHeeust3nrrrSe+PmnSpCjPg4KC2LFjRzxXJUmZqyu0b2+E7ZEj4auvYM8eqFkTSpSAQYOgTBmzqxQRERERkYTAugPkRUyWLBl88gkcPQo9eoCnJ2zcCGXLwptvGsPRRUREREREnkahW+QZUqY0rm7//Te89x64uMDvv0PRok60b+/L4cNmVygiIiIiIlal0C0SQ35+MHq0cc/3228b2xYs8CRvXhvt28PZs+bWJyIiIiIi1qPQLRJL2bPDtGmwfbudChXuERFh44cfjFnPP/kErl41u0IREREREbEKhW6R51SgAEyZcp1Vq+yULAn37sGQIZA1KwwcCLdvm12hiIiIiIiYTaFb5AWVKgVr18KiRRAcDDduwGefGVe+v/sOHjwwu0IRERERETGLQrdIHLDZoFo12LkTpk6FLFngwgXo1Aly5zaGo9vtZlcpIiIiIiIvm0K3SBxycoImTeDAAeMqd7p0cOwYNG0KBQsaV8MdDrOrFBERERGRl0WhWyQeuLlBhw7GMmMDB4KvL+zeDdWr/zMcXUREREREEj+FbpF45OUFPXvC0aPGzOYeHrB+PZQu/c9wdBERERERSbwUukVeglSp4Kuv4MgRePddcHaGxYuhUCFjze8jR8yuUERERERE4oNCt8hLlDEjfP897N8PjRoZ22bMgKAgeO89OHvW3PpERERERCRuKXSLmCBHDiNsb98OVapAeLgRxrNnN4ajX7tmdoUiIiIiIhIXFLpFTFSoECxZAqtWQYkScPeuMQw9a1bjn3fumF2hiIiIiIi8CIVuEQsoU8aYYG3hQsiXD65fN654Z8sGY8bAw4dmVygiIiIiIs9DoVvEImw2Y0mxnTthyhQIDITz542lx4KCYPp0sNvNrlJERERERGJDoVvEYpydoWlTOHgQRo6EtGmN9b6bNIHChY1Zzx0Os6sUEREREZGYUOgWsSg3N+jUyQjcX34JPj7w11/G+t6lS8O6dWZXKCIiIiIiz6LQLWJxyZPDZ5/B0aPw0Ufg4WEE7lKljOHou3aZXaGIiIiIiDyJQrdIApE6NQwZAkeOQLt2xjD0RYugYEFjOPrRo2ZXKCIiIiIi/6XQLZLAZMwIP/wA+/ZBgwbG/d3TpkGuXNCxI5w7Z3aFIiIiIiLyiEK3SAKVMyfMnAnbtkHlyhAeDqNHQ/bs8OmnxrJjIiIiIiJiLoVukQSucGH4/XdYuRL+9z+4cwcGDYKsWY3h6HfumF2hiIiIiEjSpdAtkkiULQsbNsD8+ZAnD1y7Bp98Ylz5/uEHePjQ7ApFRERERJIehW6RRMRmg5o1jRnNJ0+GgADjHu/27Y0g/vPPYLebXaWIiIiISNKh0C2SCDk7Q/PmcPAgjBgBadIYs543bgxFisCSJcYEbCIiIiIiEr8UukUSMXd3eP99+Ptv6NcPvL1h506oWvWf4egiIiIiIhJ/FLpFkgBvb+jVy1jL+4MPjDC+Zg2ULAk1asDu3WZXKCIiIiKSOCl0iyQhr7wCX38Nhw/DO++AkxP8+isUKGAMRz92zOwKRUREREQSF4VukSTI3x/GjYO9e6FePeP+7ilTIFcuYzj6hQtmVygiIiIikjgodIskYblzw+zZEBoKFSsay4qNGmWs8f3553DjhtkVioiIiIgkbArdIkLRorBsGfz5JxQvDnfuwIABRvgeOhTu3jW7QhERERGRhEmhW0QivfEGbNoEc+dCUBBcvQoffww5chjD0cPDza5QRERERCRhUegWkShsNqhd25jRfOJEyJwZzpyBdu0gTx6YNQvsdrOrFBERERFJGBS6ReSxnJ2hZUs4dAhCQoyZzw8fhoYNjeHoS5caE7CJiIiIiMiTKXSLyFO5u0OXLsYa3337Gmt+79gBVar8MxxdREREREQeT6FbRGLE2xu++AL+/hu6dQM3N1i1CkqUgFq1jOXHREREREQkKoVuEYmVNGngm2+MoeatW4OTEyxYAMHB0KIFHD9udoUiIiIiItah0C0izyVzZpgwAfbsgbp1jfu7f/oJcuY0hqNfvGh2hSIiIiIi5lPoFpEXEhQEv/wCmzdD+fLw8CGMGGGs8f3FF3DjhtkVioiIiIiYR6FbROJE8eLwxx+wfLkxu/nt29C/P2TLBsOGwd27ZlcoIiIiIvLyKXSLSJyqUAG2bIE5cyB3brhyBT780Bh2Pn48hIebXaGIiIiIyMuj0C0icc5mgzp1YPdu475vf384fRratoV8+Yzh6FrjW0RERESSAoVuEYk3Li7GDOeHDhkznqdODQcPQv36UKyYMRRd4VtEREREEjOFbhGJdx4extreR49C796QPDls2waVKv0zHF1EREREJDFS6BaRl8bHB/r0McJ3167g5gYrVsCrrxrD0fftM7tCEREREZG4pdAtIi9dmjQwfLgx7LxlS3BygnnzIDgYWrWCEyfMrlBEREREJG4odIuIaQICYOJEY8K12rXBbodJk4yZzrt2hYsXza5QREREROTFKHSLiOny5IG5c2HTJihXDh48gG+/Ndb47tMHwsLMrlBERERE5PkodIuIZbz6Kvz5JyxbBkWKwK1b0LcvZM1qDEe/d8/sCkVEREREYkehW0QsxWaDihUhNBRmzzaGml+5At27G//+448QHm52lSIiIiIiMaPQLSKWZLNBvXqwdy+MHw+ZMsGpU9CmjTHh2pw5WuNbRERERKxPoVtELM3FxQjahw7B119DqlRw4IARyB8NRxcRERERsSqFbhFJEDw94YMPjDW+e/UCLy9jCHqFCsYjNNTsCkVEREREolPoFpEExdcX+vWDv/+Gzp3B1dW42l28uHH1+8ABsysUEREREfmHQreIJEjp0hnLih06BM2bG/eAz5kDefMaw9FPnjS7QhERERERhW4RSeACA2HyZNi1C2rWBLvdmOE8Vy4bvXt7c+mS2RWKiIiISFKm0C0iiUK+fDB/PmzcCGXKwIMHNsaO9SJHDht9+8LNm2ZXKCIiIiJJkUK3iCQq//sfrFwJixfbyZfvITdv2ujTB7JmNYaj379vdoUiIiIikpQodItIomOzQeXKsHTpFWbMsJMjB1y+DF27Qs6cMGkSRESYXaWIiIiIJAWmh+4zZ87QtGlTUqdOjaenJ8HBwWzduvWpx0ybNo0CBQqQLFky/Pz8aN26NVeuXHlJFYtIQuHkBA0awN69MHYsZMhgTLDWqhUEB8O8eeBwmF2liIiIiCRmpobua9euUbJkSVxdXVmyZAn79u1j2LBhpEyZ8onHrF+/nubNm9OmTRv27t3L7Nmz2bJlC23btn2JlYtIQuLqCm3bwpEjMHQopEwJ+/dDnTrGcPQVK8yuUEREREQSK1ND9+DBg/H392fixIkUL16cLFmyUKlSJbJly/bEYzZu3EhgYCCdO3cmS5YsvP7667z77rts2bLlJVYuIgmRpyd8+CEcPQqffQbJksGWLVC+PFSqBM8YZCMiIiIiEmsusT3g/v37bN68mRMnTnDnzh3SpElDoUKFyJIlS6zffOHChVSuXJn69euzevVqMmbMSIcOHZ561bpEiRJ8+umnLF68mDfffJOLFy/yyy+/ULVq1SfWe/9fMyeFhYUBYLfbsdvtsa75ZbHb7TgcDkvXmNSpR9b2tP74+EC/ftChAwwcaGPsWFi+3Mby5VC3roP+/R3kymVC0UmIvj/Wpx5Zm/pjbeqP9alH1pZQ+hPT+mwOR8zuaFy/fj3ffvstv/76Kw8fPsTX1xdPT0+uXr3K/fv3yZo1K+3ataN9+/Z4e3vH6M09PDwA6N69O/Xr1yc0NJQuXbrw/fff06JFiyceN3v2bFq3bs29e/cIDw+nevXqzJkzB1dX12j79unTh759+0bbfujQoRjXaQa73c6NGzfw9fXFycn0W+/lMdQja4tNf06edGbo0OTMmeOBw2HD2dlBw4Z3+eCDW2TIYO3/2CdU+v5Yn3pkbeqPtak/1qceWVtC6c/NmzfJmTMnN27cwMfH54n7xSh016hRg+3bt/P2229TvXp1ihYtiqenZ+TrR48eZe3atcyYMYO//vqLn376iYoVKz6zSDc3N4oWLcqGDRsit3Xu3JnQ0FA2btz42GP27dtHhQoV6NatG5UrV+bcuXN89NFHFCtWjAkTJkTb/3FXuv39/bl27dpTfzBms9vtXLp0iTRp0lj6D1pSph5Z2/P0Z/du+PxzG4sW2QBwd3fQsSP06OEgder4rDbp0ffH+tQja1N/rE39sT71yNoSSn/CwsJImTLlM0N3jIaXV6tW7YlXkgGyZs1K1qxZadGiBfv27ePcuXMxKtLPz488efJE2RYUFMScOXOeeMygQYMoWbIkH330EQD58+fHy8uLUqVK8eWXX+Ln5xdlf3d3d9zd3aOdx8nJydINBLDZbAmizqRMPbK22PanQAH49VfYsAF69oQ1a2x88w2MH2/jww+hWzdInjyei05C9P2xPvXI2tQfa1N/rE89sraE0J+Y1hajvd59990nBu7/ypMnD+XLl4/RviVLluTgwYNRth06dIiAgIAnHnPnzp1oH87Z2RmAGI6UFxF5qtdeg1WrYMkSKFgQwsLgiy8ga1YYMQL+NXhGREREROSpYv1rgxYtWrBmzZo4efNu3bqxadMmBg4cyJEjR5g+fTpjx46lY8eOkfv07NmT5s2bRz6vXr06c+fOZcyYMRw9epT169fTuXNnihcvToYMGeKkLhERmw2qVIFt22DGDMieHS5dgi5dIFcu+OkniIgwu0oRERERsbpYh+4bN25QoUIFcuTIwcCBAzlz5sxzv3mxYsWYN28eM2bMIF++fPTv35+QkBCaNGkSuc+5c+c4efJk5POWLVvyzTffMGrUKPLly0f9+vXJlSsXc+fOfe46RESexMkJGjWCffvg++/Bzw9OnIAWLYzh6AsWgAbZiIiIiMiTxHj28n+7dOkSU6ZMYfLkyZETm7Vp04aaNWvGeBi6WcLCwvD19X3mze5ms9vtXLx4kbRp01r6PoakTD2ytvjqz507MGoUfPUVXLtmbPvf/2DQIChbNs7eJtHT98f61CNrU3+sTf2xPvXI2hJKf2KaLZ/rE6RJk4bu3bvz119/sXnzZrJnz06zZs3IkCED3bp14/Dhw89duIiIlSVLBh9/DEePwqefGs83bYJy5Yzh6Nu3m12hiIiIiFjJC/3a4Ny5cyxfvpzly5fj7OxM1apV2b17N3ny5GH48OFxVaOIiOWkSAEDBsCRI9ChA7i4wNKlUKQINGwIhw6ZXaGIiIiIWEGsQ/fDhw+ZM2cOb731FgEBAcyePZuuXbty9uxZJk+ezB9//MGsWbPo169ffNQrImIpfn7w3Xdw4AA0aWJMwDZrFuTJA+3awenTZlcoIiIiImaKdej28/Ojbdu2BAQEsGXLFrZu3Ur79u2jjGEvV64cKVKkiMs6RUQsLVs2mDoVdu6Et94yZjYfNw5y5DCGo1+5YnaFIiIiImKGWIfu4cOHc/bsWb777jsKFiz42H1SpEjBsWPHXrQ2EZEEJ39++PVXWLsWXn8d7t2DoUONNb4HDIBbt8yuUERERERepliH7mbNmuHh4QHAqVOnOHXqVJwXJSKS0L3+OqxZA7/9ZgTxsDD4/HPjivioUfDggdkVioiIiMjLEOvQHR4eTq9evfD19SUwMJDAwEB8fX35/PPPefjwYXzUKCKSINlsULUq7NgB06cbV7svXoT334dcuWDKFGMYuoiIiIgkXrEO3e+//z5jx45lyJAh7Nixgx07djBkyBAmTJhA586d46NGEZEEzckJGjeG/fth9GhInx6OH4fmzaFgQVi4EBwOs6sUERERkfgQ69A9ffp0Jk2axLvvvkv+/PnJnz8/7777LhMmTGD69OnxUaOISKLg5gbvvWcsMzZokLHs2J49ULMmlCxpDEcXERERkcQl1qHb3d2dwMDAaNuzZMmCm5tbXNQkIpKoeXlBjx5w9KjxT09P2LgRypQxhqPv3Gl2hSIiIiISV2Idujt16kT//v25f/9+5Lb79+8zYMAAOnXqFKfFiYgkZilTGle8jxyB9u3BxQWWLIFChYzh6IcPm12hiIiIiLyoWIfuHTt2sGjRIjJlykSFChWoUKECmTJl4tdff+Wvv/6iTp06kQ8REXm2DBlgzBjjnu/GjY1tP/8MQUFGGD971tz6REREROT5ucT2gBQpUlC3bt0o2/z9/eOsIBGRpCp7dmOW848/hs8+g8WL4YcfYPJk6NwZPvkEUqUyu0oRERERiY1Yh+6JEyfGRx0iIvL/ChY01vdeuxZ69oT162HIECOAf/wxdOli3BcuIiIiItYX6+Hlj1y6dIl169axbt06Ll26FJc1iYgIUKqUEbx//RWCg+HGDeMKeLZsxtJjDx6YXaGIiIiIPEusQ/ft27dp3bo1fn5+lC5dmtKlS5MhQwbatGnDnTt34qNGEZEky2aDt96CHTtg6lTIkgUuXICOHY17vqdNA7vd7CpFRERE5EliHbq7d+/O6tWr+fXXX7l+/TrXr19nwYIFrF69mg8++CA+ahQRSfKcnaFJEzhwAL77DtKlM5Yca9rUmO180SJwOMyuUkRERET+K9ahe86cOUyYMIE333wTHx8ffHx8qFq1KuPGjeOXX36JjxpFROT/ublBhw7w998wYAD4+sKuXVC9+j/D0UVERETEOmIduu/cuUO6dOmibU+bNq2Gl4uIvCReXvDpp8bV7o8/Bg8PY8K10qWhWjX46y+zKxQREREReI7QXaJECXr37s29e/cit929e5e+fftSokSJOC1ORESeLlUqGDwYjhyBd981hqEvXmzMgN6kiXFFXERERETME+vQHRISwvr168mUKRPly5enfPny+Pv7s2HDBr799tv4qFFERJ4hY0b4/nvYvx8aNTK2TZ8OuXMbw9HPnTO3PhEREZGkKtahOzg4mMOHDzNo0CAKFixIwYIF+eqrrzh8+DB58+aNjxpFRCSGcuSAGTNg+3aoUgXCw2HMGGOZsZ494do1sysUERERSVpcYrPzw4cPyZ07N4sWLaJt27bxVZOIiLygQoVgyRJYvdoI2xs3wldfGVfDP/kEOneGZMnMrlJEREQk8YvVlW5XV9co93KLiIi1lSljTLC2YAHkywfXrxshPHt24wr4w4dmVygiIiKSuMV6eHnHjh0ZPHgw4eHh8VGPiIjEMZsNatSAnTvhp58gMNC4x7tDBwgKMoaj2+1mVykiIiKSOMVqeDlAaGgof/75J8uWLSM4OBgvL68or8+dOzfOihMRkbjj7AzNmkGDBjBuHPTvb8xu/vbbxgzoAwfCm28aIV1ERERE4kasr3SnSJGCunXrUrlyZTJkyICvr2+Uh4iIWJu7O3TqZATuL78EHx9jXe9q1f4Zji4iIiIicSPWV7onTpwYH3WIiMhLljw5fPYZtG9vTLI2ahSsXQuvvw5vvQUDBkD+/GZXKSIiIpKwxfpK9xtvvMH169ejbQ8LC+ONN96Ii5pEROQlSp0ahg6Fw4ehbVtjGPqiRVCwIDRtCkePml2hiIiISMIV69C9atUqHjx4EG37vXv3WLt2bZwUJSIiL1+mTDB2LOzbZ9z37XDAtGmQKxd07Ajnz5tdoYiIiEjCE+PQvWvXLnbt2gXAvn37Ip/v2rWLHTt2MGHCBDJmzBhvhYqIyMuRMyfMnAlbt0KlShAeDqNHQ7ZsxnD0xwx2EhEREZEniPE93QULFsRms2Gz2R47jNzT05ORI0fGaXEiImKeIkVg6VJYudJY23vzZmOG8zFjoEcPYzK2ZMnMrlJERETE2mJ8pfvYsWP8/fffOBwOtmzZwrFjxyIfZ86cISwsjNatW8dnrSIiYoJy5WDjRpg/H/LkgWvX4JNPIHt2+OEHePjQ7ApFRERErCvGoTsgIIDAwEDsdjtFixYlICAg8uHn54ezs3N81ikiIiay2aBmTdi1CyZNgoAAOHfOmPk8Tx74+Wew282uUkRERMR6Yr1kGMDhw4dZuXIlFy9exP6f/8v64osv4qQwERGxHmdnaNECGjUyrnJ/+SUcOQKNG8PgwTBoEFSubIR0EREREXmO0D1u3Djee+89XnnlFdKnT4/tX/9nZbPZFLpFRJIAd3fo3BlatYKQEGPJsZ074c03oXRpI3y/9prZVYqIiIiYL9ZLhn355ZcMGDCA8+fPs3PnTnbs2BH52L59e3zUKCIiFuXtDb16GWt5f/CBEcbXrIGSJY3h6Hv2mF2hiIiIiLliHbqvXbtG/fr146MWERFJoF55Bb7+Gg4fhnfeAScnWLgQ8ueH5s3h2DGzKxQRERExR6xDd/369Vm2bFl81CIiIgmcvz+MGwd790K9euBwwJQpkCsXvP8+XLhgdoUiIiIiL1es7+nOnj07vXr1YtOmTQQHB+Pq6hrl9c6dO8dZcSIikjDlzg2zZ8PWrfDpp7B8OYwaBRMnQteuxlB0ERERkaQg1qF77NixJE+enNWrV7N69eoor9lsNoVuERGJVLQoLFsGf/4JPXtCaCgMGABjxtjo1CkZH38MXl5mVykiIiISf2Iduo/pxjwREYml8uVh82aYPx8++wz277fRr58PEyY46N3bmAXd5bkWsRQRERGxtljf0y0iIvI8bDaoXRt274YJE+xkzBjBmTM22rWDvHlh1iyw282uUkRERCRuxTh058mTh6tXr0Y+79ChA5cvX458fvHiRZIlSxa31YmISKLj7AwtW8L69ZcYPtzOK6/AoUPQsCEUKwZLlxoTsImIiIgkBjEO3QcOHCA8PDzy+dSpUwkLC4t87nA4uHfvXtxWJyIiiZa7O3TubKzx3acPJE8O27dDlSrwxhuwaZPZFYqIiIi8uOceXu54zGUIm832QsWIiEjS4+0NvXsb4btbN3Bzg1WroEQJqFXLWH5MREREJKHSPd0iImIJadLAN9/A4cPQujU4OcGCBRAcbAxHP37c7ApFREREYi/Godtms0W7kq0r2yIiEtcyZ4YJE2DPHqhb17i/e/JkyJkTunSBixfNrlBEREQk5mK8QIvD4aB8+fK4/P+aLnfv3qV69eq4ubkBRLnfW0RE5EUFBcEvv8CWLfDpp8Za3yNGGIG8e3f44APw9TW7ShEREZGni3Ho7t27d5TnNWvWjLZP3bp1X7wiERGRfyleHP74w3j07Albt0L//jB6tPG8Y0fw8DC7ShEREZHHe+7QLSIi8jJVqADly8PcufDZZ3DwIHz4IYSEGLOft2gBLjH+W01ERETk5Yj1RGp3797lzp07kc9PnDhBSEgIy5Yti9PCRERE/stmM+7z3rPHGGaeKROcPg3vvAP58hnD0bXGt4iIiFhJrEN3zZo1+emnnwC4fv06xYsXZ9iwYdSsWZMxY8bEeYEiIiL/5eJizHB++LAx43nq1MaV7/r1jeHoy5crfIuIiIg1xDp0b9++nVKlSgHwyy+/kD59ek6cOMFPP/3EiBEj4rxAERGRJ/HwMNb2PnrUWOs7eXLjnu9KlYzh6Fu2mF2hiIiIJHWxDt137tzB29sbgGXLllGnTh2cnJz43//+x4kTJ+K8QBERkWfx8THu6/77b2NZMTc3WLECXn0V6tSBffvMrlBERESSqliH7uzZszN//nxOnTrF0qVLqVSpEgAXL17Ex8cnzgsUERGJqbRpjYnVDh2Cli3ByQnmzYPgYGjVCvS7YREREXnZYh26v/jiCz788EMCAwN59dVXKVGiBGBc9S5UqFCcFygiIhJbAQEwcSLs2gW1aoHdDpMmQc6cxnD0S5fMrlBERESSiliH7nr16nHy5Em2bt3K77//Hrm9fPnyDB8+PE6LExEReRF58xpXujduhHLl4MED40p41qzGcPSwMLMrFBERkcQu1qEbIH369BQqVAgnJyfCwsKYP38+3t7e5M6dO67rExEReWH/+x/8+ScsWwZFisCtW9C3rxG+hw+He/fMrlBEREQSq1iH7gYNGjBq1CjAWLO7aNGiNGjQgPz58zNnzpw4L1BERCQu2GxQsSKEhsLs2cZQ8ytXoHt3499//BHCw82uUkRERBKbWIfuNWvWRC4ZNm/ePBwOB9evX2fEiBF8+eWXsS7gzJkzNG3alNSpU+Pp6UlwcDBbt2594v4tW7bEZrNFe+TNmzfW7y0iIkmPzQb16sHevTBuHGTMCKdOQZs2xoRrc+dqjW8RERGJO7EO3Tdu3CBVqlQA/P7779StW5dkyZJRrVo1Dh8+HKtzXbt2jZIlS+Lq6sqSJUvYt28fw4YNI2XKlE885ttvv+XcuXORj1OnTpEqVSrq168f248iIiJJmIsLvPMOHD4MX38NqVLBgQNQt66x1Niff5pdoYiIiCQGsQ7d/v7+bNy4kdu3b/P7779HLhl27do1PDw8YnWuwYMH4+/vz8SJEylevDhZsmShUqVKZMuW7YnH+Pr6kj59+sjH1q1buXbtGq1atYrtRxEREcHTEz74AI4ehV69wMvLGIJeoYLxCA01u0IRERFJyFxie0DXrl1p0qQJyZMnJyAggLJlywLGsPPg4OBYnWvhwoVUrlyZ+vXrs3r1ajJmzEiHDh1o27ZtjM8xYcIEKlSoQEBAwGNfv3//Pvfv3498Hvb/U9Xa7Xbsdnus6n2Z7HY7DofD0jUmdeqRtak/1mbF/nh7GzOav/ceDBpk4/vv4c8/bRQvDnXqOOjf30FSmi/Uij2Sf6g/1qb+WJ96ZG0JpT8xrc/mcMT+zrWtW7dy6tQpKlasSPLkyQH47bffSJEiBSVLlozxeR5dGe/evTv169cnNDSULl268P3339OiRYtnHn/27FkyZ87M9OnTadCgwWP36dOnD3379o22/dChQ3h7e8e41pfNbrdz48YNfH19cXJ6rknmJZ6pR9am/lhbQujPqVPODB2anF9+8cDhsOHk5KBhw7t0736LTJms/T8BcSEh9CgpU3+sTf2xPvXI2hJKf27evEnOnDm5ceMGPj4+T9zvuUL3I48Otdlsz3W8m5sbRYsWZcOGDZHbOnfuTGhoKBs3bnzm8YMGDWLYsGGcPXsWNze3x+7zuCvd/v7+XLt27ak/GLPZ7XYuXbpEmjRpLP0HLSlTj6xN/bG2hNSfPXugVy8bCxcaf9e5uzt47z3o2dPBK6+YXFw8Skg9SorUH2tTf6xPPbK2hNKfsLAwUqZM+czQHevh5QA//fQTQ4cOjZw4LWfOnHz00Uc0a9YsVufx8/MjT548UbYFBQXFaOkxh8PBjz/+SLNmzZ4YuAHc3d1xd3ePtt3JycnSDQTjlxkJoc6kTD2yNvXH2hJKf/LnhwULYONG6NkTVq+2ERICEybY+PBD6NbNGJqeGCWUHiVV6o+1qT/Wpx5ZW0LoT0xri/Un+Oabb3jvvfeoWrUqs2bNYtasWVSpUoX27dszfPjwWJ2rZMmSHDx4MMq2Q4cOPfH+7H9bvXo1R44coU2bNrF6TxERkedRogSsXAm//w6FCsHNm9C7N2TLBt9+C/8aVCUiIiISKdahe+TIkYwZM4bBgwdTo0YNatSowZAhQxg9ejQjRoyI1bm6devGpk2bGDhwIEeOHGH69OmMHTuWjh07Ru7Ts2dPmjdvHu3YCRMm8Oqrr5IvX77YfgQREZHnYrNB5cqwdSvMnAk5csClS9C1K+TMCZMmQUSE2VWKiIiIlcQ6dJ87d47XXnst2vbXXnuNc+fOxepcxYoVY968ecyYMYN8+fLRv39/QkJCaNKkSZT3O3nyZJTjbty4wZw5c3SVW0RETOHkBA0awN69MHYsZMgAJ09Cq1bGcPR58+D5Z0wRERGRxCTWoTt79uzMmjUr2vaZM2eSI0eOWBfw1ltvsXv3bu7du8f+/fujLRc2adIkVq1aFWWbr68vd+7cidXSYiIiInHN1RXatoUjR2DIEEiZEvbtgzp14H//M4aji4iISNIW64nU+vbtS8OGDVmzZk3k8mDr16/nzz//fGwYFxERSew8PeGjj4wA/vXXMHw4bNkCb7wBFSvCoEFQpIjZVYqIiIgZYn2lu27dumzZsoVXXnmF+fPnM3/+fF555RW2bNlC7dq146NGERGRBCFFCvjyS/j7b+jUybgSvnw5FC1qDEf/z9yhIiIikgTEKnQ/fPiQ1q1bkzJlSqZOncq2bdvYtm0bU6dOpVChQvFVo4iISIKSPj2MHGmE7GbNjAnYZs+GvHmNq+GnT5tdoYiIiLwssQrdrq6uMVpDW0RERCBLFvjpJ/jrL6he3ZjZfPx4yJ4dPvwQrlwxu0IRERGJb7EeXl6rVi3mz58fD6WIiIgkTsHBsHAhrF8PpUoZa3oPGwZZs0L//nDrltkVioiISHyJ9URqOXLkoF+/fqxfv54iRYrg5eUV5fXOnTvHWXEiIiKJyWuvwerV8Pvv8OmnsHMnfPEFjBoFn38O7dqBu7vZVYqIiEhcinXonjBhAilSpIi8n/vfbDabQreIiMhT2Gzw5ptQuTLMmmWE7b//hs6djavf/fpBkybg7Gx2pSIiIhIXYh26jx07Fh91iIiIJClOTtCoEdStCz/+CH37wokT0KKFseb3gAFQo4YR0kVERCThitU93WFhYdjt9mjb7XY7YWFhcVaUiIhIUuHqCu++C0eOwODBxrJje/dCrVrGcPRVq0wuUERERF5IjEP3vHnzKFq0KPfu3Yv22t27dylWrBi//vprnBYnIiKSVCRLBh9/DEePQs+e4OkJmzZBuXJQpQps3252hSIiIvI8Yhy6x4wZw8cff0yyZMmivebl5cUnn3zCqFGj4rQ4ERGRpCZlShg40LjPu0MHcHGBpUuhSBFo2BAOHTK7QhEREYmNGIfuPXv2ULZs2Se+Xrp0aXbv3h0XNYmIiCR5fn7w3Xdw4IAxsZrNZky8liePMRz9zBmzKxQREZGYiHHovnbtGuHh4U98/eHDh1y7di1OihIRERFDtmwwdSrs2AHVqkFEBIwdC9mzG8PRr1wxu0IRERF5mhiH7sDAQLZu3frE17du3UpAQECcFCUiIiJRFSgAixbB2rXw+utw7x4MHQpZsxoznd+6ZXaFIiIi8jgxDt116tThs88+48KFC9FeO3/+PJ9//jl169aN0+JEREQkqtdfhzVr4LffIH9+CAsz1vrOnh1GjYIHD8yuUERERP4txqG7R48eeHt7kyNHDjp06MC3337Lt99+y3vvvUfOnDlJnjw5PXr0iM9aRUREBOP+7qpVjSHn06YZV7svXID334fcuY3h6BERZlcpIiIiEIvQ7e3tzfr162natCkzZ86kW7dudOvWjZkzZ9K0aVPWrVuHt7d3fNYqIiIi/+LkBG+/Dfv3w+jRkD49HDsGzZpBwYLw66/gcJhdpYiISNIW49AN4Ovry+jRo7l8+TIXLlzg/PnzXLlyhdGjR5MyZcr4qlFERESews0N3nsPjhyBQYMgRQrYswdq1PhnOLqIiIiYI1ah+xGbzUaaNGlImzYtNpstrmsSERGR5+DlBT16wNGjxj89PWHDBihTxhiOvnOn2RWKiIgkPTEK3VWqVGHTpk3P3O/mzZsMHjyY77777oULExERkeeTMqVxxfvIEWjfHlxcYMkSKFQIGjc2touIiMjLEaPQXb9+ferWrUuePHn45JNPmD17NuvXr2fbtm388ccfjBgxggYNGuDn58f27dupXr16fNctIiIiz5AhA4wZY9zz3bixse3nnyEoyAjjZ8+aW5+IiEhSEKPQ3aZNG44ePcqnn37Kvn37aNeuHaVKlaJYsWJUrlyZcePGkTlzZkJDQ5k5cyaZM2eO77pFREQkhrJnh+nTjdnOq1aF8HD44Qdje48ecO1a1P0jImDVKpg3z4NVqzQTuoiIyItwiemO7u7uNG3alKZNmwJw48YN7t69S+rUqXF1dY23AkVERCRuFCxorO+9Zg307Gnc7z14MHz/PXzyCXTuDEuXQpcucPq0E5ACgEyZ4NtvoU4dM6sXERFJmJ5rIjUwZjJPnz69AreIiEgCU7o0rFtnLCkWHAw3bsCnnxrhum5dOH066v5nzkC9ejB3rjn1ioiIJGTPHbpFREQk4bLZ4K23jCHnU6dCYCBcv/74fR+t9d21q4aai4iIxJZCt4iISBLm7AxNmsDYsU/fz+GAU6dg7dqXU5eIiEhiodAtIiIiXL4cs/127IjfOkRERBIbhW4RERHBzy9m+3XvDsWLQ0gInDsXryWJiIgkCrEO3adOneL0v2ZY2bJlC127dmXss8aliYiIiGWVKmVMpGazPXkfd3fj9dBQ6NYNMmaE8uVhwoToy46JiIiIIdah++2332blypUAnD9/nooVK7JlyxY+++wz+vXrF+cFioiISPxzdjaWBYPowdtmMx7TpxtXt0eOhBIljPu8V6yAd96B9Omhdm2YPRvu3n359YuIiFhVrEP3nj17KF68OACzZs0iX758bNiwgWnTpjFp0qS4rk9ERERekjp14JdfjCvY/5Ypk7G9Th1Ilw46dTLW+D56FAYOhLx54cEDmD8fGjSAtGmheXP4/Xd4+NCUjyIiImIZsQ7dDx8+xN3dHYA//viDGjVqAJA7d27O6eYuERGRBK1OHTh+HP78087o0df58087x44Z2/8rSxbo2RP27IFdu6BHDwgIgFu3YMoUePNNI8B37Ajr14Pd/tI/joiIiOliHbrz5s3L999/z9q1a1m+fDlVqlQB4OzZs6ROnTrOCxQREZGXy9kZypaF2rXvUbas8fxZgoNh0CA4dswI2B07Qpo0cOkSjB4Nr78OWbMaIX337vj+BCIiItYR69A9ePBgfvjhB8qWLUvjxo0pUKAAAAsXLowcdi4iIiJJk80Gr70Go0bBmTOwZIkx1Dx5cjhxAr76CvLnh3z5jKHpx46ZXbGIiEj8inXoLlu2LJcvX+by5cv8+OOPkdvbtWvH999/H6fFiYiISMLl6gpVqsDkyXDxIsyaBbVqgZsb7N0Ln31mXP0uUcKYnO3CBbMrFhERiXuxDt13797l/v37pEyZEoATJ04QEhLCwYMHSZs2bZwXKCIiIgmfpyfUrw/z5hnhesIEY7kxmw02bYLOnSFDBqhcGSZNghs3zK5YREQkbsQ6dNesWZOffvoJgOvXr/Pqq68ybNgwatWqxZgxY+K8QBEREUlcUqSA1q3hjz+MIeghIVC8uDHR2rJl0KqVMUt6vXowdy7cu2d2xSIiIs8v1qF7+/btlCpVCoBffvmFdOnSceLECX766SdGjBgR5wWKiIhI4uXnB126wObNcPgw9OsHuXPD/fswZw7UrWsE8FatYPlyCA83u2IREZHYiXXovnPnDt7e3gAsW7aMOnXq4OTkxP/+9z9OnDgR5wWKiIhI0pA9O/TqBfv2wY4d8NFHxhrhYWHGkPNKlYznXboYQ9IdDrMrFhERebZYh+7s2bMzf/58Tp06xdKlS6lUqRIAFy9exMfHJ84LFBERkaTFZoOCBWHIEGPG8zVroH17SJXKuB98xAhj8rXs2eHzz42QLiIiYlWxDt1ffPEFH374IYGBgRQvXpwSJUoAxlXvQoUKxXmBIiIiknQ5OUGpUjBmDJw7B4sWQZMm4OUFR4/CgAGQNy8UKACDBxshXURExEpiHbrr1avHyZMn2bp1K0uXLo3cXr58eYYPHx6nxYmIiIg84uYG1arB1KnGFe8ZM6B6dWNpsl27oEcPCAz8J6RfumR2xSIiIs8RugHSp09PoUKFOHv2LKdPnwagePHi5M6dO06LExEREXkcLy9o1AgWLoTz52HsWChb1hiavm4ddOhgTNJWtaoR0m/eNLtiERFJqmIduu12O/369cPX15eAgAACAgJIkSIF/fv3x263x0eNIiIiIk+UKhW0bQsrV8LJk/D111CkCEREwJIl0KyZMQN6w4awYIExM7qIiMjLEuvQ/dlnnzFq1Ci++uorduzYwY4dOxg4cCAjR46kV69e8VGjiIiISIxkygQffABbt8KBA9C7N+TIAXfvwqxZUKsWpE//T0iPiDC7YhERSexiHbonT57M+PHjee+998ifPz/58+enQ4cOjBs3jkmTJsVDiSIiIiKxlysX9OkDBw9CaCh07w4ZMsD16zB+PLzxBvj7G9tDQ7UEmYiIxI9Yh+6rV68+9t7t3Llzc/Xq1TgpSkRERCSu2GxQtCgMG2YMP1+xwrjSnSKFMSP68OFQvDjkzGlcGT9wwOyKRUQkMYl16C5QoACjRo2Ktn3UqFEUKFAgTooSERERiQ/OzlCunDHx2vnzxj3eDRuCpyccOQL9+kFQkHFP+Ndfw//PFysiIvLcXGJ7wJAhQ6hWrRp//PFH5BrdGzdu5NSpUyxevDjOCxQRERGJD+7uUKOG8bh1ywjg06fD0qWwfbvx+PhjKF0a3n4b6taF1KnNrlpERBKaWF/pLlOmDIcOHaJ27dpcv36d69evU6dOHQ4ePEipUqXio0YRERGReJU8OTRpAr/9ZlwBHzPGWO/b4YDVq+Hdd40J2KpXN9YHv33b7IpFRCShiPWVboAMGTIwYMCAKNtOnz5Nu3btGDt2bJwUJiIiImKGV16B9u2Nx8mT8PPPxhXwv/6CRYuMR7JkxkzojRtDpUrg5mZ21SIiYlWxvtL9JFeuXGHChAlxdToRERER02XObAwx37kT9u6Fzz+HrFnhzh0jiFevDn5+RkBfswbsdrMrFhERq4mz0C0iIiKSmOXJA/37GxOubdoEXbpAunRw9Sr88AOUKQMBAfDRR7Bjh5YgExERg0K3iIiISCzYbPDqqxASYsxuvnw5tGoFPj7G86+/hsKFo4Z0ERFJuhS6RURERJ6TiwtUqAA//ggXLsDcuVCvnjEz+oED8MUXkCOHsQ54SIixLriIiCQtMZ5IrU6dOk99/fr16y9ai4iIiEiC5eEBtWsbj7AwmDfPmOl8+XIIDTUe3bsb64S//TbUqQMpU5pdtYiIxLcYX+n29fV96iMgIIDmzZvHZ60iIiIiCYKPD7RoAb//DmfPwsiRUKKEcZ/3ihXwzjvGEmS1a8OsWcbEbCIikjjF+Er3xIkT47MOERERkUQpXTro1Ml4HDv2zxJke/bA/PnGI3lyI4A3bmwMV3d1NbtqERGJK7qnW0REROQlyZIFevaE3bth1y7j3wMC4NYtmDIFqlaFDBmgY0dYv15LkImIJAYK3SIiIiImCA6GgQONq9/r1xtBO00auHwZRo+G11831gTv0cMI6FqCTEQkYTI9dJ85c4amTZuSOnVqPD09CQ4OZuvWrU895v79+3z22WcEBATg7u5OYGAgP/7440uqWERERCTu2Gzw2mswapRx//fvv0Pz5saQ8xMnYPBgKFAgakgXEZGEw9TQfe3aNUqWLImrqytLlixh3759DBs2jJTPmMqzQYMG/Pnnn0yYMIGDBw8yY8YMcuXK9ZKqFhEREYkfLi5QuTJMngwXL8Ls2ca93m5usHcvfPaZcfW7ZEkbEyYk48IFsysWEZFnifFEavFh8ODB+Pv7R5mkLUuWLE895vfff2f16tUcPXqUVKlSARAYGBifZYqIiIi8dJ6exprf9erB9evGGuDTp8PKlbBpk41Nm3z44gsHFSoYE7DVrg2+vmZXLSIi/2Vq6F64cCGVK1emfv36rF69mowZM9KhQwfatm371GOKFi3KkCFDmDJlCl5eXtSoUYP+/fvj6ekZbf/79+9z//79yOdhYWEA2O127BaencRut+NwOCxdY1KnHlmb+mNt6o/1qUfW4uMDLVsaj3PnYOZMB1OnRrBjhxvLlsGyZdC+vYNq1aBxYwdVqxrrhos59P2xPvXI2hJKf2Jan6mh++jRo4wZM4bu3bvz6aefEhoaSufOnXFzc6NFixZPPGbdunV4eHgwb948Ll++TIcOHbhy5cpjlzUbNGgQffv2jbb90qVL3Lt3L84/U1yx2+3cuHEDh8OBk5Ppt97LY6hH1qb+WJv6Y33qkXU5O0OjRnbefPMGV6+mYuHCZMyd68mRIy7MnQtz59rw9rZTteo9ate+R8mSD3Ax9f/4kh59f6xPPbK2hNKfmzdvxmg/m8Nh3lyYbm5uFC1alA0bNkRu69y5M6GhoWzcuPGxx1SqVIm1a9dy/vx5fP9/DNXcuXOpV68et2/fjna1+3FXuv39/bl27Ro+Pj7x8Kniht1u59KlS6RJk8bSf9CSMvXI2tQfa1N/rE89srb/9sfhgL/+ghkzbMycCadO2SL3TZfOQYMG0KiRg1dfNSZuk/il74/1qUfWllD6ExYWRsqUKblx48ZTs6Wpv/f08/MjT548UbYFBQUxZ86cpx6TMWPGyMD96BiHw8Hp06fJkSNHlP3d3d1xd3ePdh4nJydLNxDAZrMliDqTMvXI2tQfa1N/rE89srb/9qdwYeMxeLCxBNn06cZEbBcu2Bg5EkaOtJE1q3H/d+PGkDevyR8gkdP3x/rUI2tLCP2JaW2mfoKSJUty8ODBKNsOHTpEQEDAU485e/Yst27dinKMk5MTmTJlirdaRURERBICJycoVQrGjDHu//7tN2jSBLy84OhRGDAA8uUzliEbPNhYlkxEROKPqaG7W7dubNq0iYEDB3LkyBGmT5/O2LFj6dixY+Q+PXv2pHnz5pHP3377bVKnTk2rVq3Yt28fa9as4aOPPqJ169aPnUhNREREJKlydYWqVWHqVLhwAWbMgBo1jO27dkGPHhAYCK+/DqNHw6VLZlcsIpL4mBq6ixUrxrx585gxYwb58uWjf//+hISE0KRJk8h9zp07x8mTJyOfJ0+enOXLl3P9+nWKFi1KkyZNqF69OiNGjDDjI4iIiIgkCF5e0KgRLFgA58/D2LFQtqxxj/f69dCxI/j5/RPSYzg/kIiIPIOpE6mZISwsDF9f32fe7G42u93OxYsXSZs2raXvY0jK1CNrU3+sTf2xPvXI2uKyP2fOwMyZxj3g27b9s93TE6pXh7ffhipV4DFT5MgT6PtjfeqRtSWU/sQ0W1r3E4iIiIhIvMuYEbp3h61b4cAB6N0bcuSAu3dh1iyoVQvSp4d33oEVKyAiwuyKRUQSFoVuEREREQEgVy7o0wcOHjRCePfukCEDXL8OEyZA+fLg729sDw2FpDVeUkTk+Sh0i4iIiEgUNhsUKQLDhsHJk7ByJbRtCylSGDOiDx8OxYtDzpzGlfEDB8yuWETEuhS6RUREROSJnJ2NCdfGjjUmYFuwABo2NO75PnIE+vWDoCAjpH/9NZw+bXbFIiLWotAtIiIiIjHi7m4sOfbzz3DxojHLedWq4OIC27fDRx9B5sz/hPQrV8yuWETEfArdIiIiIhJryZNDkybw22/GkPMxY6BUKeM+79Wr4d13jQnYqlc31ge/fdvsikVEzKHQLSIiIiIv5JVXoH17WLMGTpyAIUOgYEEID4dFi4xlx9KmNf65aBE8eGB2xSIiL49Ct4iIiIjEmcyZjWHmO3bA3r3w+eeQNSvcuWNc8a5eHfz8jJC+ejXY7WZXLCISvxS6RURERCRe5MkD/fsbE65t3gxdukC6dHD1Kvzwg3Hvd0DAPyFdS5CJSGKk0C0iIiIi8cpmM5YYCwmBM2dg+XJo3Rp8fY3Zzr/+GgoXNmZB79cPDh82u2IRkbij0C0iIiIiL42zM1SoABMmGEuQzZ0L9eoZM6MfPGis+50z5z8h/dw5sysWEXkxCt0iIiIiYgoPD6hdG2bPNpYgmzwZKlc2gnloKHTrBhkzQvnyRki/ds3sikVEYk+hW0RERERM5+MDzZvD778bQ9BHjoTXXjPu816xAt55x1iCrFYtmDXLmJhNRCQhUOgWEREREUtJlw46dYL16+HoURg4EIKDjaXGFiyAhg2NfZo3hyVL4OFDsysWEXkyhW4RERERsawsWaBnT9i1y3j07GnMeH7rFkyZAlWrQoYM0LGjEdK1BJmIWI1Ct4iIiIgkCMHBxlXvY8dgwwbjaniaNHD5MoweDa+/bqwJ3qOHEdC1BJmIWIFCt4iIiIgkKDYblChh3Pd99qxxH3jz5uDtDSdOwODBUKBA1JAuImIWhW4RERERSbBcXIwZzydPhgsXjJnQa9cGNzfYuxc++8y4+v0opF+4YHbFIpLUKHSLiIiISKLg6Wms+T13rhGuf/zRWBPcyQk2bYLOnY37vytVgkmT4MYNsysWkaRAoVtEREREEp0UKaBVK1i+HE6fhpAQKF7cmGht+XLjtXTpjJA+Zw7cu2d2xSKSWCl0i4iIiEii5ucHXbrA5s1w+DD07w+5c8P9+0bgrlfPCOCPQnp4uNkVi0hiotAtIiIiIklG9uzw+eewbx/s2AEffwz+/hAWZgw5r1QJMmY0hqJv2qQZ0EXkxSl0i4iIiEiSY7NBwYLGTOfHj8OaNdC+PaRODRcvGpOulSgB2bIZIX3vXrMrFpGESqFbRERERJI0JycoVQrGjIFz5+C336BJE/DyMpYbGzAA8uUzliEbPNhYlkxEJKYUukVERERE/p+rK1StClOnGjOg//wz1KhhbN+1C3r0gMBAeP11GD0aLl0yu2IRsTqFbhERERGRx/DygoYNYcECOH8exo6FcuWMoenr10PHjsYkbY9C+s2bZlcsIlak0C0iIiIi8gypUkHbtrBiBZw6BcOGQZEiEBEBS5ZAs2bGDOiPQvr9+2ZXLCJWodAtIiIiIhILGTNC9+6wdSscPAh9+kDOnHD3LsyaBXXqOFGgQFratrWxYoURzEUk6VLoFhERERF5TjlzQu/ecOCAEcK7d4cMGRzcuOHEjz/aKF/eWJKsWzcIDdUSZCJJkUK3iIiIiMgLstmM4ebDhsHx4w7mzLnKO+84SJnSmBE9JASKF48a0kUkaVDoFhERERGJQ87O8NprD/jhBwfnz8PChdCoEXh6wpEj0K8fBAVB4cLw9ddw+rTZFYtIfFLoFhERERGJJ25uUL06zJgBFy8as5xXrQouLrBjB3z0EWTODGXLwg8/wJUrZlcsInFNoVtERERE5CVInhyaNIHffjOGnI8ZA6VKGfd5r14N7dtD+vT/hPTbt82uWETigkK3iIiIiMhL9sorRsheswZOnIAhQ6BgQQgPh0WL4O23IW1a45+LFsGDB2ZXLCLPS6FbRERERMREmTMbw8x37IB9+6BXL8iWDe7cMa54V68Ofn5GSF+9Gux2sysWkdhQ6BYRERERsYigIGOitcOHYfNm6NIF0qWDq1eNe77LloWAgH9CupYgE7E+hW4REREREYux2YwlxkJC4MwZ+OMPaN0afH2N2c6//tqY/fzfIV1ErEmhW0RERETEwpydoXx5mDABzp+HuXOhfn3w8ICDB411v3Pm/CeknztndsUi8m8K3SIiIiIiCYSHB9SuDbNmwYULMHkyVK5sBPPQUOjWDTJm/CekX7tmdsUiotAtIiIiIpIA+fhA8+bw++9w9iyMGgWvvWbc571iBbzzjrEEWa1aRki/c8fsikWSJoVuEREREZEELm1a6NgR1q+Ho0dh4EAIDjaWGluwABo2NCZka9YMliyBhw/Nrlgk6VDoFhERERFJRLJkgZ49Ydcu49GzpzHj+a1bMHUqVK0KGTIYIX3dOi1BJhLfFLpFRERERBKp4GDjqvexY7BhA3TqBGnSwOXLMHo0lCplhPQePYyAriXIROKeQreIiIiISCJns0GJEjBypHH/99Kl0KIFeHvDyZMweDAUKGCE9AEDjCHqIhI3FLpFRERERJIQFxeoVAkmTTJmQJ8925gR3c0N9u6Fzz+HbNn+CekXLphdsUjCptAtIiIiIpJEeXpCvXrG2t8XLsCPP0KFCuDkBJs2QefOxv3fj0L6jRtmVyyS8Ch0i4iIiIgIKVJAq1awfDmcOQPffguvvmpMtLZ8ufFaunRGSJ8zB+7dM7tikYRBoVtERERERKJIn964yr1pExw5Av37Q1AQ3L9vBO569YwA/iikh4ebXbGIdSl0i4iIiIjIE2XLZtznvXcv7NwJH38M/v4QFmYMOa9UCTJm/CekawZ0kagUukVERERE5JlsNmOG88GD4fhxWLMG3nsPUqeGixeNSddKlDBC+mefGSFdRBS6RUREREQklpycjDW+R4+Gc+fgt9+gSRPw8jLWBB84EPLl+yeknzhhdsUi5lHoFhERERGR5+bqClWrwtSpxgzoP/8MNWoY23ftgh49IDAQXn/dCOmXLpldscjLpdAtIiIiIiJxwssLGjaEBQvg/HkYNw7KlTOGpq9fDx07gp8fvPkmTJkCN2+aXbFI/FPoFhERERGROJcqFbzzDqxYAadOwbBhULQoRETA779D8+aQNq0R0ufPN2ZGF0mMFLpFRERERCReZcwI3btDaCgcPAh9+kDOnMZa37NmQe3axjJlj0J6RITZFYvEHYVuERERERF5aXLmhN694cAB2LYNPvgAMmSA69dhwgQoX95YkqxbNyOkawkySegUukVERERE5KWz2aBwYfj6azh5ElauhLZtIWVKY0b0kBAoXjxqSBdJiBS6RURERETEVM7OULYsjB1rTMC2cCE0agSennDkCPTrB0FB/4T006fNrlgk5hS6RURERETEMtzcoHp1mDEDLl6EadOgWjVwcYEdO+CjjyBzZiOk//ADXLlidsUiT6fQLSIiIiIilpQ8Obz9NixaZAw5HzMGSpUy7vNevRratzcmYHsU0m/fNrtikehMD91nzpyhadOmpE6dGk9PT4KDg9m6desT91+1ahU2my3a4/z58y+xahEREREReZleecUI2WvWwIkTMGQIFCwI4eFGKH/7bWMJskch/cEDsysWMZgauq9du0bJkiVxdXVlyZIl7Nu3j2HDhpEyZcpnHnvw4EHOnTsX+UibNu1LqFhERERERMyWObMxzHzHDti3D3r1gmzZ4M4d44p39erg5wfvvmtcEbfbza5YkjIXM9988ODB+Pv7M3HixMhtWbJkidGxadOmJUWKFPFUmYiIiIiIJARBQcZEa337GkuMzZgBP/9sTMg2dqzxyJgRGjc2HoUKmV2xJDWmhu6FCxdSuXJl6tevz+rVq8mYMSMdOnSgbdu2zzy2YMGC3L9/n3z58tGnTx9Kliz52P3u37/P/fv3I5+HhYUBYLfbsVv4V152ux2Hw2HpGpM69cja1B9rU3+sTz2yNvXH2tQf8xQtajyGDIFVq2DGDBtz58KZMza+/tqY+TxXLgeNGjmoWNGJV15Rj6wooXyHYlqfzeEwb7l5Dw8PALp37079+vUJDQ2lS5cufP/997Ro0eKxxxw8eJBVq1ZRtGhR7t+/z/jx45kyZQqbN2+mcOHC0fbv06cPffv2jbb90KFDeHt7x+0HikN2u50bN27g6+uLk5Ppt97LY6hH1qb+WJv6Y33qkbWpP9am/ljL/fuwYoU78+Z5sHy5B/fu2SJfK1DgAbVr36NmzXukT2/tgJeUJJTv0M2bN8mZMyc3btzAx8fnifuZGrrd3NwoWrQoGzZsiNzWuXNnQkND2bhxY4zPU6ZMGTJnzsyUKVOivfa4K93+/v5cu3btqT8Ys9ntdi5dukSaNGks/QctKVOPrE39sTb1x/rUI2tTf6xN/bGusDCYP98Yfv7HHzYiIowAbrM5KFcOGjZ0ULcuxGCKKYlHCeU7FBYWRsqUKZ8Zuk0dXu7n50eePHmibAsKCmLOnDmxOk/x4sVZt27dY19zd3fH3d092nYnJydLNxDAZrMliDqTMvXI2tQfa1N/rE89sjb1x9rUH2tKkQJatoTmze3s23eJVateYcYMJzZssLFiBaxYYaNTJ6ha1ZgF/a23IFkys6tOmhLCdyimtZn6CUqWLMnBgwejbDt06BABAQGxOs/OnTvx8/OLy9JERERERCQRe+UVOx06wPr1cOwYDBoEwcHw8CEsWAANG0K6dNCsGSxZYmwXeR6mhu5u3bqxadMmBg4cyJEjR5g+fTpjx46lY8eOkfv07NmT5s2bRz4PCQlhwYIFHDlyhD179tC1a1dWrFgR5RgREREREZGYCgyEHj1g1y7j0bOnse3WLZg61bjynSEDdOwI69ZpCTKJHVNDd7FixZg3bx4zZswgX7589O/fn5CQEJo0aRK5z7lz5zh58mTk8wcPHvDBBx8QHBxMmTJl+Ouvv/jjjz8oX768GR9BREREREQSkeBgGDgQjh6FDRugUydIkwYuX4bRo6FUKciS5Z+Qbt4MWZJQmDqRmhnCwsLw9fV95s3uZrPb7Vy8eJG0adNa+j6GpEw9sjb1x9rUH+tTj6xN/bE29cf6Ytuj8HBYsQKmT4e5c+HmzX9ey5v3nzXAs2aNx6KTkITyHYpptrTuJxAREREREbEAFxeoVAkmTYILF+CXX6BOHXBzg7174fPPIVs2KFECRoyA8+fNrlisRKFbREREREQkhjw9oW5dmDPHCOA//ggVKoCTE2zaBF26QMaM/4T0GzfMrljMptAtIiIiIiLyHFKkgFatYPlyOHMGvv0WXn3VmGht+XLjtXTp/gnp9+6ZXbGYQaFbRERERETkBaVPD507G1e7jxyBL7+EoCC4f9+4D7xePSOAt2oFy5YZ94lL0qDQLSIiIiIiEoeyZYPPPjPu9965Ez7+GPz9ISzMGHJeubIxBP1RSE9aU1snPQrdIiIiIiIi8cBmgwIFYPBgOH4c1q6F996D1Knh4kUYOdKYfO3fIV0SH4VuERERERGReObkBK+/bqz1fe4c/PYbNG0KXl5w7JixNni+fP+E9BMnzK5Y4opCt4iIiIiIyEvk6gpVq8KUKcYV759/hho1jO27dkGPHhAY+E9Iv3TJ7IrlRSh0i4iIiIiImCRZMmjYEBYsMNb3HjcOypUzhqavXw8dO4KfH7z5phHSb940u2KJLYVuERERERERC0iVCt55B1asgFOn4JtvoGhRiIiA33+H5s0hbVojpM+fb8yMLtan0C0iIiIiImIxGTNCt24QGgoHD0KfPpAzp7HW96xZULu2sUzZo5AeEWF2xfIkCt0iIiIiIiIWljMn9O4NBw7Atm3wwQdGKL9+HSZMgPLljSXJHoV0LUFmLQrdIiIiIiIiCYDNBoULw9dfw8mTsGoVtGsHKVMaM6KHhEDx4kZI/+ILI6SL+RS6RUREREREEhgnJyhTBn74wZiAbeFCaNTImJjtyBHo3x+Cgv4J6adOmV1x0qXQLSIiIiIikoC5uUH16jBjBly4ANOmQbVq4OICO3bARx9B5sz/hPQrV8yuOGlR6BYREREREUkkkieHt9+GRYuMIefffw+lSxuvrVkD7dsbE7BVrw7Tp8OtW+bWmxQodIuIiIiIiCRCr7wC774Lq1cb94APGQIFC0J4uBHKmzSBdOn+CekPHphdceKk0C0iIiIiIpLI+fsbw8x37IB9+6BXL8iWDe7cMYalV68Ofn7/hHS73eyKEw+FbhERERERkSQkKAj69YPDh2HzZuja1RhyfvUqjB0LZcsa94B/9BFs364lyF6UQreIiIiIiEgSZLMZS4wNHw6nT8Mff0CbNuDrC2fOGLOeFykSNaRL7Cl0i4iIiIiIJHHOzlC+PIwfb8yAPm8e1K8PHh5w8CD07m2s/12smBHSz541u+KEQ6FbREREREREIrm7Q61aMGuWEcB/+gmqVDGC+dat0L07ZMr0T0i/ds3siq1NoVtEREREREQey8cHmjWDJUuMq9ujRkHJksZ93itWQNu2xgzotWrBzJnGxGwSlUK3iIiIiIiIPFPatNCxI6xbB8eOwaBBEBwMDx/CggXQqJERwB+F9IcPza7YGhS6RUREREREJFYCA6FHD9i1C3bvhk8/NbbdugVTp0LVqpAhA3ToYIT0pLwEmUK3iIiIiIiIPLd8+WDAADh6FDZsgE6djKvily/DmDFQqhRkyWKE9L/+evoSZBERsGoVzJvnwapVxvOETqFbREREREREXpjNBiVKwMiRxpJjS5dCixbg7Q0nT8LgwVCwYNSQ/m9z5xpXy8uXd6JDhxSUL+9EYKCxPSFT6BYREREREZE45eIClSrBpEnGDOi//AJ16oCbG+zbB59/DtmyGSF9xAiYMAHq1TPWC/+3M2eM7Qk5eLuYXYCIiIiIiIgkXp6eULeu8bh+3VgDfMYM+PNP2LTJeDyJw2FcQe/aFWrWNJYtS2h0pVtEREREREReihQpoFUrWLbMuIr97bcQFPT0YxwOOHUK1q59KSXGOV3pFhERERERkZcufXro3BnSpIG33372/ufOxX9N8UFXukVERERERMQ0fn5xu5/VKHSLiIiIiIiIaUqVgkyZjHu3H8dmA39/Y7+ESKFbRERERERETOPsbNzbDdGD96PnISEJcxI1UOgWERERERERk9WpYywrljFj1O2ZMv2z3FhCpYnURERERERExHR16hjLgq1ebefgwTBy5fKhTBmnBHuF+xGFbhEREREREbEEZ2coWxby5LlH2rQ+OCWCsdmJ4COIiIiIiIiIWJNCt4iIiIiIiEg8UegWERERERERiScK3SIiIiIiIiLxRKFbREREREREJJ4odIuIiIiIiIjEE4VuERERERERkXii0C0iIiIiIiISTxS6RUREREREROKJQreIiIiIiIhIPFHoFhEREREREYknLmYX8LI5HA4AwsLCTK7k6ex2Ozdv3sTDwwMnJ/1uxIrUI2tTf6xN/bE+9cja1B9rU3+sTz2ytoTSn0eZ8lHGfJIkF7pv3rwJgL+/v8mViIiIiIiISEJ38+ZNfH19n/i6zfGsWJ7I2O12zp49i7e3NzabzexynigsLAx/f39OnTqFj4+P2eXIY6hH1qb+WJv6Y33qkbWpP9am/lifemRtCaU/DoeDmzdvkiFDhqdekU9yV7qdnJzIlCmT2WXEmI+Pj6X/oIl6ZHXqj7WpP9anHlmb+mNt6o/1qUfWlhD687Qr3I9Yd4C8iIiIiIiISAKn0C0iIiIiIiISTxS6Lcrd3Z3evXvj7u5udinyBOqRtak/1qb+WJ96ZG3qj7WpP9anHllbYutPkptITURERERERORl0ZVuERERERERkXii0C0iIiIiIiISTxS6RUREREREROKJQvdLsGbNGqpXr06GDBmw2WzMnz//mcesWrWKwoUL4+7uTvbs2Zk0aVK0fb777jsCAwPx8PDg1VdfZcuWLXFffBIR2x7NnTuXihUrkiZNGnx8fChRogRLly6Nsk+fPn2w2WxRHrlz547HT5F4xbY/q1ativazt9lsnD9/Psp++g7Fndj2qGXLlo/tUd68eSP30XcobgwaNIhixYrh7e1N2rRpqVWrFgcPHnzmcbNnzyZ37tx4eHgQHBzM4sWLo7zucDj44osv8PPzw9PTkwoVKnD48OH4+hiJ2vP0aNy4cZQqVYqUKVOSMmVKKlSoEO2/YY/7nlWpUiU+P0qi9Dz9mTRpUrSfvYeHR5R99B2KO8/To7Jlyz7276Fq1apF7qPvUNwYM2YM+fPnj1xzu0SJEixZsuSpxyS2v4MUul+C27dvU6BAAb777rsY7X/s2DGqVatGuXLl2LlzJ127duWdd96JEupmzpxJ9+7d6d27N9u3b6dAgQJUrlyZixcvxtfHSNRi26M1a9ZQsWJFFi9ezLZt2yhXrhzVq1dnx44dUfbLmzcv586di3ysW7cuPspP9GLbn0cOHjwY5eefNm3ayNf0HYpbse3Rt99+G6U3p06dIlWqVNSvXz/KfvoOvbjVq1fTsWNHNm3axPLly3n48CGVKlXi9u3bTzxmw4YNNG7cmDZt2rBjxw5q1apFrVq12LNnT+Q+Q4YMYcSIEXz//fds3rwZLy8vKleuzL17917Gx0pUnqdHq1atonHjxqxcuZKNGzfi7+9PpUqVOHPmTJT9qlSpEuU7NGPGjPj+OInO8/QHwMfHJ8rP/sSJE1Fe13co7jxPj+bOnRulP3v27MHZ2Tna30P6Dr24TJky8dVXX7Ft2za2bt3KG2+8Qc2aNdm7d+9j90+Ufwc55KUCHPPmzXvqPh9//LEjb968UbY1bNjQUbly5cjnxYsXd3Ts2DHyeUREhCNDhgyOQYMGxWm9SVFMevQ4efLkcfTt2zfyee/evR0FChSIu8LE4XDErD8rV650AI5r1649cR99h+LP83yH5s2b57DZbI7jx49HbtN3KH5cvHjRAThWr179xH0aNGjgqFatWpRtr776quPdd991OBwOh91ud6RPn94xdOjQyNevX7/ucHd3d8yYMSN+Ck9CYtKj/woPD3d4e3s7Jk+eHLmtRYsWjpo1a8ZDhUlbTPozceJEh6+v7xNf13cofj3Pd2j48OEOb29vx61btyK36TsUf1KmTOkYP378Y19LjH8H6Uq3BW3cuJEKFSpE2Va5cmU2btwIwIMHD9i2bVuUfZycnKhQoULkPvJy2e12bt68SapUqaJsP3z4MBkyZCBr1qw0adKEkydPmlRh0lSwYEH8/PyoWLEi69evj9yu75D1TJgwgQoVKhAQEBBlu75Dce/GjRsA0f579W/P+nvo2LFjnD9/Pso+vr6+vPrqq/oOxYGY9Oi/7ty5w8OHD6Mds2rVKtKmTUuuXLl47733uHLlSpzWmhTFtD+3bt0iICAAf3//aFf19B2KX8/zHZowYQKNGjXCy8srynZ9h+JWREQEP//8M7dv36ZEiRL/1979x1Rd/XEcf12Fi6AZGna5WV/CXwxNLDUItWnRCtxaNpu6IUPLHCVOt2wyl1NGW7gxXWtGPyZaaTDQIa4STQz+YJktUbDQpbGWIzRrJviDP7jv7x+Ou66i6e1eQHg+tjvuPZ/3/XDOPXvfc9/3cz/3dhnTF9cgiu5eqKWlRS6Xy6fN5XLp4sWLunLlis6fP6+Ojo4uY64/ZxXdo6CgQG1tbZo3b563LSkpSdu2bVNlZaUKCwvV1NSkJ598Uq2trT3Y0/7B7Xbrgw8+0K5du7Rr1y499NBDmjVrlo4cOSJJ5FAv09zcrL1792rJkiU+7eRQ4Hk8Hq1cuVLTp0/XI488ctO4m61DnfnR+ZccCrzbnaPrrV69Wg888IDPi9DU1FR9+umnqqqq0oYNG1RTU6O0tDR1dHQEo+v9wu3OT1xcnIqKilRRUaHt27fL4/Fo2rRpOnPmjCRyKJj8yaHDhw/r+PHjN6xD5FDgNDQ0aMiQIQoLC1NWVpbKy8s1fvz4LmP74hoU0tMdAO52n3/+uXJzc1VRUeFzznBaWpr3ekJCgpKSkhQTE6PS0lK98sorPdHVfiMuLk5xcXHe29OmTdPp06e1adMmffbZZz3YM3Tlk08+UWRkpObMmePTTg4F3rJly3T8+HHOje/F/Jmj/Px8lZSUqLq62ufLuhYsWOC9PnHiRCUkJGj06NGqrq5WSkpKQPvdX9zu/CQnJ/scxZs2bZri4+P14YcfKi8vL9jd7Nf8yaEtW7Zo4sSJSkxM9GknhwInLi5OR48e1d9//62dO3cqMzNTNTU1Ny28+xqOdPdC0dHROnv2rE/b2bNnNXToUIWHhysqKkoDBw7sMiY6Oro7u9rvlZSUaMmSJSotLb3hYzDXi4yM1Lhx43Tq1Klu6h3+KTEx0fvYk0O9h5mpqKhIGRkZcjqdt4wlh/6b7OxsffHFF/rmm2/04IMP3jL2ZutQZ350/iWHAutO5qhTQUGB8vPztX//fiUkJNwydtSoUYqKiiKH/OTP/HQKDQ3VY4895n3syaHg8GeOLl26pJKSktt6M5cc8p/T6dSYMWM0ZcoUvfPOO5o0aZLefffdLmP74hpE0d0LJScnq6qqyqft66+/9r5j6nQ6NWXKFJ8Yj8ejqqqqm54bgcArLi7W4sWLVVxc7PPzEjfT1tam06dPy+12d0PvcL2jR496H3tyqPeoqanRqVOnbuvFDjnkHzNTdna2ysvLdfDgQcXGxv7rff5tHYqNjVV0dLRPzMWLF/Xdd9+RQ37wZ46ka9/em5eXp8rKSk2dOvVf48+cOaM///yTHLpD/s7PP3V0dKihocH72JNDgfVf5qisrEzt7e1auHDhv8aSQ4Hj8XjU3t7e5bY+uQb16Ne49ROtra1WV1dndXV1Jsk2btxodXV19uuvv5qZWU5OjmVkZHjjf/nlF4uIiLA333zTGhsbbfPmzTZw4ECrrKz0xpSUlFhYWJht27bNfvrpJ1u6dKlFRkZaS0tLt4+vL7jTOdqxY4eFhITY5s2b7ffff/deLly44I154403rLq62pqamqy2ttaeeeYZi4qKsnPnznX7+O52dzo/mzZtst27d9vPP/9sDQ0NtmLFChswYIAdOHDAG0MOBdadzlGnhQsXWlJSUpf7JIcC47XXXrN7773XqqurfZ6vLl++7I3JyMiwnJwc7+3a2loLCQmxgoICa2xstHXr1lloaKg1NDR4Y/Lz8y0yMtIqKiqsvr7eXnjhBYuNjbUrV6506/j6An/mKD8/35xOp+3cudPnPq2trWZ2LSdXrVpl3377rTU1NdmBAwds8uTJNnbsWLt69Wq3j/Fu5s/85Obm2r59++z06dP2ww8/2IIFC2zQoEH2448/emPIocDxZ446zZgxw+bPn39DOzkUODk5OVZTU2NNTU1WX19vOTk55nA4bP/+/WbWP9Ygiu5u0PnzRddfMjMzzezazxHMnDnzhvs8+uij5nQ6bdSoUbZ169Yb9vvee+/Z//73P3M6nZaYmGiHDh0K/mD6qDudo5kzZ94y3uzaz7y53W5zOp02cuRImz9/vp06dap7B9ZH3On8bNiwwUaPHm2DBg2y4cOH26xZs+zgwYM37JccChx/nucuXLhg4eHh9tFHH3W5T3IoMLqaF0k+68rMmTN9nr/MzEpLS23cuHHmdDptwoQJ9uWXX/ps93g8tnbtWnO5XBYWFmYpKSl28uTJbhhR3+PPHMXExHR5n3Xr1pmZ2eXLl+3ZZ5+1ESNGWGhoqMXExNirr77KG4t+8Gd+Vq5c6V1fXC6XzZ49244cOeKzX3IocPx9njtx4oRJ8hZ//0QOBc7LL79sMTEx5nQ6bcSIEZaSkuLzmPeHNchhZhagg+YAAAAAAOAfOKcbAAAAAIAgoegGAAAAACBIKLoBAAAAAAgSim4AAAAAAIKEohsAAAAAgCCh6AYAAAAAIEgougEAAAAACBKKbgAAAAAAgoSiGwAABIzD4dDu3bt7uhsAAPQaFN0AAPQRixYtksPhuOGSmpra010DAKDfCunpDgAAgMBJTU3V1q1bfdrCwsJ6qDcAAIAj3QAA9CFhYWGKjo72uQwbNkzStY9+FxYWKi0tTeHh4Ro1apR27tzpc/+GhgY9/fTTCg8P13333aelS5eqra3NJ6aoqEgTJkxQWFiY3G63srOzfbafP39eL774oiIiIjR27Fjt2bMnuIMGAKAXo+gGAKAfWbt2rebOnatjx44pPT1dCxYsUGNjoyTp0qVLeu655zRs2DB9//33Kisr04EDB3yK6sLCQi1btkxLly5VQ0OD9uzZozFjxvj8j9zcXM2bN0/19fWaPXu20tPT9ddff3XrOAEA6C0cZmY93QkAAPDfLVq0SNu3b9egQYN82tesWaM1a9bI4XAoKytLhYWF3m1PPPGEJk+erPfff18ff/yxVq9erd9++02DBw+WJH311Vd6/vnn1dzcLJfLpZEjR2rx4sV6++23u+yDw+HQW2+9pby8PEnXCvkhQ4Zo7969nFsOAOiXOKcbAIA+5KmnnvIpqiVp+PDh3uvJyck+25KTk3X06FFJUmNjoyZNmuQtuCVp+vTp8ng8OnnypBwOh5qbm5WSknLLPiQkJHivDx48WEOHDtW5c+f8HRIAAHc1im4AAPqQwYMH3/Bx70AJDw+/rbjQ0FCf2w6HQx6PJxhdAgCg1+OcbgAA+pFDhw7dcDs+Pl6SFB8fr2PHjunSpUve7bW1tRowYIDi4uJ0zz336OGHH1ZVVVW39hkAgLsZR7oBAOhD2tvb1dLS4tMWEhKiqKgoSVJZWZmmTp2qGTNmaMeOHTp8+LC2bNkiSUpPT9e6deuUmZmp9evX648//tDy5cuVkZEhl8slSVq/fr2ysrJ0//33Ky0tTa2traqtrdXy5cu7d6AAANwlKLoBAOhDKisr5Xa7fdri4uJ04sQJSde+WbykpESvv/663G63iouLNX78eElSRESE9u3bpxUrVujxxx9XRESE5s6dq40bN3r3lZmZqatXr2rTpk1atWqVoqKi9NJLL3XfAAEAuMvw7eUAAPQTDodD5eXlmjNnTk93BQCAfoNzugEAAAAACBKKbgAAAAAAgoRzugEA6Cc4owwAgO7HkW4AAAAAAIKEohsAAAAAgCCh6AYAAAAAIEgougEAAAAACBKKbgAAAAAAgoSiGwAAAACAIKHoBgAAAAAgSCi6AQAAAAAIEopuAAAAAACC5P/wh6NpablA+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: models/sequential_recommender/training_history.png\n"
     ]
    }
   ],
   "source": [
    "# Visualization: Training Loss Curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(history['train_loss']) + 1), history['train_loss'], 'b-o', label='Train Loss')\n",
    "plt.plot(range(1, len(history['val_loss']) + 1), history['val_loss'], 'r-o', label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (CrossEntropy)')\n",
    "plt.title('SASRec Training History')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history.png'), dpi=150)\n",
    "plt.show()\n",
    "print(f\"Saved: {OUTPUT_DIR}/training_history.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07f7f64e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "executionInfo": {
     "elapsed": 4918,
     "status": "ok",
     "timestamp": 1766481260041,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "07f7f64e",
    "outputId": "7fbfbd8c-740e-41b4-d802-b4be335319aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating visualization model...\n",
      "Transferring trained weights...\n",
      "Success! Weights transferred.\n",
      "Visualizing...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAMPCAYAAABFeTOzAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAwYVJREFUeJzs3Xt8z/X///H7e7MDNoyxjeR8yGGmDTlHDkVKJKUiSUgpPn0qOaucyjEl5JRySEk+HZxGX5+icoqUsxkxbMIwNttevz/6eP/2bvNu75k93/O+XT+X1+XT+/l6vZ/Pxzbp/djz+Xg+bZZlWQIAAACAbPAyHQAAAACA/IMEAgAAAEC2kUAAAAAAyDYSCAAAAADZRgIBAAAAINtIIAAAAABkGwkEAAAAgGwjgQAAAACQbSQQAAAAALKNBAKAW7PZbBo5cqTpMHADjh07Jn9/f/3www+mQzHutddeU4MGDUyHAQA3hAQCuIW9//77stls1/3A8vvvv2vkyJE6cuRIlu+dP3/+zQ3wf7755hu3SxJGjhwpm82mhISELO+XL19e999//02NYdGiRZoyZcpNHSMvjB49Wg0aNFDjxo3tbU899ZQCAgIMRpX7Vq5cqTvvvFP+/v66/fbbNWLECKWmpjo889JLL2nnzp1auXKloSgB4MaRQAC3sE8++UTly5fXzz//rIMHD2a6//vvv2vUqFFukUCMGjUqy3uXL1/W0KFD8yQOd3MrJBDx8fFasGCB+vbtazqUm+rbb79Vx44dVaxYMb377rvq2LGj3nzzTb3wwgsOz4WGhurBBx/UO++8YyhSALhxJBDALSomJkabNm3SpEmTVLJkSX3yySemQ8oRf39/FShQwHQYyKGPP/5YBQoUUIcOHUyHckOuXLmi9PT0695/+eWXFR4erjVr1qh3796aNm2aBg8erJkzZ2rv3r0Ozz7yyCP6/vvvdfjw4ZsdNgDcFCQQwC3qk08+UVBQkNq3b6+HH344UwIxf/58denSRZLUokUL2Ww22Ww2fffddypfvrx+++03/d///Z+9/e6777a/99y5c3rppZdUtmxZ+fn5qXLlyho/frzDB6wjR47IZrPpnXfe0axZs1SpUiX5+fmpXr162rJli/25p556Su+9954k2cey2Wz2+1nVQOzYsUP33XefihQpooCAAN1zzz368ccfM319NptNP/zwgwYNGqSSJUuqcOHCeuihhxQfH39D39vrSU9P15QpU1SzZk35+/srJCREffr00dmzZx2e+/LLL9W+fXuVLl1afn5+qlSpkt544w2lpaXZn7n77rv19ddfKzY21v49KV++vCTpu+++k81m06effqpRo0apTJkyCgwM1MMPP6zz588rOTlZL730kkqVKqWAgAD17NlTycnJDjHMmzdPLVu2VKlSpeTn56caNWpoxowZmb6ma0u11qxZo4iICPn7+6tGjRpavnx5tr4nK1asUIMGDXK0XCk2NlbPPfecqlWrpoIFC6pEiRLq0qWLw4zZ4cOHZbPZNHny5Ezv37Rpk2w2mxYvXmxvO378uJ5++mmFhITIz89PNWvW1Ny5cx3ed+37u2TJEg0dOlRlypRRoUKFlJiYmGWcv//+u37//Xc9++yzDsnuc889J8uy9Nlnnzk836pVK0l//TkAgPyIX+sBt6hPPvlEnTp1kq+vrx577DHNmDFDW7ZsUb169SRJzZo104ABAzRt2jS9/vrruuOOOyRJd9xxh6ZMmaIXXnhBAQEBGjJkiCQpJCREkpSUlKTmzZvr+PHj6tOnj26//XZt2rRJgwcPVlxcXKYlN4sWLdKFCxfUp08f2Ww2TZgwQZ06ddLhw4fl4+OjPn366MSJE1q7dq0WLlz4j1/Xb7/9pqZNm6pIkSJ65ZVX5OPjo5kzZ+ruu+/W//3f/2Wq93jhhRcUFBSkESNG6MiRI5oyZYqef/55LV26NFvfxz///DPL9qx+G92nTx/Nnz9fPXv21IABAxQTE6Pp06drx44d+uGHH+Tj4yPpr+QmICBAgwYNUkBAgNavX6/hw4crMTFRb7/9tiRpyJAhOn/+vP744w/7h+O/fwgfO3asChYsqNdee00HDx7Uu+++Kx8fH3l5eens2bMaOXKkfvzxR82fP18VKlTQ8OHD7e+dMWOGatasqQceeEAFChTQf/7zHz333HNKT09X//79HcY5cOCAunbtqr59+6pHjx6aN2+eunTpolWrVql169bX/d5dvXpVW7ZsUb9+/bLxnc5sy5Yt2rRpkx599FHddtttOnLkiGbMmKG7775bv//+uwoVKqSKFSuqcePG+uSTTzRw4ECH93/yyScKDAzUgw8+KEk6deqU7rrrLtlsNj3//PMqWbKkvv32W/Xq1UuJiYl66aWXHN7/xhtvyNfXVy+//LKSk5Pl6+ubZZw7duyQJEVFRTm0ly5dWrfddpv9/jVFixZVpUqV9MMPP2SKGQDyBQvALWfr1q2WJGvt2rWWZVlWenq6ddttt1kvvviiw3PLli2zJFkbNmzI1EfNmjWt5s2bZ2p/4403rMKFC1v79+93aH/ttdcsb29v6+jRo5ZlWVZMTIwlySpRooT1559/2p/78ssvLUnWf/7zH3tb//79rev9dSTJGjFihP11x44dLV9fX+vQoUP2thMnTliBgYFWs2bN7G3z5s2zJFmtWrWy0tPT7e0DBw60vL29rXPnzmU53jUjRoywJDm92rdvb3/+v//9ryXJ+uSTTxz6WbVqVab2pKSkTOP16dPHKlSokHXlyhV7W/v27a1y5cplenbDhg2WJKtWrVpWSkqKvf2xxx6zbDabdd999zk837Bhw0z9ZBVD27ZtrYoVKzq0lStXzpJkff755/a28+fPW2FhYVbdunUz9ZHRwYMHLUnWu+++m+lejx49rMKFCzt9f1Yxbt682ZJkffTRR/a2mTNnWpKsPXv22NtSUlKs4OBgq0ePHva2Xr16WWFhYVZCQoJDn48++qhVtGhR+3jXvr8VK1bMMoa/e/vtty1J9j/7GdWrV8+66667MrW3adPGuuOOO/6xbwBwRyxhAm5Bn3zyiUJCQtSiRQtJfy0D6tq1q5YsWeKwTCYnli1bpqZNmyooKEgJCQn2q1WrVkpLS9PGjRsdnu/atauCgoLsr5s2bSpJOVr/nZaWpjVr1qhjx46qWLGivT0sLEzdunXT999/n2mZybPPPuuwJKpp06ZKS0tTbGxstsb8/PPPtXbt2kzXtRmZa5YtW6aiRYuqdevWDt+XyMhIBQQEaMOGDfZnCxYsaP/nCxcuKCEhQU2bNlVSUlKm9fLOdO/e3T6rIUkNGjSQZVl6+umnHZ5r0KCBjh075rAjUMYYzp8/r4SEBDVv3lyHDx/W+fPnHd5funRpPfTQQ/bXRYoUUffu3bVjxw6dPHnyuvGdOXNGkhx+/q7IGOPVq1d15swZVa5cWcWKFdP27dvt9x555BH5+/s7LNNbvXq1EhIS9MQTT0iSLMvS559/rg4dOsiyLIefUdu2bXX+/HmHPiWpR48eDjFcz+XLlyVJfn5+me75+/vb72d07d8fAMiPWMIE3GLS0tK0ZMkStWjRQjExMfb2Bg0aaOLEiYqOjlabNm1y3P+BAwe0a9culSxZMsv7p0+fdnh9++23O7y+9mHy73UB2REfH6+kpCRVq1Yt07077rhD6enpOnbsmGrWrJlr4zdr1kzBwcGZ2v39/R1eHzhwQOfPn1epUqWy7Cfj9+W3337T0KFDtX79+kwJz98/vDvz96+taNGikqSyZctmak9PT9f58+dVokQJSdIPP/ygESNGaPPmzUpKSsoUw7W+JKly5coOSZgkVa1aVdJftS6hoaFO47QsK9tfU0aXL1/W2LFjNW/ePB0/ftyhn4zfp2LFiqlDhw5atGiR3njjDUl/JdFlypRRy5YtJf31Z+fcuXOaNWuWZs2aleV4f/+zW6FChWzFeS3J+HudifRX8XVWSYhlWZm+pwCQX5BAALeY9evXKy4uTkuWLNGSJUsy3f/kk09uKIFIT09X69at9corr2R5/9oHy2u8vb2zfC6nHypdlVfjp6enq1SpUtfd7epawnXu3Dk1b95cRYoU0ejRo1WpUiX5+/tr+/btevXVV53u9PN31/va/ulrPnTokO655x5Vr15dkyZNUtmyZeXr66tvvvlGkydPdikGZ64lKzlJFqW/6lfmzZunl156SQ0bNlTRokVls9n06KOPZoqxe/fuWrZsmTZt2qTatWtr5cqVeu655+Tl9ddE+7Xnn3jiCfXo0SPL8cLDwx1eZ2f2QfprBkyS4uLiMiVvcXFxql+/fqb3nD17NsvEFADyAxII4BbzySefqFSpUvadjTJavny5vvjiC33wwQcqWLCg09+AXu9epUqVdPHiRftOMrkhu7+JLVmypAoVKqR9+/Zlurd37155eXll+gCXVypVqqR169apcePGTj94fvfddzpz5oyWL1+uZs2a2dszzhZdc7N+Q/2f//xHycnJWrlypcMsRsZlVhkdPHgw02/M9+/fL0n2naGycvvtt6tgwYJZfm3Z8dlnn6lHjx6aOHGive3KlSs6d+5cpmfvvfde+3bFDRo0UFJSkp588kn7/ZIlSyowMFBpaWm5+mdXkiIiIiRJW7dudUgWTpw4oT/++EPPPvtspvfExMSoTp06uRoHAOQVaiCAW8jly5e1fPly3X///Xr44YczXc8//7wuXLhgPwW3cOHCkpTlB7LChQtn2f7II49o8+bNWr16daZ7586dy3TybnY4iyMjb29vtWnTRl9++aXDVp6nTp3SokWL1KRJExUpUsTl8XPDI488orS0NPsSmoxSU1PtX9u12YGMMyApKSl6//33M72vcOHCLi1pyq6sYjh//rzmzZuX5fMnTpzQF198YX+dmJiojz76SBEREU6XL/n4+CgqKkpbt27NcZx/nyl69913s6zjKVCggB577DF9+umnmj9/vmrXru0wo+Dt7a3OnTvr888/1+7duzO9/0a29q1Zs6aqV6+uWbNmOcQ2Y8YM2Ww2Pfzwww7Pnz9/XocOHVKjRo1yPCYAmMQMBHALWblypS5cuKAHHnggy/t33XWX/be0Xbt2VUREhLy9vTV+/HidP39efn5+9rMBIiMjNWPGDL355puqXLmySpUqpZYtW+rf//63Vq5cqfvvv19PPfWUIiMjdenSJf3666/67LPPdOTIEZeXZkRGRkqSBgwYoLZt28rb21uPPvpols+++eabWrt2rZo0aaLnnntOBQoU0MyZM5WcnKwJEya49g3LRc2bN1efPn00duxY/fLLL2rTpo18fHx04MABLVu2TFOnTtXDDz+sRo0aKSgoSD169NCAAQNks9m0cOHCLJdURUZGaunSpRo0aJDq1aungICAXDmQrU2bNvL19VWHDh3Up08fXbx4UbNnz1apUqUUFxeX6fmqVauqV69e2rJli0JCQjR37lydOnXquglHRg8++KCGDBmixMTETMnd1atX9eabb2Z6T/HixfXcc8/p/vvv18KFC1W0aFHVqFFDmzdv1rp16+xLo/6ue/fumjZtmjZs2KDx48dnuj9u3Dht2LBBDRo0UO/evVWjRg39+eef2r59u9atW3fdLXuz4+2339YDDzygNm3a6NFHH9Xu3bs1ffp0PfPMM/Ytkq9Zt26dLMuyby8LAPmOgZ2fANwkHTp0sPz9/a1Lly5d95mnnnrK8vHxsW9lOXv2bKtixYqWt7e3w5auJ0+etNq3b28FBgZakhy2dL1w4YI1ePBgq3Llypavr68VHBxsNWrUyHrnnXfs24pe28b17bffzhSD/rY1a2pqqvXCCy9YJUuWtGw2m8OWrn9/1rIsa/v27Vbbtm2tgIAAq1ChQlaLFi2sTZs2OTxzbRvXLVu2OLRf26Izq61rM7q2jWt8fHyW98uVK+ewjes1s2bNsiIjI62CBQtagYGBVu3ata1XXnnFOnHihP2ZH374wbrrrrusggULWqVLl7ZeeeUVa/Xq1ZniunjxotWtWzerWLFiliT7VqzXvoZly5Zl62vO6mtZuXKlFR4ebvn7+1vly5e3xo8fb82dO9eSZMXExGT6OlevXm2Fh4dbfn5+VvXq1TONfT2nTp2yChQoYC1cuNChvUePHtfdHrdSpUqWZVnW2bNnrZ49e1rBwcFWQECA1bZtW2vv3r1WuXLlHLZnzahmzZqWl5eX9ccff1w3nv79+1tly5a1fHx8rNDQUOuee+6xZs2aZX/met/ff/LFF19YERERlp+fn3XbbbdZQ4cOddhm95quXbtaTZo0calvAHAnNsvKo0pGAEC+U758edWqVUtfffVVjvvo1auX9u/fr//+97+5GFnW6tatq+LFiys6Ovqmj5UTJ0+eVIUKFbRkyRJmIADkW9RAAABuqhEjRmjLli364Ycfbuo4W7du1S+//KLu3bvf1HFuxJQpU1S7dm2SBwD5GjMQAIDryo0ZiJtt9+7d2rZtmyZOnKiEhAQdPnw40zkdAIDcwwwEACBf++yzz9SzZ09dvXpVixcvJnkAgJuMBAIAcF1Hjhxx69kHSRo5cqTS09O1Z88eNW/e3HQ4AJBnNm7cqA4dOqh06dKy2WxasWLFP77nu+++05133ik/Pz9VrlxZ8+fPd3lcEggAAAAgH7p06ZLq1KmT5eGxWYmJiVH79u3VokUL/fLLL3rppZf0zDPPZHm2kzPUQAAAAAD5nM1m0xdffKGOHTte95lXX31VX3/9tcOBmo8++qjOnTunVatWZXssZiAAAAAAN5GcnKzExESHKzk5OVf63rx5s1q1auXQ1rZtW23evNmlfm7Jk6gL1n3edAjIQ2e3TDcdAgAAcJG/G38KNflZ8tUHgzVq1CiHthEjRmjkyJE33PfJkycVEhLi0BYSEqLExERdvnxZBQsWzFY/bvyjAwAAADzL4MGDNWjQIIc2Pz8/Q9FkjQQCAAAAyMhmbpW/n5/fTUsYQkNDderUKYe2U6dOqUiRItmefZCogQAAAAA8QsOGDRUdHe3QtnbtWjVs2NClfkggAAAAgHzo4sWL+uWXX/TLL79I+mub1l9++UVHjx6V9NdyqO7du9uf79u3rw4fPqxXXnlFe/fu1fvvv69PP/1UAwcOdGlcowlEQkKCyeEBAACAzGw2c5cLtm7dqrp166pu3bqSpEGDBqlu3boaPny4JCkuLs6eTEhShQoV9PXXX2vt2rWqU6eOJk6cqA8//FBt27Z17dtj8hwIb29v3X333erVq5c6d+6ca+u92IXJs7ALEwAA+Y9b78IU+aKxsS9vm2ps7OwyOgNhWZZ8fX3Vs2dPhYWF6YUXXrBPwQAAAABG2LzMXfmA8SgXLFig48ePa8iQIVq/fr0iIyMVGRmpGTNmKDEx0XR4AAAAADIwnkBIUnBwsP71r3/pt99+0/fff6+IiAi9+uqrCgsLcyj8AAAAAG66fFIDYYrRBMKWxTepYcOGmjNnjuLi4jRt2jQdOnTIQGQAAAAAsmK8BuJ6ChcurF69eumHH37Iw4gAAAAAOGO0/n3evHkqWrSoyRAAAAAAR/mkmNkUowlEjx49TA4PAAAAwEVG06vPP/9cSUlJJkMAAAAAHFFE7ZTRBKJLly4KCwvTs88+q59++slkKAAAAACywfgCr5dffllbt25Vw4YNVatWLU2ZMkVnzpwxHRYAAACALBhPIPr06aPt27dry5YtatasmUaNGqUyZcrokUce0dq1a02HBwAAAE/DSdROuU2UkZGRev/99xUXF6fZs2crPj5e9957rypUqGA6NAAAAAD/43YHyfn7++vJJ5/Uhg0btG/fPnXr1s1AZAAAAPBYFFE75bYHyUlS5cqV9dZbb+VRNAAAAAD+idFzIGJiYlSyZEmTIQAAAACO8kktgilGE4hy5cqZHB4AAACAi4wmEJJ0+fJlLV68WN9//73i4uLk5eWlihUrqmPHjrrnnntMhwcAAAAgA6MJxMGDB9WqVStdvnxZfn5++uOPP9SuXTtt2bJFM2bMUKdOnbRo0SIVKGA8zwEAAICnyCfFzKYYXeA1YMAA3XvvvTp58qSOHj2qsWPHKj09XT/++KP27NmjLVu26M033zQZIgAAAIAMbNY/bYV0ExUuXFi//PKLqlSpIklKSUlRQECA4uLiVKJECX355Zd66aWXFBMT41K/Bes+fzPChZs6u2W66RAAAICL/N14gUnBJsOMjX35+zeMjZ1dRmcgihUrpgsXLthfJyUlKTU1Vb6+vpKk8PBwxcXFmQoPAAAAwN8YTSBat26tQYMGae/evYqJiVHfvn0VERGhwMBASdLRo0dVqlQpkyECAAAAyMDo5NGECRP04IMPqkaNGrLZbCpbtqy++OIL+/34+Hj9+9//NhghAAAAPA5F1E4ZTSBKlSqlzZs368CBA0pOTlb16tUddlx6+OGHDUYHAAAA4O/conzlWhE1AAAAYBwnUTvlFgnENSdOnNDMmTN18OBBhYWF6ZlnnlH16tVNhwUAAADgf4ymV4UKFVJ8fLwk6ffff1eNGjW0aNEiXb16VV9//bUiIyO1a9cukyECAADA09i8zF35gNEor1y5omvHULz++utq1qyZ9uzZo08//VS//fabHnjgAQ0ZMsRkiAAAAAAycJslTNu3b9cnn3xiL6L28vLSK6+8ovbt2xuODAAAAMA1RhMIm80m2/+2yfLy8lLRokUd7hcrVkxnz541ERoAAAA8lRfbuDpjdAmTZVmqWrWqihcvrhMnTmSqdzh48KBCQ0MNRQcAAADg74zOQMybN8/hdeXKlR1e//jjj3rooYfyMiQAAAB4unxSzGyK0QSiR48eTu8PGzYsjyIBAAAAkB2kVwAAAACyza0TiD179qhixYqmwwAAAIAnsdnMXfmAWycQKSkpio2NNR0GAAAAgP8xWgMxaNAgp/evnVINAAAA5BmKqJ0ymkBMnTpVERERKlKkSJb3L168mMcRAQAAAHDGaAJRuXJlDRw4UE888USW93/55RdFRkbmcVQAAAAArsfo/ExUVJS2bdt23fs2m02WZeVhRAAAAPB4FFE7ZXQGYuLEiUpOTr7u/Tp16ig9PT0PIwIAAADgjNEEIjQ01OTwAAAAQGYUUTtlNIG4Ji0tTd7e3vbXP//8s9LT01W3bl35+fkZjAwAAABARkbTq9jYWEVFRcnPz0/33XefEhMT1bp1a911111q1KiRatSoof3795sMEQAAAJ6GGginjCYQ//rXvxQQEKAVK1aoSJEiateunVJTU3Xs2DEdP35cVapU0auvvmoyRAAAAAAZGF3CtHHjRq1Zs0YRERFq2rSpgoKCtHHjRpUpU0aSNGbMGLVr185kiAAAAAAyMJpAXLlyRUWLFpUkBQYGytvbW4GBgfb7RYoUUVJSkqnwAAAA4IkoonbK6HenZs2amjt3riRpwYIFKlGihJYsWWK/v3jxYlWtWtVUeAAAAAD+xugMxMiRI9WxY0dNmDBBXl5eWr16tXr37q3169fLy8tLW7Zs0aJFi0yGCAAAAE+TT4qZTTGaQLRt21Z79uzRtm3bFBkZqfLly2vjxo167733lJSUpDFjxqhFixYmQwQAAACQgfFzIMqXL6/y5cvbX4eEhGj06NHmAgIAAABwXcYTCGdSU1N14sQJ3X777aZDAQAAgKegiNopt/7u/Pbbb6pQoYLpMAAAAAD8j1vPQGRHcnKykpOTHdqs9DTZvLwNRQQAAIB8jSJqp4wmEHfeeafT+5cvX/7HPsaOHatRo0Y5tHmH1JNPWP0big0AAABAZkYTiN9//12PPvrodZcpxcXFaf/+/U77GDx4sAYNGuTQVqrpq7kWIwAAADwMNRBOGU0gatWqpQYNGqhfv35Z3v/ll180e/Zsp334+fnJz8/PoY3lSwAAAMDNYTS9aty4sfbt23fd+4GBgWrWrFkeRgQAAADAGaMzEFOnTnV6v1KlStqwYUMeRQMAAACIJUz/gO8OAAAAgGxziwQiPT39uu1Hjx7N42gAAADg0Ww2c1c+YDSBSExM1COPPKLChQsrJCREw4cPV1pamv1+fHw8B8kBAAAAbsRoDcSwYcO0c+dOLVy4UOfOndObb76p7du3a/ny5fL19ZUkWZZlMkQAAAAAGRhNIFasWKEFCxbo7rvvliR17NhR7du3V4cOHbRy5UpJki2fTOUAAADgFkERtVNGvzvx8fEqV66c/XVwcLDWrVunCxcuqF27dkpKSjIYHQAAAIC/M5pA3H777dqzZ49DW2BgoNasWaPLly/roYceMhQZAAAAPBZF1E4ZTSDatGmjefPmZWoPCAjQ6tWr5e/vbyAqAAAAANdjtAZi1KhROnHiRJb3AgMDtXbtWm3fvj2PowIAAIBHowbCKaPfnaCgINWsWfO69wMDA9W8eXP769q1a+vYsWN5ERoAAACALOSr9OrIkSO6evWq6TAAAAAAj2V0CRMAAADgdvJJMbMp+WoGAgAAAIBZzEAAAAAAGXCQsXPMQAAAAADINhIIAAAAANmWr5YwzZw5UyEhIabDAAAAwC2MJUzOuUUCMW3atCzbbTab/P39VblyZTVr1kzdunXL48gAAAAAZOQWCcTkyZMVHx+vpKQkBQUFSZLOnj2rQoUKKSAgQKdPn1bFihW1YcMGlS1b1nC0AAAAuKUxAeGUW9RAjBkzRvXq1dOBAwd05swZnTlzRvv371eDBg00depUHT16VKGhoRo4cKDpUAEAAACP5hYzEEOHDtXnn3+uSpUq2dsqV66sd955R507d9bhw4c1YcIEde7c2WCUAAAA8ATUQDjnFjMQcXFxSk1NzdSempqqkydPSpJKly6tCxcu5HVoAAAAADJwiwSiRYsW6tOnj3bs2GFv27Fjh/r166eWLVtKkn799VdVqFDBVIgAAAAA5CYJxJw5c1S8eHFFRkbKz89Pfn5+ioqKUvHixTVnzhxJUkBAgCZOnGg4UgAAANzqbDabsSs/cIsaiNDQUK1du1b79u3Tvn37JEnVqlVTtWrV7M+0aNHCVHgAAAAA/sctEohr/p40AAAAAHktv8wEmOIWS5g6d+6s8ePHZ2qfMGGCunTpYiAiAAAAAFlxiwRi48aNateuXab2++67Txs3bjQQEQAAAICsuMUSposXL8rX1zdTu4+PjxITEw1EBAAAAE/FEibn3GIGonbt2lq6dGmm9iVLlqhGjRoGIgIAAACQFbeYgRg2bJg6deqkQ4cO2c99iI6O1uLFi7Vs2TLD0QEAAMCjMAHhlFskEB06dNCKFSs0ZswYffbZZypYsKDCw8O1bt06NW/e3HR4AAAAAP7HLRIISWrfvr3at29vOgwAAAB4OGognHObBOKaixcvKj093aGtSJEihqIBAAAAkJFbFFHHxMSoffv2Kly4sIoWLaqgoCAFBQWpWLFiCgoKMh0eAAAAgP9xixmIJ554QpZlae7cuQoJCWHaCAAAAMbwWdQ5t0ggdu7cqW3btqlatWqmQwEAAADghFssYapXr56OHTtmOgwAAABANpvN2JUfuMUMxIcffqi+ffvq+PHjqlWrlnx8fBzuh4eHG4oMAAAAQEZukUDEx8fr0KFD6tmzp73NZrPJsizZbDalpaUZjA4AAADANW6RQDz99NOqW7euFi9eTBE1AAAAjOKzqHNukUDExsZq5cqVqly5sulQAAAAADjhFkXULVu21M6dO02HAQAAAEg2g1c+4BYzEB06dNDAgQP166+/qnbt2pmKqB944AFDkQEAAADIyC0SiL59+0qSRo8enekeRdQAAADIS9RAOOcWCUR6errpEAAAAABkg7EaiOLFiyshIUHSX7swXbhwwVQoAAAAALLJWAKRkpKixMRESdKCBQt05coVU6EAAAAAdpxE7ZyxJUwNGzZUx44dFRkZKcuyNGDAABUsWDDLZ+fOnZvH0QEAAADIirEE4uOPP9bkyZN16NAh2Ww2nT9/nlkIAAAAGJdfZgJMMZZAhISEaNy4cZKkChUqaOHChSpRooSpcAAAAABkg1vswhQTE6Po6GhFR0fr9OnTDrsy2Ww2zZkzx2B0AAAAAK5xiwRi9OjRGjVqlKKiohQWFsa0EQAAAMzho6hTxnZhymjGjBmaP3++fvrpJ61YsUJffPGFwwUAAAAga++9957Kly8vf39/NWjQQD///LPT56dMmaJq1aqpYMGCKlu2rAYOHOhSLbJbzECkpKSoUaNGpsMAAAAA8tVqmKVLl2rQoEH64IMP1KBBA02ZMkVt27bVvn37VKpUqUzPL1q0SK+99prmzp2rRo0aaf/+/Xrqqadks9k0adKkbI3pFjMQzzzzjBYtWmQ6DAAAACBfmTRpknr37q2ePXuqRo0a+uCDD1SoUKHrHoOwadMmNW7cWN26dVP58uXVpk0bPfbYY/84a5GRW8xAXLlyRbNmzdK6desUHh4uHx8fh/vZzYYAAACA/Cw5OVnJyckObX5+fvLz88v0bEpKirZt26bBgwfb27y8vNSqVStt3rw5y/4bNWqkjz/+WD///LPq16+vw4cP65tvvtGTTz6Z7RjdIoHYtWuXIiIiJEm7d+92uJeTKaSew57LjbCQT7zy1V7TISAPTbi/uukQAAC3OJNLmMaOHatRo0Y5tI0YMUIjR47M9GxCQoLS0tIUEhLi0B4SEqK9e7P+fNStWzclJCSoSZMmsixLqamp6tu3r15//fVsx+gWCcSGDRtMhwAAAAAYN3jwYA0aNMihLavZh5z67rvvNGbMGL3//vtq0KCBDh48qBdffFFvvPGGhg0blq0+3CKBAAAAANyFyRmI6y1XykpwcLC8vb116tQph/ZTp04pNDQ0y/cMGzZMTz75pJ555hlJUu3atXXp0iU9++yzGjJkiLy8/rlE2i2KqAEAAAC4xtfXV5GRkYqOjra3paenKzo6Wg0bNszyPUlJSZmSBG9vb0mSZVnZGpcZCAAAACCD/LSN66BBg9SjRw9FRUWpfv36mjJlii5duqSePXtKkrp3764yZcpo7NixkqQOHTpo0qRJqlu3rn0J07Bhw9ShQwd7IvFPSCAAAACAfKpr166Kj4/X8OHDdfLkSUVERGjVqlX2wuqjR486zDgMHTpUNptNQ4cO1fHjx1WyZEl16NBBb731VrbHtFnZnau4CU6fPu1wwMUvv/yiyZMn6+DBgwoLC9Pzzz+vu+++2+V+n1v+ey5GCXdXIBtr9XDrYBcmALg1+Lvxr7FL91lubOwTMzsZGzu7jH7yCgsL0+nTpyX9dahF/fr1FRsbq8aNGysxMVGtW7fWxo0bTYYIAAAAT2MzeOUDRnO/jJMfI0eO1JNPPqk5c+bY21566SWNGjXKoTAEAAAAgDlus/Zj9+7d6t27t0Nb7969tWvXLkMRAQAAwBPZbDZjV35gfPXZhQsX5O/vL39//0x73vr7+yspKclQZAAAAAD+zvgMRNWqVRUUFKQjR45o69atDvd+++03lS5d2lBkAAAAAP7O6AzEhg0bHF6HhYU5vI6JidGzzz6blyEBAADAw+WXpUSmGE0gmjdv7vT+iy++mEeRAAAAAMgO4zUQAAAAgDthBsI54zUQ77//vlq1aqVHHnkk03atCQkJqlixoqHIAAAAAPyd0QRi2rRp+ve//63q1avLz89P7dq109ixY+3309LSFBsbazBCAAAAeBwOknPK6BKmmTNnavbs2erWrZskqV+/furYsaMuX76s0aNHmwwNAAAAQBaMJhAxMTFq1KiR/XWjRo20fv16tWrVSlevXtVLL71kLjgAAAAAmRhNIIKDg3Xs2DGVL1/e3larVi2tX79eLVu21IkTJ8wFBwAAAI9EEbVzRmsgmjRpouXLl2dqr1GjhqKjo/Xtt98aiAoAAADA9RidgXjttde0bdu2LO/VrFlT69ev1+eff57HUQEAAMCTMQPhnNEEIjw8XOHh4de9X6tWLdWqVSsPIwIAAADgjPFzICQpPT39uu1Hjx7N42gAAAAAXI/RBCIxMVGPPPKIChcurJCQEA0fPlxpaWn2+/Hx8apQoYLBCAEAAOBpbDabsSs/MLqEadiwYdq5c6cWLlyoc+fO6c0339T27du1fPly+fr6SpIsyzIZIgAAAIAMjCYQK1as0IIFC3T33XdLkjp27Kj27durQ4cOWrlypSSKWAAAAJC3+PzpnNElTPHx8SpXrpz9dXBwsNatW6cLFy6oXbt2SkpKMhgdAAAAgL8zmkDcfvvt2rNnj0NbYGCg1qxZo8uXL+uhhx4yFBkAAAA8ls3glQ8YTSDatGmjefPmZWoPCAjQ6tWr5e/vbyAqAAAAANdjtAZi1KhROnHiRJb3AgMDtXbtWm3fvj2PowIAAABwPUYTiKCgIAUFBWVqtyxLNptNgYGBat68uYHIAAAA4KkoonbOLQ6S+zs/P79MtREAAAAAzDM6AzFo0KAs29PS0jRu3DiVKFFCkjRp0qS8DAsAAAAejBkI54wmEFOmTFGdOnVUrFgxh3bLsrRnzx4VLlyYHyAAAADgRowmEGPGjNGsWbM0ceJEtWzZ0t7u4+Oj+fPnq0aNGgajAwAAAPB3RmsgXnvtNS1dulT9+vXTyy+/rKtXr5oMBwAAAJDNZu7KD4wXUderV0/btm1TfHy8oqKitHv3bpYtAQAAAG7K6BKmawICArRgwQItWbJErVq1UlpamumQAAAA4KH4ZbZzbpFAXPPoo4+qcePG2r59u26//XbT4QAAAAD4G7dKICSpbNmyKlu2rCzLMh0KAAAAPBATEM4ZrYFITk7Wyy+/rGbNmmn8+PGSpDfffFMBAQEKDAxUt27dlJiYaDJEAAAAABkYTSAGDx6sxYsXq379+lqwYIH69++v2bNna+bMmZo9e7a2bNmioUOHmgwRAAAAQAZGlzB99tlnWrBggVq1aqXnnntOVapU0fLly/Xggw9KkoKDg9W7d29NmzbNZJgAAADwIBRRO2d0BiIhIUFVq1aVJFWsWFHe3t6qXLmy/X6VKlUUHx9vKjwAAAAAf2M0gbj99tu1efNmSdKWLVtks9n0888/2+//9NNPKlOmjKnwAAAA4IE4SM45o0uY+vbtq6eeekoffvihtm3bpnfeeUevv/669u7dKy8vL82YMUP/+te/TIYIAAAAIAOjCcRLL72kUqVKafPmzXr66af12GOPqXbt2ho+fLiSkpI0cOBADRkyxGSIAAAAADIwfg5Et27d1K1bN/vru+++Wxs3bjQYEQAAADyZl1c+WUtkiNEaiKwkJyfr0KFDSk5ONh0KAAAAgL8xmkDMnz/fXkR95coV9erVS4ULF1bVqlUVEBCgvn37kkgAAAAgT1FE7ZzRBGL06NHy8vorhGHDhmn9+vVatmyZfvvtN3322WfasGGDhg0bZjJEAAAAABkYrYE4ceKEwsLCJEkrV67UjBkzdO+990qSqlevrqCgID355JOaMGGCyTABAADgQThIzjmjMxChoaE6dOiQJOnSpUsKDg52uF+yZEmdOXPGRGgAAAAAsmA0gXj88cc1ZMgQnTt3Tk8++aRGjx6tixcvSpKSkpI0cuRINW7c2GSIAAAAADIwuoRpxIgR2r17typWrKioqCj997//VUhIiMqUKaMTJ06oRIkSWrt2rckQAQAA4GFYweSc0QTC19dXX375pVatWqX//Oc/8vb2Vnp6usLCwtS4cWN169ZNhQsXNhkiAAAAgAyMHyQnSffee6+9eBoAAAAwiSJq54zWQCQkJJgcHgAAAICLjCYQISEhuueee7Ro0SIOjAMAAADyAaMJhGVZ8vX1Vc+ePRUWFqYXXnhBv/zyi8mQAAAA4OFsNpuxKz8wmkBI0oIFC3T8+HENGTJE69evV2RkpCIjIzVjxgwlJib+4/uTk5OVmJjocKVdTcmDyAEAAADPYzyBkKTg4GD961//0m+//abvv/9eERERevXVVxUWFqbu3bs7fe/YsWNVtGhRh2v78tl5FDkAAABuNTabuSs/MJpAZDVN07BhQ82ZM0dxcXGaNm2a/aTq6xk8eLDOnz/vcN3ZqffNChkAAADwaEa3cbUs67r3ChcurF69eqlXr15O+/Dz85Ofn59Dm7ePb67EBwAAAM+TX2oRTDE6AzFv3jwVLVrUZAgAAAAAXGB0BqJHjx4mhwcAAADgIrcook5PT79u+9GjR/M4GgAAAHgyiqidM5pAJCYm6pFHHlHhwoUVEhKi4cOHKy0tzX4/Pj5eFSpUMBghAAAAgIyMLmEaNmyYdu7cqYULF+rcuXN68803tX37di1fvly+vn8VQjsrtAYAAAByG0XUzhmdgVixYoVmzpyphx9+WM8884y2bt2q+Ph4dejQQcnJyZL4AQIAAADuxGgCER8fr3LlytlfBwcHa926dbpw4YLatWunpKQkg9EBAAAA+DujCcTtt9+uPXv2OLQFBgZqzZo1unz5sh566CFDkQEAAMBTUUTtnNEEok2bNpo3b16m9oCAAK1evVr+/v4GogIAAABwPUaLqEeNGqUTJ05keS8wMFBr167V9u3b8zgqAAAAeDJqcJ0zOgMRFBSkmjVrXvd+YGCgmjdvbn9du3ZtHTt2LC9CAwAAAJAFtzhILruOHDmiq1evmg4DAAAA8FhGlzABAAAA7oYVTM7lqxkIAAAAAGYxAwEAAABkQBG1c8xAAAAAAMg2ZiAAAACADJiAcC5fzUDMnDlTISEhpsMAAAAAPJZbzEBMmzYty3abzSZ/f39VrlxZzZo1U7du3fI4MgAAAAAZuUUCMXnyZMXHxyspKUlBQUGSpLNnz6pQoUIKCAjQ6dOnVbFiRW3YsEFly5Y1HC0AAABuZRRRO+cWS5jGjBmjevXq6cCBAzpz5ozOnDmj/fv3q0GDBpo6daqOHj2q0NBQDRw40HSoAAAAgEdzixmIoUOH6vPPP1elSpXsbZUrV9Y777yjzp076/Dhw5owYYI6d+5sMEoAAAB4AiYgnHOLGYi4uDilpqZmak9NTdXJkyclSaVLl9aFCxfyOjQAAAAAGbhFAtGiRQv16dNHO3bssLft2LFD/fr1U8uWLSVJv/76qypUqGAqRAAAAABykwRizpw5Kl68uCIjI+Xn5yc/Pz9FRUWpePHimjNnjiQpICBAEydONBwpAAAAbnU2m83YlR+4RQ1EaGio1q5dq3379mnfvn2SpGrVqqlatWr2Z1q0aGEqPAAAAAD/4xYJxDV/TxoAAACAvJZPJgKMcYslTJ07d9b48eMztU+YMEFdunQxEBEAAACArLhFArFx40a1a9cuU/t9992njRs3GogIAAAAnooaCOfcIoG4ePGifH19M7X7+PgoMTHRQEQAAAAAsuIWCUTt2rW1dOnSTO1LlixRjRo1DEQEAAAAICtuUUQ9bNgwderUSYcOHbKf+xAdHa3Fixdr2bJlhqMDAACAJ8kvS4lMcYsEokOHDlqxYoXGjBmjzz77TAULFlR4eLjWrVun5s2bmw4PAAAAwP+4RQIhSe3bt1f79u1NhwEAAAAPxwSEc26TQFxz8eJFpaenO7QVKVLEUDQAAAAAMnKLIuqYmBi1b99ehQsXVtGiRRUUFKSgoCAVK1ZMQUFBpsMDAAAA8D9uMQPxxBNPyLIszZ07VyEhIRSuAAAAwBg+izrnFgnEzp07tW3bNlWrVs10KAAAAACccCmBOHfunL744gv997//VWxsrJKSklSyZEnVrVtXbdu2VaNGjXIURL169XTs2DESCAAAABjHBIRz2UogTpw4oeHDh+uTTz5R6dKlVb9+fUVERKhgwYL6888/tWHDBr3zzjsqV66cRowYoa5du7oUxIcffqi+ffvq+PHjqlWrlnx8fBzuh4eHu9QfAAAAgJsjWwlE3bp11aNHD23btu26J0NfvnxZK1as0JQpU3Ts2DG9/PLL2Q4iPj5ehw4dUs+ePe1tNptNlmXJZrMpLS0t230BAAAAN4IaCOeylUD8/vvvKlGihNNnChYsqMcee0yPPfaYzpw541IQTz/9tOrWravFixdTRA0AAAC4sWwlEP+UPNzo87GxsVq5cqUqV67s0vsAAAAA5K0c7cJ04MABbdiwQadPn8506Nvw4cNd7q9ly5bauXMnCQQAAACMYzGMcy4nELNnz1a/fv0UHBys0NBQh+VGNpstRwlEhw4dNHDgQP3666+qXbt2piLqBx54wOU+AQAAAOQ+m2VZlitvKFeunJ577jm9+uqruRaEl9f1D8TOSRH1c8t/v9GQkI8UcPLnB7eeCfdXNx0CACAX+LvFaWRZaz39R2Njr33+LmNjZ5fLP7qzZ8+qS5cuuRrE35dBAQAAAHBPLv/qtkuXLlqzZs0ND1y8eHElJCRI+msXpgsXLtxwnwAAAABuLpdnICpXrqxhw4bpxx9/zLJeYcCAAdnqJyUlRYmJiQoODtaCBQs0fvx4BQYGuhoOAAAAkKsoonbO5QRi1qxZCggI0P/93//p//7v/xzu2Wy2bCcQDRs2VMeOHRUZGSnLsjRgwAAVLFgwy2fnzp3rapgAAAAAbgKXE4iYmJhcGfjjjz/W5MmTdejQIdlsNp0/f15XrlzJlb4BAACAnOJQY+duqP792gZOOfkmh4SEaNy4cZKkChUqaOHChS4fQAcAAAAgb+Uogfjoo4/09ttv68CBA5KkqlWr6t///reefPLJHAURExOj6OhoRUdHZzqczmazac6cOTnqFwAAAHCVFxMQTrmcQEyaNEnDhg3T888/r8aNG0uSvv/+e/Xt21cJCQkaOHCgy0GMHj1ao0aNUlRUlMLCwpg2AgAAANyUywnEu+++qxkzZqh79+72tgceeEA1a9bUyJEjc5RAzJgxQ/Pnz8/xDAYAAADgqd577z29/fbbOnnypOrUqaN3331X9evXv+7z586d05AhQ7R8+XL9+eefKleunKZMmaJ27dplazyXE4i4uDg1atQoU3ujRo0UFxfnaneS/trSNas+AQAAgLyWn1bDLF26VIMGDdIHH3ygBg0aaMqUKWrbtq327dunUqVKZXo+JSVFrVu3VqlSpfTZZ5+pTJkyio2NVbFixbI9pssHyVWuXFmffvpplsFXqVLF1e4kSc8884wWLVqUo/cCAAAAnmrSpEnq3bu3evbsqRo1auiDDz5QoUKFrnsMwty5c/Xnn39qxYoVaty4scqXL6/mzZurTp062R7T5RmIUaNGqWvXrtq4caO9BuKHH35QdHR0lolFdly5ckWzZs3SunXrFB4enulwukmTJuWoXwAAAMBVJicgkpOTlZyc7NDm5+cnPz+/TM+mpKRo27ZtGjx4sL3Ny8tLrVq10ubNm7Psf+XKlWrYsKH69++vL7/8UiVLllS3bt306quvytvbO1sxupxAdO7cWT/99JMmT56sFStWSJLuuOMO/fzzz6pbt66r3UmSdu3apYiICEnS7t27He7lZArphbvK5SgO5E/HzieZDgF56NlPd5kOAXlo1iPhpkMAgDw1duxYjRo1yqFtxIgRGjlyZKZnExISlJaWppCQEIf2kJAQ7d27N8v+Dx8+rPXr1+vxxx/XN998o4MHD+q5557T1atXNWLEiGzFmKNtXCMjI/Xxxx/n5K1Z2rBhQ671BQAAAORXgwcP1qBBgxzaspp9yKn09HSVKlVKs2bNkre3tyIjI3X8+HG9/fbbuZtAJCYmqkiRIvZ/dubacwAAAEB+ZJO5NUzXW66UleDgYHl7e+vUqVMO7adOnVJoaGiW7wkLC5OPj4/DcqU77rhDJ0+eVEpKinx9ff9x3GwVUQcFBen06dOSpGLFiikoKCjTda0dAAAAwM3n6+uryMhIRUdH29vS09MVHR2thg0bZvmexo0b6+DBgw4HN+/fv19hYWHZSh6kbM5ArF+/XsWLF5fEciMAAADc2vLTSdSDBg1Sjx49FBUVpfr162vKlCm6dOmSevbsKUnq3r27ypQpo7Fjx0qS+vXrp+nTp+vFF1/UCy+8oAMHDmjMmDEaMGBAtsfMVgLRvHlz+z9XqFBBZcuWzVTcbFmWjh07lu2BMzp8+LC+//57xcXFycvLSxUrVlTr1q1ZDgUAAAA40bVrV8XHx2v48OE6efKkIiIitGrVKnth9dGjR+Xl9f8XHZUtW1arV6/WwIEDFR4erjJlyujFF1/Uq6++mu0xbZZlWa4E6e3trbi4uEwHU5w5c0alSpVSWlpatvu6dOmSnnrqKX3++ed/BWOzqVSpUoqPj1fBggU1btw49e/f35XwJEl7Tlxy+T3Iv9iFybN8vCNnB1Yif2IXJuDW5Z+jrXzyxoOztxob+8veUcbGzi6XD5KzLCvLrVUvXrwof39/l/oaNGiQ4uLitGvXLu3fv1+dOnVS9+7dlZiYqKlTp+qVV17hgDkAAADAjWQ797u2nZTNZtOwYcNUqFAh+720tDT99NNP9rMcsmv58uVatWqVatWqJUmaNWuWSpcurREjRujpp5/W5cuX9fbbb6tbt24u9QsAAADg5sh2ArFjxw5Jf81A/Prrrw5V2r6+vqpTp45efvlllwZPTU11qHMICAhQamqqLl26pEKFCqlNmzYu9wkAAADcCJMnUecH2U4gru2+1LNnT02dOjVXCpzr1aunqVOnavr06ZKkqVOnqmTJkipZsqSkv5ZFBQQE3PA4AAAAAHKHy+Ur8+bNy7XBx40bp9atW+vzzz+Xr6+vTp48qQULFtjvb9q0Se3atcu18QAAAIB/4sUUhFPZSiA6deqk+fPnq0iRIurUqZPTZ5cvX57twe+8807t3r1bX331lZKTk9WyZUvVqFHDfr9///452oUJAAAAwM2RrQSiaNGi9p2XihYtmqsBhIWFqXfv3rnaJwAAAICbI1sJRMZlS7m5hEn66/yIXbt2qU6dOipevLgSEhI0Z84cJScnq0uXLrrjjjtydTwAAADAGVYwOedyDcTly5dlWZZ9G9fY2Fh98cUXqlGjhtq0aeNSXz///LPatGmjxMREFStWTGvXrlWXLl1UoEABpaena9y4cfr+++915513uhomAAAAgJvA5YPkHnzwQX300UeSpHPnzql+/fqaOHGiHnzwQc2YMcOlvoYMGaIuXbro/Pnzev3119WxY0fdc8892r9/vw4ePKhHH31Ub7zxhqshAgAAADlms9mMXfmBywnE9u3b1bRpU0nSZ599ptDQUMXGxuqjjz7StGnTXOpr27ZtGjRokAIDA/Xiiy/qxIkTDvUQzz//vLZs2eJqiAAAAABuEpeXMCUlJSkwMFCStGbNGnXq1EleXl666667FBsb61JfKSkpKliwoCTJx8dHhQoVUnBwsP1+cHCwzpw542qIAAAAQI7lk4kAY1yegahcubJWrFihY8eOafXq1fa6h9OnT7t8uFzZsmV1+PBh++slS5YoLCzM/jouLs4hoQAAAABglssJxPDhw/Xyyy+rfPnyql+/vho2bCjpr9mIunXrutTXo48+qtOnT9tft2/f3j4jIUkrV65U/fr1XQ0RAAAAwE1isyzLcvVNJ0+eVFxcnOrUqSMvr79ykJ9//llFihRR9erVcy24pKQkeXt7y8/Pz6X37TlxKddigPs7dj7JdAjIQx/viDMdAvLQrEfCTYcA4Cbxd3khfd7pumCHsbGX9nDtF/Im5OhHFxoaqtDQUP3xxx+SpNtuu+2mzBRc2yoWAAAAgHtweQlTenq6Ro8eraJFi6pcuXIqV66cihUrpjfeeEPp6eku9bV9+3bFxMTYXy9cuFCNGzdW2bJl1aRJEy1ZssTV8AAAAIAbYjN45QcuJxBDhgzR9OnTNW7cOO3YsUM7duzQmDFj9O6772rYsGEu9dWzZ08dOnRIkvThhx+qT58+ioqK0pAhQ1SvXj317t1bc+fOdTVEAAAAADeJy0uYFixYoA8//FAPPPCAvS08PFxlypTRc889p7feeivbfR04cEBVqlSRJL3//vuaOnWqwzkQ9erV01tvvaWnn37a1TABAAAA3AQuz0D8+eefWRZKV69eXX/++adLfRUqVEgJCQmSpOPHj2eqo2jQoIHDEicAAADgZuMkaudcTiDq1Kmj6dOnZ2qfPn266tSp41Jf9913n2bMmCFJat68uT777DOH+59++qkqV67saogAAAAAbhKXlzBNmDBB7du317p16+xnQGzevFnHjh3TN99841Jf48ePV+PGjdW8eXNFRUVp4sSJ+u6773THHXdo3759+vHHH/XFF1+4GiIAAACQY175YyLAGJdnIJo3b679+/erU6dOOnfunM6dO6dOnTpp3759atq0qUt9lS5dWjt27FDDhg21atUqWZaln3/+WWvWrNFtt92mH374Qe3atXM1RAAAAAA3iUszEEeOHNHatWuVkpKiRx99VLVq1brhAIoVK6Zx48Zp3LhxN9wXAAAAgJsr2wnEhg0bdP/99+vy5ct/vbFAAc2dO1dPPPFErgf13XffqUGDBipYsGCu9w0AAAA4k1+KmU3J9hKmYcOGqXXr1jp+/LjOnDmj3r1765VXXrkpQbVp00ZHjhy5KX0DAAAAyLlsz0Ds3r1bmzZtUlhYmCTp7bff1syZM3XmzBmVKFEiR4PfeeedWbanpqaqc+fO8vf3l/TXidUAAABAXmACwrlsJxCJiYkKDg62vy5UqJAKFiyo8+fP5ziB+PXXX9WqVSvddddd9jbLsrRz5061aNFCpUqVylG/AAAAAG4Ol4qoV69eraJFi9pfp6enKzo6Wrt377a3ZTyh+p9899136tGjh+rXr68RI0bIy+uvFVVvvfWW+vfvrxo1argSHgAAAHDDqIFwzqUEokePHpna+vTpY/9nm82mtLS0bPfXuHFjbdu2TX379lWjRo30ySefqFKlSq6EBAAAACAPZbuIOj09/R8vV5KHa4oWLarFixerT58+atKkiWbNmkXWBwAAALgpl0+ivll69uypJk2a6PHHH1dqaqrpcAAAAOChOInaObdJICSpSpUq+vHHH3XhwgUVKVLEdDgAAAAA/sYtEoi0tDR5e3tLkry8vLRv3z6lp6erbt268vPzMxwdAAAAPAnL6Z3Ldg3EzRAbG6uoqCj5+fnpvvvuU2Jiolq3bq277rpLjRo1Uo0aNbR//36TIQIAAADIwGgC8a9//UsBAQFasWKFihQponbt2ik1NVXHjh3T8ePHVaVKFb366qsmQwQAAACQgctLmCpWrKgtW7ZkOjzu3LlzuvPOO3X48OFs97Vx40atWbNGERERatq0qYKCgrRx40aVKVNGkjRmzBi1a9fO1RABAACAHGMBk3Muz0AcOXIky+1ak5OTdfz4cZf6unLliv1gusDAQHl7eyswMNB+v0iRIkpKSnI1RAAAAAA3SbZnIFauXGn/57+fSJ2Wlqbo6GiVL1/epcFr1qypuXPn6o033tCCBQtUokQJLVmyRHXq1JEkLV68WFWrVnWpTwAAAOBGeFFE7VS2E4iOHTtK+qsq/e8nUvv4+Kh8+fKaOHGiS4OPHDlSHTt21IQJE+Tl5aXVq1erd+/eWr9+vby8vLRlyxYtWrTIpT4BAAAA3DzZTiDS09MlSRUqVNCWLVsUHBx8w4O3bdtWe/bs0bZt2xQZGany5ctr48aNeu+995SUlKQxY8aoRYsWNzwOAAAAkF1MQDjnchF1TExMrgZQvnx5h6VPISEhGj16dK6OAQAAACB35OgguejoaEVHR+v06dP2mYlr5s6d61JfaWlpio2NVfny5eXl5aXk5GR9+eWXSk9PV4sWLRQSEpKTEAEAAADcBC4nEKNGjdLo0aMVFRWlsLCwGzqpb9euXbr33nt16tQp1ahRQ998843atWunmJgY2Ww2+fj4aPXq1apXr16OxwAAAABcwUnUzrmcQHzwwQeaP3++nnzyyRse/JVXXlHjxo01YsQIffjhh2rbtq1q1aql7du3y2azqWfPnnr99de1du3aGx4LAAAAwI1zOYFISUlRo0aNcmXwn3/+WT/88IPuuOMOjR07VtOnT9f8+fPl4+MjSXrttdfUvHnzXBkLAAAAyA4mIJxz+SC5Z555Jte2VrUsSwUK/JXD/P3/Jcnb2ztTjQUAAAAAc1yegbhy5YpmzZqldevWKTw83D5bcM2kSZOy3VdkZKTGjx+vUaNGac6cOapQoYKmT59uL8R+9913VatWLVdDBAAAAHCTuJxA7Nq1SxEREZKk3bt3O9xzteBk7Nixuu+++zRv3jyVKFFCGzZsUK9evRQWFiYvLy+dPXtW//nPf1wNEQAAAMgxTqJ2zuUEYsOGDbk2eL169RQbG6u9e/eqWrVqCggI0HfffadPPvlEly9fVuvWrVWtWrVcGw8AAADAjcnRORCSdPDgQR06dEjNmjVTwYIFZVlWjra8Kly4sCIjI+2v/f391atXr5yGBQAAANwQJiCcc7mI+syZM7rnnntUtWpVtWvXTnFxcZKkXr166V//+leuBnfp0iVt3LgxV/sEAAAAkHMuJxADBw6Uj4+Pjh49qkKFCtnbu3btqlWrVuVqcAcPHlSLFi1ytU8AAADAGZvNZuzKD1xewrRmzRqtXr1at912m0N7lSpVFBsbm2uBAQAAAHA/LicQly5dcph5uObPP/+Un5+fS30VL17c6f20tLR/7CM5OVnJyckObSnJqfJ1MRYAAAAA/8zlBKJp06b66KOP9MYbb0j6a4onPT1dEyZMcHm5UXJysvr166fatWtneT82NlajRo1y2sfYsWMzPfPcoMF6/l9DXIoFAAAAkHKwxt/DuJxATJgwQffcc4+2bt2qlJQUvfLKK/rtt9/0559/6ocffnCpr4iICJUtW1Y9evTI8v7OnTv/MYEYPHiwBg0a5NAWcybVpTgAAAAAZI/LCUStWrW0f/9+TZ8+XYGBgbp48aI6deqk/v37KywszKW+2rdvr3Pnzl33fvHixdW9e3enffj5+WVaOuV78ZJLcQAAAADX5JdiZlNcSiCuXr2qe++9Vx988IGGDLnxJUKvv/660/tly5bVvHnzbngcAAAAALnDpSVePj4+2rVr182KBQAAAICbc7lG5IknntCcOXNuRiyZnD17Vh999FGejAUAAABIkpfN3JUfuFwDkZqaqrlz52rdunWKjIxU4cKFHe5PmjQp14I7evSoevbs+Y91EAAAAADyhssJxO7du3XnnXdKkvbv3+9wz9WCk8TERKf3L1y44FpwAAAAwA3KLzMBpriUQKSlpWnUqFGqXbu2goKCbnjwYsWKOU06LMuiCh4AAABwIy4lEN7e3mrTpo327NmTKwlEYGCghgwZogYNGmR5/8CBA+rTp88NjwMAAABkF7/Adi5H50AcPnxYFSpUuOHBry2Fat68eZb3ixUrJsuybngcAAAAALnD5V2Y3nzzTb388sv66quvFBcXp8TERIfLFd26dZO/v/9174eGhmrEiBGuhggAAADgJrFZLv6K38vr/+ccGad3rtUrpKWl5V50ObTnBCdRe5Jj55NMh4A89PGOONMhIA/NeiTcdAgAbhJ/l9fB5J1/f7XP2Nhv31/N2NjZ5fKPbsOGDTcjjmypXbu2vvnmG5UtW9ZYDAAAAIAnczmBuF69Ql44cuSIrl69amx8AAAA3PqooXbO5QRi48aNTu83a9Ysx8EAAAAAcG8uJxB33313praMtRDuUAMBAAAA4OZwOYE4e/asw+urV69qx44dGjZsmN56661cCwwAAAAwwYs1TE65nEAULVo0U1vr1q3l6+urQYMGadu2bbkSGAAAAAD3k2sbaIWEhGjfPnNbXgEAAAC5weWD0jyMywnErl27HF5blqW4uDiNGzdOERERuRVXlmbOnKmQkJCbOgYAAACA63M5gYiIiJDNZtPfz5+76667NHfu3BwFMW3atCzbbTab/P39VblyZTVr1kzdunXLUf8AAABAdlEC4ZzLCURMTIzDay8vL5UsWVL+/v45DmLy5MmKj49XUlKSgoKCJP1VrF2oUCEFBATo9OnTqlixojZs2MAhcgAAAIBBLi/xKleunMNVtmzZG0oeJGnMmDGqV6+eDhw4oDNnzujMmTPav3+/GjRooKlTp+ro0aMKDQ3VwIEDb2gcAAAAADcm2wnE+vXrVaNGDSUmJma6d/78edWsWVP//e9/cxTE0KFDNXnyZFWqVMneVrlyZb3zzjsaPHiwbrvtNk2YMEE//PBDjvoHAAAAssvLZjN25QfZTiCmTJmi3r17q0iRIpnuFS1aVH369NGkSZNyFERcXJxSU1MztaempurkyZOSpNKlS+vChQs56h8AAABA7sh2ArFz507de++9173fpk2bHJ8B0aJFC/Xp00c7duywt+3YsUP9+vVTy5YtJUm//vqrKlSokKP+AQAAgOyy2cxd+UG2E4hTp07Jx8fnuvcLFCig+Pj4HAUxZ84cFS9eXJGRkfLz85Ofn5+ioqJUvHhxzZkzR5IUEBCgiRMn5qh/AAAAALkj27swlSlTRrt371blypWzvL9r1y6FhYXlKIjQ0FCtXbtW+/btsx9GV61aNVWrVs3+TIsWLXLUNwAAAIDck+0Eol27dho2bJjuvffeTLsuXb58WSNGjND9999/Q8H8PWkAAAAA8ppXPllKZEq2lzANHTpUf/75p6pWraoJEyboyy+/1Jdffqnx48erWrVq+vPPPzVkyJAcBdG5c2eNHz8+U/uECRPUpUuXHPUJAAAAIPdlewYiJCREmzZtUr9+/TR48GD7SdQ2m01t27bVe++9p5CQkBwFsXHjRo0cOTJT+3333UfdAwAAAPJUftlO1RSXTqIuV66cvvnmG509e1YHDx6UZVmqUqWK/fTonLp48aJ8fX0ztfv4+GR57gQAAAAAM1w+iVqSgoKCVK9ePdWvX/+GkwdJql27tpYuXZqpfcmSJapRo8YN9w8AAABkF9u4OpetGYi+fftq6NChuu222/7x2aVLlyo1NVWPP/54toMYNmyYOnXqpEOHDtnPfYiOjtbixYu1bNmybPcDAAAA4ObKVgJRsmRJ1axZU40bN1aHDh0UFRWl0qVLy9/fX2fPntXvv/+u77//XkuWLFHp0qU1a9Ysl4Lo0KGDVqxYoTFjxuizzz5TwYIFFR4ernXr1ql58+Y5+sIAAAAA5D6bda0a+h+cOnVKH374oZYsWaLff//d4V5gYKBatWqlZ555xulp1Xllz4lLpkNAHjp2Psl0CMhDH++IMx0C8tCsR8JNhwDgJvF3qRI3b70VfdDY2EPuyfrMNXfi0i5MQ4YM0ZAhQ3T27FkdPXpUly9fVnBwsCpVqiRbLi3aunjxotLT0x3aihQpkit9AwAAALgxOcr9goKCcqV4+pqYmBg9//zz+u6773TlyhV7u2VZstlsSktLy7WxAAAAAGdsyifVzIa4xeTRE088IcuyNHfuXIWEhOTabAYAAACA3OUWCcTOnTu1bds2VatWzXQoAAAAAJzI0TkQua1evXo6duyY6TAAAAAAednMXfmBW8xAfPjhh+rbt6+OHz+uWrVqycfHx+F+eDi7cAAAAADuwOUEYsSIEXr66adVrly5XAsiPj5ehw4dUs+ePe1tNpuNImoAAADkufwyE2CKy0uYvvzyS1WqVEn33HOPFi1apOTk5BsO4umnn1bdunW1efNmHT58WDExMQ7/DwAAAMA9uDwD8csvv2jHjh2aN2+eXnzxRfXv31+PPvqonn76adWrVy9HQcTGxmrlypWqXNn9D84AAAAAPFmOiqjr1q2radOm6cSJE5ozZ47++OMPNW7cWOHh4Zo6darOnz/vUn8tW7bUzp07cxIKAAAAkKtsNpuxKz+4oSJqy7J09epVpaSkyLIsBQUFafr06Ro2bJhmz56trl27ZqufDh06aODAgfr1119Vu3btTEXUDzzwwI2ECQAAACCX5CiB2LZtm+bNm6fFixfLz89P3bt313vvvWdfgvTuu+9qwIAB2U4g+vbtK0kaPXp0pnsUUQMAACAvUUTtnMsJRO3atbV37161adNGc+bMUYcOHeTt7e3wzGOPPaYXX3wx232mp6e7GgYAAAAAA1yugXjkkUd05MgRff311+rYsWOm5EGSgoOD/zEpKF68uBISEiT9tQvThQsXXA0FAAAAyHU2m7krP3Apgbh69armz5+vxMTEGx44JSXF3s+CBQt05cqVG+4TAAAAwM3l0hImHx+fXPug37BhQ3Xs2FGRkZGyLEsDBgxQwYIFs3x27ty5uTImAAAAgBvj8hKm/v37a/z48UpNTb2hgT/++GO1a9dOFy9elM1m0/nz53X27NksLwAAACCveNlsxq78wOUi6i1btig6Olpr1qxR7dq1VbhwYYf7y5cvz1Y/ISEhGjdunCSpQoUKWrhwoUqUKOFqOAAAAADykMsJRLFixdS5c+dcDSImJkbR0dGKjo7W6dOnHQqwbTab5syZk6vjAQAAANfDNq7OuZxAzJs3L9eDGD16tEaNGqWoqCiFhYXlm1P4AAAAAE/jcg2EJKWmpmrdunWaOXOmffvVEydO6OLFizkKYsaMGZo/f75++uknrVixQl988YXDBQAAACBr7733nsqXLy9/f381aNBAP//8c7bet2TJEtlsNnXs2NGl8VxOIGJjY1W7dm09+OCD6t+/v+Lj4yVJ48eP18svv+xqd5L+2tK1UaNGOXovAAAAkJvy0zkQS5cu1aBBgzRixAht375dderUUdu2bXX69Gmn7zty5IhefvllNW3a1OUxXU4gXnzxRUVFRens2bMO264+9NBDio6OdjkASXrmmWe0aNGiHL0XAAAA8FSTJk1S79691bNnT9WoUUMffPCBChUq5PQYhLS0ND3++OMaNWqUKlas6PKYLtdA/Pe//9WmTZvk6+vr0F6+fHkdP37c5QAk6cqVK5o1a5bWrVun8PBw+fj4ONyfNGlSjvoFAAAAXOUlc/W4ycnJSk5Odmjz8/OTn59fpmdTUlK0bds2DR482N7m5eWlVq1aafPmzdcdY/To0SpVqpR69eql//73vy7H6HICkZ6errS0tEztf/zxhwIDA10OQJJ27dqliIgISdLu3bsd7uWkoLqgn3eO4kD+VNw/879QuHXdW7246RCQh77bF286BOShu6uVNB0CYNzYsWM1atQoh7YRI0Zo5MiRmZ5NSEhQWlqaQkJCHNpDQkK0d+/eLPv//vvvNWfOHP3yyy85jtHlBKJNmzaaMmWKZs2aJemvD/gXL17UiBEj1K5duxwFsWHDhhy9DwAAAMhtJjcEHTx4sAYNGuTQltXsQ05cuHBBTz75pGbPnq3g4OAc9+NyAjFx4kS1bdtWNWrU0JUrV9StWzcdOHBAwcHBWrx4cY4DAQAAADzd9ZYrZSU4OFje3t46deqUQ/upU6cUGhqa6flDhw7pyJEj6tChg73t2vlrBQoU0L59+1SpUqV/HNflBOK2227Tzp07tWTJEu3atUsXL15Ur1699PjjjzsUVQMAAAC4eXx9fRUZGano6Gj7Vqzp6emKjo7W888/n+n56tWr69dff3VoGzp0qC5cuKCpU6eqbNmy2RrX5QRC+itDeeKJJ3LyVgAAAMCt5aeTqAcNGqQePXooKipK9evX15QpU3Tp0iX17NlTktS9e3eVKVNGY8eOlb+/v2rVquXw/mLFiklSpnZnXE4gPvroI6f3u3fv7mqXdtcqznNrnRcAAABwK+vatavi4+M1fPhwnTx5UhEREVq1apW9sPro0aPy8srR2dHXZbMsy3LlDUFBQQ6vr169qqSkJPn6+qpQoUL6888/XQpg7dq1mjx5sjZv3qzExERJUpEiRdSwYUMNGjRIrVq1cqk/STpy5orL70H+lZCYYjoE5KH9ZxNNh4A8VJxfKHkUdmHyLP45WgeTN2b9GGts7GfvKmds7OxyOR05e/asw3Xx4kXt27dPTZo0cbmIesGCBWrXrp2KFi2qyZMn66uvvtJXX32lyZMnq1ixYmrXrp0WLlzoaogAAAAAbhKXZyCuZ+vWrXriiSeuu+dsVqpWraoXX3xR/fv3z/L++++/r8mTJ+vAgQMuxcIMhGdhBsKzMAPhWZiB8CzMQHgWZiCydkvOQFxPgQIFdOLECZfec/ToUadLlO655x798ccfNxoaAAAAkG02m7krP3A591u5cqXDa8uyFBcXp+nTp6tx48Yu9VWzZk3NmTNHEyZMyPL+3LlzVaNGDVdDBAAAAHCTuJxAXNtj9hqbzaaSJUuqZcuWmjhxokt9TZw4Uffff79WrVqlVq1a2avFT506pejoaB0+fFhff/21qyECAAAAOeaVX6YCDHE5gbh2Wl1uuPvuu7V7927NmDFDP/74o06ePClJCg0N1X333ae+ffuqfPnyuTYeAAAAgBuT4/KVhIQE+fr6qkiRIjcUQPny5TV+/Pgb6gMAAADILUxAOOdSEfW5c+fUv39/BQcHKyQkREFBQQoNDdXgwYOVlJR0Q4EcPXpUP/30k7Zs2aIzZ87cUF8AAAAAbo5sz0D8+eefatiwoY4fP67HH39cd9xxhyTp999/17vvvqu1a9fq+++/165du/Tjjz9qwIAB2er3/fff1/jx4zPtttSwYUNNnTpVkZGRLnw5AAAAAG6mbCcQo0ePlq+vrw4dOmQvds54r02bNnryySe1Zs0aTZs2LVt9vvPOO5o8ebIGDx4sf39/TZo0SY899pjq1aunRYsWqVmzZvq///s/RUVFufZVAQAAADmUa+cc3KKynUCsWLFCM2fOzJQ8SH8VPU+YMEHt2rXTiBEj1KNHj2z1+d577+nDDz/UfffdJ0lq1qyZGjVqpJMnT+ree+9VUFCQXn/9da1Zsya7YQIAAAC4ibKdQMTFxalmzZrXvV+rVi15eXlpxIgR2R789OnT9qVQklSlShWdP39e8fHxCgsL09NPP60mTZpkuz8AAADgRtmoonYq2zM0wcHBOnLkyHXvx8TEqFSpUi4NXrVqVa1du9b+esOGDfL19VVoaKgkyd/fnx8gAAAA4EayPQPRtm1bDRkyRGvXrpWvr6/DveTkZA0bNkz33nuvS4MPHjxYTzzxhNatWyd/f38tX75cAwYMsCcN3333nWrVquVSnwAAAABuHptlWVZ2Hvzjjz8UFRUlPz8/9e/fX9WrV5dlWdqzZ4/ef/99JScna8uWLbr99ttdCuDbb7/Vxx9/rOTkZLVt21a9e/e237u2nWuJEiVc6vPImSsuPY/8LSExxXQIyEP7zyaaDgF5qLifn+kQkIfurlbSdAjIQ/45Po3s5vto6zFjY3ePKmts7OzKdgIh/bVM6bnnntOaNWt07W02m02tW7fW9OnTVbly5ZsWqCtIIDwLCYRnIYHwLCQQnoUEwrOQQGQtPyQQLv3oKlSooG+//VZnz57VgQMHJEmVK1dW8eLFbyiIS5cuadu2bYqLi5OXl5cqVqyoO++8k/oHAAAA5DkvPoM6laPcLygoSPXr17/hwdPT0/Xaa69p+vTpSk5OliT7zMbtt9+ud999Vx06dLjhcQAAAADkDqPnZLz++uv66quv9Omnn2r16tVq0qSJxo0bp99//13du3dXly5dOAMCAAAAecpm8MoPXKqByG2lS5fW0qVL1bRpU0nS8ePHVb16dSUkJMjPz09vvPGGvv32W23atMmlfqmB8CzUQHgWaiA8CzUQnoUaCM/izjUQn2z7w9jYj0feZmzs7DI6A3Hx4kWVKVPG/josLExXrlzR2bNnJUmdO3fWzp07TYUHAAAA4G+MJhC1a9fW4sWL7a8//fRTBQQE2A+SS09Plx+/fQIAAEAestnMXfmB0cmj0aNHq3379lq5cqX8/f21adMmvf322/b7q1atUt26dQ1GCAAAACAjozUQkrRz5059+umn9oPkWrdufcN9UgPhWaiB8CzUQHgWaiA8CzUQnsWdayAW7zhubOzH6pb554cMM/6jq1OnjurUqWM6DAAAAADZYLQGQvrr3IeYmBilpqZKklJSUrR06VJ99NFHSkhIMBwdAAAAgIyMzkDs27dPbdu21dGjR1WpUiWtWbNGXbp00d69e2VZlgoVKqRNmzapSpUqJsMEAACABzH+G3Y3Z/T78+qrr6pOnTrauXOn7r//frVv31633Xabzp49qz///FMNGzbU6NGjTYYIAAAAIAOjRdSlSpXSmjVrFBERoUuXLikwMFAbN25UkyZNJEmbNm3SY489ptjYWJf6pYjas1BE7VkoovYsFFF7FoqoPYs7F1F/+ssJY2M/ElHa2NjZZfwgueLFi0uSChcurMKFCyssLMx+v2zZsjp16pSp8AAAAAD8jdEEonTp0jp69Kj99YQJE1SqVCn76/j4eAUFBZkIDQAAAB7KZvDKD4wmEK1atdLevXvtr/v166fAwED76zVr1ujOO+80ERoAAACALBg/SM6ZmJgY+fv7Oyxryg5qIDwLNRCehRoIz0INhGehBsKzuHMNxDKDNRBd8kENhBv/6KQKFSqYDgEAAAAexmbLL4uJzDCeQCQkJGju3LnavHmzTp48KUkKDQ1Vo0aN9NRTT6lkSX4bAQAAALgLozUQW7ZsUdWqVTVt2jQVLVpUzZo1U7NmzVS0aFFNmzZN1atX19atW02GCAAAAA/jZfDKD4zOQLzwwgvq0qWLPvjgg0xTRZZlqW/fvnrhhRe0efNmQxECAAAAyMhoArFz507Nnz8/y3VmNptNAwcOVN26dQ1EBgAAACArRmdKQkND9fPPP1/3/s8//6yQkJA8jAgAAACezmazGbvyA6MzEC+//LKeffZZbdu2Tffcc489WTh16pSio6M1e/ZsvfPOOyZDBAAAAJCB0QSif//+Cg4O1uTJk/X+++8rLS1NkuTt7a3IyEjNnz9fjzzyiMkQAQAA4GHyxzyAOca3ce3atau6du2qq1evKiEhQZIUHBwsHx8fw5EBAAAA+DvjCcQ1Pj4+Kl68uP2fAQAAABPySSmCMca3m127dq3atWunoKAgFSpUSIUKFVJQUJDatWundevWmQ4PAAAAQAZGE4gFCxaoXbt2Klq0qCZPnqyvvvpKX331lSZPnqxixYqpXbt2WrhwockQAQAAAGRgdAnTW2+9pSlTpqh///6Z7j311FNq0qSJRo8erSeffNJAdAAAAPBEXpRRO2V0BuLo0aNq1arVde/fc889+uOPP/IwIgAAAADOGE0gatasqTlz5lz3/ty5c1WjRo08jAgAAACezmYzd+UHRpcwTZw4Uffff79WrVqlVq1aZTpI7vDhw/r6669NhggAAAAgA6MJxN13363du3drxowZ+vHHH3Xy5ElJUmhoqO677z717dtX5cuXNxkiAAAAgAyMnwNRvnx5jR8/3nQYAAAAgCTJRhG1U8bPgQAAAACQfxhPIN5//321atVKjzzyiKKjox3uJSQkqGLFioYiAwAAgCeiiNo5ownEtGnT9O9//1vVq1eXn5+f2rVrp7Fjx9rvp6WlKTY21mCEAAAAADIyWgMxc+ZMzZ49W926dZMk9evXTx07dtTly5c1evTobPWRnJys5OTkv7VZ8vPzy/V4AQAAAE9ndAYiJiZGjRo1sr9u1KiR1q9fr1mzZmnw4MHZ6mPs2LEqWrSowzVjyts3K2QAAADc4rxkM3blB0ZnIIKDg3Xs2DGHrVpr1aql9evXq2XLljpx4sQ/9jF48GANGjTIoS3uopXboQIAAACQ4QSiSZMmWr58uZo2berQXqNGDUVHR6tFixb/2Iefn1+m5Up/Xr2Sq3ECAADAc+SXYmZTjCYQr732mrZt25blvZo1a2r9+vX6/PPP8zgqAAAAANdjNIEIDw9XeHj4de/XqlVLtWrVysOIAAAA4OmYgXDO+DkQkpSenn7d9qNHj+ZxNAAAAACux2gCkZiYqEceeUSFCxdWSEiIhg8frrS0NPv9+Ph4VahQwWCEAAAAADIyuoRp2LBh2rlzpxYuXKhz587pzTff1Pbt27V8+XL5+vpKkiyLHZUAAACQd2z5ZDtVU4zOQKxYsUIzZ87Uww8/rGeeeUZbt25VfHy8OnToYD8czsYiNAAAAMBtGE0g4uPjVa5cOfvr4OBgrVu3ThcuXFC7du2UlJRkMDoAAAB4Ii+buSs/MJpA3H777dqzZ49DW2BgoNasWaPLly/roYceMhQZAAAAgKwYTSDatGmjefPmZWoPCAjQ6tWr5e/vbyAqAAAAANdjtIh61KhROnHiRJb3AgMDtXbtWm3fvj2PowIAAIAno4jaOaMzEEFBQapZs+Z17wcGBqp58+b217Vr19axY8fyIjQAAAAAWTA6A+GqI0eO6OrVq6bDAAAAwC2MTUCdc4uTqAEAAADkD/lqBgIAAAC42aiBcI4ZCAAAAADZRgIBAAAAINtYwgQAAABkkF9OhDYlX81AzJw5UyEhIabDAAAAADyWW8xATJs2Lct2m80mf39/Va5cWc2aNVO3bt3yODIAAAB4GoqonXOLBGLy5MmKj49XUlKSgoKCJElnz55VoUKFFBAQoNOnT6tixYrasGGDypYtazhaAAAAwHO5xRKmMWPGqF69ejpw4IDOnDmjM2fOaP/+/WrQoIGmTp2qo0ePKjQ0VAMHDjQdKgAAAODRbJZlWaaDqFSpkj7//HNFREQ4tO/YsUOdO3fW4cOHtWnTJnXu3FlxcXH/2N+RM1duUqRwRwmJKaZDQB7afzbRdAjIQ8X9/EyHgDx0d7WSpkNAHvJ3i3UwWfv+wFljYzepEmRs7OxyixmIuLg4paamZmpPTU3VyZMnJUmlS5fWhQsX8jo0AAAAABm4RQLRokUL9enTRzt27LC37dixQ/369VPLli0lSb/++qsqVKhgKkQAAAB4CJvBKz9wiwRizpw5Kl68uCIjI+Xn5yc/Pz9FRUWpePHimjNnjiQpICBAEydONBwpAAAA4NncYvVZaGio1q5dq3379mnfvn2SpGrVqqlatWr2Z1q0aGEqPAAAAHgQL1t+mQswwy0SiGv+njQAAAAAcC9usYSpc+fOGj9+fKb2CRMmqEuXLgYiAgAAAJAVt0ggNm7cqHbt2mVqv++++7Rx40YDEQEAAMBTUUTtnFskEBcvXpSvr2+mdh8fHyUmsuc7AAAA4C7cIoGoXbu2li5dmql9yZIlqlGjhoGIAAAA4LGYgnDKLYqohw0bpk6dOunQoUP2cx+io6O1ePFiLVu2zHB0AAAAAK5xiwSiQ4cOWrFihcaMGaPPPvtMBQsWVHh4uNatW6fmzZubDg8AAADA/7hFAiFJ7du3V/v27U2HAQAAAA9nyy9riQxxmwTimosXLyo9Pd2hrUiRIoaiAQAAAJCRWyQQMTExev755/Xdd9/pypUr9nbLsmSz2ZSWlmYwOgAAAHgSDqJ2zi0SiCeeeEKWZWnu3LkKCQmRjZ8aAAAA4JbcIoHYuXOntm3bpmrVqpkOBQAAAB6OX2U75xbnQNSrV0/Hjh0zHQYAAACAf+AWMxAffvih+vbtq+PHj6tWrVry8fFxuB8eHm4oMgAAAAAZuUUCER8fr0OHDqlnz572NpvNRhE1AAAA8h5rmJxyiwTi6aefVt26dbV48WKKqAEAAAA35hYJRGxsrFauXKnKlSubDgUAAAAejoPknHOLIuqWLVtq586dpsMAAAAA8A/cYgaiQ4cOGjhwoH799VfVrl07UxH1Aw88YCgyAAAAABnZLMuyTAfh5XX9iZCcFFEfOXPlnx/CLSMhMcV0CMhD+88mmg4Beai4n5/pEJCH7q5W0nQIyEP+bvFr7KxtO2LuvzWR5YsYGzu73OJHl56ebjoEAAAAANlgrAaiePHiSkhIkPTXLkwXLlwwFQoAAABgZzN45QfGEoiUlBQlJv41PbRgwQJducKyIwAAAMDdGVvC1LBhQ3Xs2FGRkZGyLEsDBgxQwYIFs3x27ty5eRwdAAAAPFZ+mQowxFgC8fHHH2vy5Mk6dOiQbDabzp8/zywEAAAA4ObcYhemChUqaOvWrSpRokSu9McuTJ6FXZg8C7sweRZ2YfIs7MLkWdx5F6btseb+W3NnOXZhypaYmBhFR0crOjpap0+fdtiVyWazac6cOQajAwAAgCfhJGrn3CKBGD16tEaNGqWoqCiFhYXJZuOHBgAAALgjt0ggZsyYofnz5+vJJ580HQoAAAA8HL/Lds7YNq4ZpaSkqFGjRqbDAAAAAPKd9957T+XLl5e/v78aNGign3/++brPzp49W02bNlVQUJCCgoLUqlUrp89nxS0SiGeeeUaLFi0yHQYAAACQryxdulSDBg3SiBEjtH37dtWpU0dt27bV6dOns3z+u+++02OPPaYNGzZo8+bNKlu2rNq0aaPjx49ne0y32IXpxRdf1EcffaTw8HCFh4fLx8fH4f6kSZNc6o9dmDwLuzB5FnZh8izswuRZ2IXJs7jzLkw7j14wNnad2wNder5BgwaqV6+epk+fLklKT09X2bJl9cILL+i11177x/enpaUpKChI06dPV/fu3bM1plv86Hbt2qWIiAhJ0u7dux3uUVANAAAAT5GcnKzk5GSHNj8/P/ll8QuVlJQUbdu2TYMHD7a3eXl5qVWrVtq8eXO2xktKStLVq1dVvHjxbMfoFgnEhg0bcrW/lNT0f34ItwyfAiSZniQ8pJjpEJCH0tKNT5IjD/146E/TISAP3V0t+x9Y85zBjxZjx47VqFGjHNpGjBihkSNHZno2ISFBaWlpCgkJcWgPCQnR3r17szXeq6++qtKlS6tVq1bZjtEtEggAAAAA0uDBgzVo0CCHtqxmH3LDuHHjtGTJEn333Xfy9/fP9vtIIAAAAIAMTB4kd73lSlkJDg6Wt7e3Tp065dB+6tQphYaGOn3vO++8o3HjxmndunUKDw93KUa32IUJAAAAgGt8fX0VGRmp6Ohoe1t6erqio6PVsGHD675vwoQJeuONN7Rq1SpFRUW5PC4zEAAAAEA+NWjQIPXo0UNRUVGqX7++pkyZokuXLqlnz56SpO7du6tMmTIaO3asJGn8+PEaPny4Fi1apPLly+vkyZOSpICAAAUEBGRrTBIIAAAAIIP8tAlo165dFR8fr+HDh+vkyZOKiIjQqlWr7IXVR48elZfX/190NGPGDKWkpOjhhx926Od6hdpZcYtzIHLb/lNJpkNAHrqckmY6BOQhb6989Lc6bhi7MHmWs0lXTYeAPOTOuzD9+sdFY2PXvi17swAmMQMBAAAAZMCvqpyjiBoAAABAtrnFDMSlS5e0bds2xcXFycvLSxUrVtSdd97JKdQAAACAmzGaQKSnp+u1117Te++9pytXrkiSrpVk3H777Xr33XfVoUMHkyECAADA0/A7bKeMLmF6/fXX9dVXX2np0qVavXq1mjRponHjxun3339X9+7d1aVLF61Zs8ZkiAAAAAAyMLoLU+nSpbV06VI1bdpUknT8+HFVr15dCQkJ8vPz0xtvvKFvv/1WmzZtcqlfdmHyLOzC5FnYhcmzsAuTZ2EXJs/izrsw/Xb8krGxa5YpbGzs7DI6A3Hx4kWVKVPG/josLExXrlzR2bNnJUmdO3fWzp07TYUHAAAA4G+MJhC1a9fW4sWL7a8//fRTBQQEKDQ0VNJfNRJ+fn6mwgMAAADwN0aLqEePHq327dtr5cqV8vf316ZNm/T222/b769atUp169Y1GCEAAAA8DRuBOmf8JOqdO3fq008/VXJystq2bavWrVvfcJ/UQHgWaiA8CzUQnoUaCM9CDYRncecaiN9PmKuBqFHa/WsgjJ8DUadOHdWpU8d0GAAAAIAkdnH9J8YTiIzOnTunZcuW6ejRoypXrpy6dOmiokWLmg4LAAAAwP8YLaLu1KmTPvvsM0nSb7/9pipVqmjIkCFau3athg4dqurVq2vPnj0mQwQAAICnsRm88gGjCcR3332nWrVqSZL+/e9/q02bNvrjjz/0448/6tixY2rfvr1eeuklkyECAAAAyMDoEqYrV67Ix8dHkvTLL7/o66+/lq+vryTJx8dHr7zyiurXr28yRAAAAAAZGJ2BCA8P1/r16yVJoaGhio2NdbgfGxurggULmggNAAAAHspm8H/5gdEZiGHDhql79+7y8fHRgAEDNHDgQJ05c0Z33HGH9u3bpxEjRujJJ580GSIAAACADIyfA/H555/rpZde0okTJ5QxFD8/P/Xt21fvvPOOvL29XeqTcyA8C+dAeBbOgfAsnAPhWTgHwrO48zkQ+06a+yxZLbSQsbGzy3gCIUlpaWnatm2bYmJilJ6errCwMEVGRiowMDBH/ZFAeBYSCM9CAuFZSCA8CwmEZyGByFp+SCDc4hwIb29v1a9fn4JpAAAAwM25RQKxfv16ff/994qLi5OXl5cqVqyoBx54QFWqVDEdGgAAADwMc93OGV3CdPr0aXXo0EFbt26Vl5eX0tPTVbduXR0/flzx8fEaNGiQJkyY4HK/LGHyLCxh8iwsYfIsLGHyLCxh8izuvIRpv8ElTFXzwRImo9u4DhgwQKVLl9bZs2d18eJFPffcc6pZs6bi4uK0Zs0azZ07V1OnTjUZIgAAADwNJ1E7ZXQGomjRotq0aZNq1qwpSbp06ZKCgoKUkJCgIkWK6OOPP9abb76pvXv3utQvMxCehRkIz8IMhGdhBsKzMAPhWdx6BsLgZ8mqIe4/A2G0BsLPz0822///MODl5aW0tDSlpqZKkho1aqQjR44Yig4AAACeKL8c6GaK0SVMTZo00fDhw3Xp0iVdvXpVr7/+uipWrKjixf/KSOPj4xUUFGQyRAAAAAAZGJ2BeOedd9SmTRsVK1ZMNptNhQsX1rJly+z39+zZo6eeespcgAAAAAAcGD9ILikpST/88IOSk5N11113KTg4+Ib7pAbCs1AD4VmogfAs1EB4FmogPIs710AcPH3Z2NiVSxU0NnZ2GT8HolChQmrdurXpMAAAAABkg/EEIqNLly7p008/1cGDBxUWFqbHHntMJUqUMB0WAAAAPAhz3c4ZTSBq1Kih77//XsWLF9exY8fUtGlTnTt3TlWrVtWhQ4f0xhtv6Mcff1SFChVMhgkAAADgf4zuwrR37177lq2DBw9WmTJlFBsbq59//lmxsbEKDw/XkCFDTIYIAAAAIAO3WcK0efNmffDBBypatKgkKSAgQKNGjdKjjz5qODIAAAB4FNYwOWV0BkKS/SC5K1euKCwszOFemTJlFB8fbyIsAAAAAFkwPgNxzz33qECBAkpMTNS+fftUq1Yt+73Y2FiKqAEAAJCnOInaOaMJxIgRIxxeBwQEOLz+z3/+o6ZNm+ZlSAAAAACcMH6Q3M3AQXKehYPkPAsHyXkWDpLzLBwk51nc+SC5mIQrxsauEOxvbOzsMl4DAQAAACD/MJ5AfPjhh+rRo4fmzZsnSVq6dKnuuOMOVaxYMdMSJwAAAABmGa2BmDJlioYOHaq2bdtqyJAhOnHihCZPnqyBAwcqLS1NEydOVJkyZfTss8+aDBMAAAAehMWyzhlNIGbOnKlZs2apW7du2rFjh+rXr68PPvhAvXr1kvTXNq4zZswggQAAAADchNElTLGxsWrSpIkkqW7duvL29tZdd91lv9+8eXMdOnTIVHgAAADwRDaDVz5gNIEoVKiQLl26ZH9dsmTJTFu5pqam5nVYAAAAAK7DaAJRvXp17dq1y/762LFjKleunP313r17Vb58eQORAQAAAMiK0RqI8ePHq3Dhwte9f/ToUfXp0ycPIwIAAICn4yRq5zhIDvkeB8l5Fg6S8ywcJOdZOEjOs7jzQXKxZ5KNjV2uhJ+xsbPL6BKmhIQEk8MDAAAAmdhs5q78wGgCERISonvuuUeLFi1ScrK5TA8AAABA9hhNICzLkq+vr3r27KmwsDC98MIL+uWXX0yGBAAAAA/HLq7OGU0gJGnBggU6fvy4hgwZovXr1ysyMlKRkZGaMWOGEhMTTYcHAAAAIAPjCYQkBQcH61//+pd+++03ff/994qIiNCrr76qsLAwde/e3XR4AAAAAP7HaAJhy6JSpGHDhpozZ47i4uI0bdo0TqIGAABAnqKI2jmj27h6eXnp5MmTKlWqVK72yzaunoVtXD0L27h6FrZx9Sxs4+pZ3Hkb1z/Omtvc57Yg99/G1ehBcvPmzVPRokVvqI/k5ORMOzilJKfJ18/9v/kAAABwR/yyyhmjS5h69Oghvxv8oD927FgVLVrU4Zo57Z1cihAAAABARm55EnXLli01b948lStX7h+fzWoG4ug5ZiA8CUuYPAtLmDwLS5g8C0uYPIt7L2FKMTb2bUG+xsbOLqNLmFauXJll+8aNG/XVV1+pbNmykqQHHnjgun34+fllmsXwvUwNBAAAAHImvxQzm2K8iNpms8lZCDabTWlprv2GmSJqz8IMhGdhBsKzMAPhWZiB8CzuPANx/Jy5GYgyxdx/BsJoDUTbtm1133336eTJk0pPT7df3t7e2r17t9LT011OHgAAAIAbwUnUzhlNIL799lvdc889ioqK0ldffWUyFAAAAADZYPwk6oEDB2rlypV69dVX1adPHyUlsfwIAAAA5nCQnHPGEwhJioiI0NatW2Wz2RQREeG0JgIAAACAOUZ3YcqoYMGC+uCDD7Ry5Upt2LBBwcHBpkMCAAAA8DdueQ7E9dSuXVvffPONfXvX62EXJs/CLkyehV2YPAu7MHkWdmHyLO68C9PJ8+b+LIYW9TE2dna5xRKm7Dpy5IiuXuUvFwAAAMAUt1nCBAAAALgFJrudylczEAAAAADMIoEAAAAAkG0sYQIAAAAyYAWTc8xAAAAAAMi2fDUDMXPmTIWEhJgOAwAAALew/HIitClukUBMmzYty3abzSZ/f39VrlxZzZo1U7du3fI4MgAAAAAZuUUCMXnyZMXHxyspKUlBQUGSpLNnz6pQoUIKCAjQ6dOnVbFiRW3YsOEfD5EDAAAAboSNKgin3KIGYsyYMapXr54OHDigM2fO6MyZM9q/f78aNGigqVOn6ujRowoNDdXAgQNNhwoAAAB4NJtlWZbpICpVqqTPP/9cERERDu07duxQ586ddfjwYW3atEmdO3dWXFzcP/a3/1TSTYoU7uhySprpEJCHvL34rZAnSUs3/p8o5KGzSVdNh4A8dHe14qZDuK74C6nGxi4Z6BYLhJxyiwjj4uKUmpr5B5WamqqTJ09KkkqXLq0LFy7kdWgAAADwNPyuyim3WMLUokUL9enTRzt27LC37dixQ/369VPLli0lSb/++qsqVKhgKkQAAAAAcpMEYs6cOSpevLgiIyPl5+cnPz8/RUVFqXjx4pozZ44kKSAgQBMnTjQcKQAAAG51NoNXfuAWNRDX7Nu3T/v27ZMkVatWTdWqVctRP9RAeBZqIDwLNRCehRoIz0INhGdx5xqIhIvmaiCCA9yiwsApt4rwRpIGAAAAADefWyxh6ty5s8aPH5+pfcKECerSpYuBiAAAAOCpbDZzV37gFgnExo0b1a5du0zt9913nzZu3GggIgAAAABZcYslTBcvXpSvr2+mdh8fHyUmJhqICAAAAJ6Kk6idc4sZiNq1a2vp0qWZ2pcsWaIaNWoYiAgAAABAVtxiBmLYsGHq1KmTDh06ZD/3ITo6WosXL9ayZcsMRwcAAADgGrdIIDp06KAVK1ZozJgx+uyzz1SwYEGFh4dr3bp1at68uenwAAAA4EHySzGzKW51DkRu4RwIz8I5EJ6FcyA8C+dAeBbOgfAs7nwOxNkkc58tggp5Gxs7u9xiBiKjixcvKj093aGtSJEihqIBAAAAkJFbFFHHxMSoffv2Kly4sIoWLaqgoCAFBQWpWLFiCgoKMh0eAAAAgP9xixmIJ554QpZlae7cuQoJCZGNhWcAAAAwhI+izrlFArFz505t27ZN1apVMx0KAAAAACfcYglTvXr1dOzYMdNhAAAAAPgHbjED8eGHH6pv3746fvy4atWqJR8fH4f74eHhhiIDAACAp+EkaufcIoGIj4/XoUOH1LNnT3ubzWaTZVmy2WxKS2ObTgAAAMAduEUC8fTTT6tu3bpavHgxRdQAAAAwio+izrlFAhEbG6uVK1eqcuXKpkMBAAAA4IRbFFG3bNlSO3fuNB0GAAAAgH/gFjMQHTp00MCBA/Xrr7+qdu3amYqoH3jgAUORAQAAwNOwgsk5m2VZlukgvLyuPxGSkyLq/aeSbjQk5COXUyiy9yTeXvy17knS0o3/Jwp56GzSVdMhIA/dXa246RCu68KVdGNjB/q7xQIhp9xiBiI93dwPCQAAAHDA76qcMpbiFC9eXAkJCZL+2oXpwoULpkIBAAAAkE3GEoiUlBQlJiZKkhYsWKArV66YCgUAAACwsxn8X35gbAlTw4YN1bFjR0VGRsqyLA0YMEAFCxbM8tm5c+fmcXQAAAAAsmIsgfj44481efJkHTp0SDabTefPn2cWAgAAAHBzbrELU4UKFbR161aVKFEiV/pjFybPwi5MnoVdmDwLuzB5FnZh8izuvAvTpRRzf/cU9nX//865xS5MMTExio6OVnR0tE6fPu2wK5PNZtOcOXMMRgcAAADgGrdIIEaPHq1Ro0YpKipKYWFhstncP/MCAADArYlPos65RQIxY8YMzZ8/X08++aTpUAAAAAA44RZH3aWkpKhRo0amwwAAAADwD9wigXjmmWe0aNEi02EAAAAAf61hMnXlA26xhOnKlSuaNWuW1q1bp/DwcPn4+DjcnzRpkqHIAAAAAGTkFgnErl27FBERIUnavXu3wz0KqgEAAJCX8suJ0Ka4RQKxYcMG0yEAAAAA+dJ7772nt99+WydPnlSdOnX07rvvqn79+td9ftmyZRo2bJiOHDmiKlWqaPz48WrXrl22x3OLGggAAADAXdhs5i5XLV26VIMGDdKIESO0fft21alTR23bttXp06ezfH7Tpk167LHH1KtXL+3YsUMdO3ZUx44dM60Ccvr9cYeTqHMbJ1F7Fk6i9iycRO1ZOInas3AStWdx55Oor6SaG9vfxfVBDRo0UL169TR9+nRJUnp6usqWLasXXnhBr732Wqbnu3btqkuXLumrr76yt911112KiIjQBx98kK0xmYEAAAAA3ERycrISExMdruTk5CyfTUlJ0bZt29SqVSt7m5eXl1q1aqXNmzdn+Z7Nmzc7PC9Jbdu2ve7zWXGLGojcVjWkkOkQ8lxycrLGjh2rwYMHy8/Pz3Q4uMn4eXsWft6ehZ+3Z+Hn7Z5cnQXITSPfHKtRo0Y5tI0YMUIjR47M9GxCQoLS0tIUEhLi0B4SEqK9e/dm2f/JkyezfP7kyZPZjpEZiFtEcnKyRo0add0MFbcWft6ehZ+3Z+Hn7Vn4eePvBg8erPPnzztcgwcPNh2Wg1tyBgIAAADIj/z8/LI9GxUcHCxvb2+dOnXKof3UqVMKDQ3N8j2hoaEuPZ8VZiAAAACAfMjX11eRkZGKjo62t6Wnpys6OloNGzbM8j0NGzZ0eF6S1q5de93ns8IMBAAAAJBPDRo0SD169FBUVJTq16+vKVOm6NKlS+rZs6ckqXv37ipTpozGjh0rSXrxxRfVvHlzTZw4Ue3bt9eSJUu0detWzZo1K9tjkkDcIvz8/DRixAgKsDwEP2/Pws/bs/Dz9iz8vHGjunbtqvj4eA0fPlwnT55URESEVq1aZS+UPnr0qLy8/v+io0aNGmnRokUaOnSoXn/9dVWpUkUrVqxQrVq1sj3mLXkOBAAAAICbgxoIAAAAANlGAgEAAAAg20ggAAAAAGQbCQQAAACAbCOBAAAAAJBtJBAAAAAAso0Ews3t3bvXdAjIY+ysDAD5W8a/x/k7HbciEgg3tnDhQtWoUUOLFi0yHQrywKJFi7R7927ZbDbToSAPHD58WEePHtXvv//u0M6HjVtTUlKSrly5YjoM5JGMf4/bbDb+vcYthwTCTX3wwQfq1auXypcvr3Xr1unKlStKT083HRZuktmzZ+uJJ57QiRMnTIeCPDBv3jzdf//9at++vVq0aKFnn31Wu3fvlsSHjVvRokWL1K1bN0VGRuqFF17Ql19+aTok3EQrV65U//791adPH40cOVJpaWn8Ygi3HBIINzR79mw9//zz+vrrr/XWW2/p448/1rFjx+Tl5cUHi1vQrFmz1K9fPy1btkxt2rQxHQ5usi+//FKDBg3S6NGjtWDBAi1evFiLFy/WCy+8oK+//lqS+LBxC1m6dKmefvpp1a9fX/fee6+OHz+u7t27a+LEiaZDw02wYMECPf744ypQoIAkae7cuWrQoIE2bNiglJQUw9EBuciCW5k9e7Zls9ms5cuXW5ZlWampqVaDBg2sHj16WMnJyYajQ277/PPPLZvNZq1Zs8ayLMs6cOCANWXKFOuJJ56w3nvvPeuHH34wHCFyW//+/a0XX3zRsizLunr1qmVZltWrVy/Lz8/Patu2rbVlyxbLsiwrPT3dVIjIJampqdZjjz1mvfLKK/a2P/74w5owYYJls9mssWPHGowOue3w4cNW9erVrY8++sje9tNPP1kFChSwoqKirLVr1xqMDshdzEC4kaSkJB06dEgrVqzQQw89JMuyZLPZdPfdd2vLli06d+6cJLGU6RaRmpqqP/74Q5J08eJFnThxQm3bttV//vMfHTp0SLNnz2a5wy3m6tWr2rlzpy5duiTp/880hISEqF+/ftq5c6emT5/ucA/5V2pqqvbu3avk5GR7W5kyZdS/f39NnDhRI0eO1MKFCw1GiNx07tw5paamqtn/a+/O42rK+ziAf257aSMRpVIUWcu+ZcuaUsiWUMpStuzLWGfGbuxZWySUDGMrjHVKeDCJkiVlGbIW7ev9Pn947nncB89gkNP9vl+veY3Ocu8vX79zzvec3+977O0BvDlXm5qawt7eHi9fvsSkSZOEvk88moCJHCcQ34lHjx5BS0sLP/zwA5ydnYXlSkpKmDp1Kp49e4Y1a9YIy5h4yU4cKioqGDFiBFasWIG+ffvC2toagwcPRkREBOLi4rB161ZYWFggMDAQWVlZZdxq9iWoqqqiT58+OHLkCKKiolBaWoqIiAgsXrwYY8eORXh4OA4dOoRbt26VdVPZZ5L1byKCuro6nJ2dce7cOSQnJwvbaGlpwcPDA15eXti5c6dwc4iJm56eHrKzs3H8+HEAb87VMTExyMnJwcGDB5GZmYnFixcD4BsETPz4SvQ7EBYWht69eyM7OxsVKlQQTkASiQRSqRQGBgYYMWIETp06JdyxZuL19omjQoUKGDlyJNasWQMnJyd4e3ujUqVKAICmTZuiS5cuOHnyJDIzM8uquewfysjIwKNHj4SfHR0d0atXL/Tq1QtNmjTBsGHDEBwcDEtLS+jq6qKkpAR5eXll2GL2T8j6t+z/zZs3R2lpKUJDQ+WO35UrV0b79u0RGxuLly9flklb2T/3559/Ij8/HwBgaGiIfv36YdOmTejfvz+mTp2KwYMHY/To0ahfvz569eqFhw8flnGLGfsyVMq6AYpu69atGDVqFABg1apVmDt3rtwFpuxpQ8+ePfHLL7/g8uXLMDExKZO2sn/u1KlTiIuLQ05ODho3boyBAwdCW1sbHh4e6NmzJ8zMzAAApaWlUFZWRqVKlWBrawt9ff2ybTj7LLt378aGDRvw8OFDGBoaYvv27ahXrx6WL1+OIUOGICsrCxYWFrCxsQHwZsiLtbU1dHV1y7jl7HMcPXoU58+fh1QqRY0aNTBy5Ej07NkTycnJWLNmDVRUVDB06FDUrl0bAGBjY4NatWqhtLS0jFvOPkdwcDAWLFiAH374AV5eXtDR0cGECRNQp04dREZGoqioCAcPHkSPHj0AvBnSxBOpWXkhIR6IV2a2bNkCX19fhIaGIiEhAVeuXMHevXs/eLHo5eWF+Ph4nDhxAgYGBt+2sewfCwoKwtSpU9G5c2fcvn0bEokEnp6eGD9+/Hu3Ly4uhouLC3R0dLB7925+5C0ywcHBmDBhAhYsWID69etj8uTJMDExQVRU1DvbFhcXo7CwEH379gUR4ejRozxUUWRk8XZzc8OTJ09w7do1WFtbIyQkBCYmJli2bBm2b9+O2rVrY8CAATA1NcXChQuRm5uLP/74g+MtMuHh4fDy8sK2bdvg6uoKTU3Nd7bJzc1FhQoVAADZ2dlwdHREly5dMGfOnG/dXMa+vDKbvq3gVq1aRWpqarR//34iIjp79iwpKSnRnj17/u8+ffv25eosIhQdHU1Vq1aliIgIIiJ6/vw5jR49mtzc3N6JZ25uLsXExJCDgwM1bNhQqNTDcReP06dPk5mZGe3atUtYFhISQpMmTaK7d+9SXl4eFRQUENGbSj0RERHUqVMnatiwIRUVFRERUWlpaZm0nX26GzduUM2aNWn37t1ERFRYWEgREREkkUioY8eOlJaWRkREO3bsIA8PD1JTU6OmTZtS+/btOd4ilJ+fT25ubrRy5UoielN9afv27TRjxgw6d+4cpaenC9vm5eXRkSNHqFevXtSgQQPheM6Y2PETiDKQlZWFTp06YerUqRgwYIAwXMXDwwNPnjxBeHj4B58wSKVSKCkpCf9n37+8vDzMnj0bhYWFWLduHSQSCZSUlHDkyBF4e3sjISEBVapUEba/fPkyNmzYgMzMTERGRkJVVRUlJSVCXXH2/QsNDcWDBw/g7+8v3IF0cHDAzZs3UVpaCiMjI7i5uWHChAmoUKECHj58iN27d2PSpElQUVHheIvM6dOn4efnh9jYWGEO061bt+Du7o7Hjx/DwsICsbGxwvYPHjyAmpoaqlatColEwvEWmaysLNjZ2WHdunWoW7cuHBwcYGxsjKdPnyIjIwODBw/G+PHjYWFhASLCxIkTcePGDURFRUFVVVU45zMmZnwFWgZ0dXVx9uxZDBgwAEQkHEjat2+PK1eu4OnTpwDky7XK/ix7mRwnD+KhrKyMunXrwsnJCcrKykLsjIyM3rt906ZNMX36dOzbt4+TB5GR3Y/x8PDAkCFDhORh2LBhuHnzJgIDA3HhwgXY29sjJCREmFxdo0YNTJs2DSoqKigtLeV4i4Qs3lpaWsjKykJcXJyw7sqVK1BXV8f27dtx584doTwvEcHU1BRGRkZCoQyOt7ioqKjA3NwceXl5WLt2LZycnHDw4EHcvHkTP/30E6Kjo3H06FEAbybTr1q1CseOHROO55w8sPKAn0CUMXqr4hIANGvWDCYmJti/f39ZNot9YRkZGcKdSfrP+z0ePXqEjh074vTp0zA2NgbwZp6El5eXsB8/aRKPEydOQEVFBc2aNRMSB+DN2OeoqCi0bt0aNWrUAPDmDqZsUvXAgQPLqsnsC3n48CH8/PxQWFgIGxsbGBgYYP78+QgNDcXgwYPRq1cv1KtXD0uXLi3rprIvZMSIEYiOjkbt2rUxcuRIuLu7C+v8/f1x5MgRJCYmQllZWUgY+HjOyhP+l/yNREdHY/ny5fD29sbp06eFO48SiUS4CwUA7u7uuHv3LpKSkgDwy2bE6vLly9i7dy+2bNmCV69eoVKlSkKlFVmyWFRUhLy8PKipqQF4U2lryZIlck+e+GQjDoGBgXB1dUVycrJQZUXWd3V0dNC/f38heQCAtLQ02NraCtV4mLj8+eefOH78OKKiopCVlYUaNWpgwYIFsLGxwdmzZ3Hs2DHs27cPgwcPBgCoq6vzu1xE7N69e3j48CFSU1OFZUuXLoW1tTViYmLw+vVrue0bNGiAWrVqQVVVVe5pAx/PWblSFhMvFE1gYCBpa2vT0KFDqXPnzmRoaEhubm508eJFYRvZBNn09HSqUqUKTZ06tayay/6hwMBAMjc3p4YNG1KNGjXIzMyMMjMz5baRSqUUHx9PVatWpb/++otcXV3J2tpamFDJE6bFIzo6mvT19YUJ8jIlJSXv/XNBQQE5OztTjx49eOKsCG3bto2MjY2pYcOGZGNjQ1WrVqWDBw8K66VSqVx/z8zMpFatWtGaNWvKoLXsnwoKCiJra2tq1KgRaWtr09ixY+nSpUtE9Kb4iZ2dHVWvXp1+//13evz4MeXn51P37t3J3d29jFvO2NfFCcRXlpCQQFZWVnTgwAFh2dq1a0kikVCrVq3o9OnTwnLZRYa/vz85OzsTEV9Iis2+fftIT0+PIiMj6dmzZ3Tnzh1q06YNjRs3jqRSqVw879+/T7Vq1aI6depQ7dq1heSBq3SIy/z582nkyJFE9KYaz8SJE8nBwYHGjx9P0dHRwnbZ2dm0c+dOcnJyogYNGnD1HRE6ceIEGRgY0G+//UYvXryg9PR0cnR0JENDQ9qwYQNlZGQI2xYUFNAff/xBjo6OctXUmHgcOHCAKlasSLt376YbN27QkSNHSEVFhVq1akVHjhwhIqJr165R165dSU9PjywtLcnW1pYaNWrEN4NYucfP076y169fQ0NDA40aNUJhYSEAwMnJCY0aNYKmpibWrVsnvJ1U9qhz1KhRPAdChJ49e4bAwEBMmzYN/fr1g6GhISwtLdGkSRPhvQ9vv8uhpKQEd+/ehZaWFpKSknjCtMjQf4YonT9/HoaGhiguLkbXrl2RnZ2NGjVq4K+//oKnpyciIiKEfc6fPw8NDQ38+eefQrx5WIN4JCYmokePHujduzf09PRgZGSETp06IS8vDzNmzMDp06cBvHkRZG5uLnbt2oXs7GxcvnxZmCDPxOPIkSNwd3fHwIEDUbt2bfTs2RNeXl64efMm1q1bh3PnzqFBgwY4duwYgoKCMHfuXEyZMgVXrlwR+je/v4eVV3yl8hW8PVHqxYsXSEtLg5KSEtTV1QEAMTEx0NPTg4uLC+bPn49r167BxMRE2M/a2vqdz2HfPx0dHTRo0EB4qzDwZr5D69atERMTAyJCSUkJVFVVAQB6enpYs2YNfH19oayszMmDSNB/JsHLLgw6dOiAc+fOYd68eejUqRM2bNgAdXV1pKWlYfXq1diwYQPs7e1RrVo1rFixAmpqapBIJFxtSYTS0tJw8eJFABBip6ysjJkzZyI5ORl+fn7o2rUrtLW1UalSJSxatAh6enpQUlLi/i0iRITS0lLcvn0bDRs2BAChv+rp6cHR0REXL17Erl270KZNGwBAnz595D6D+zcr7/jq9Ct49uyZ8GdXV1c0b94c7dq1w9KlSzFz5kwMGzYMo0ePxrhx49CqVStERkYCwDt3Kjh5EIeCggIAgIaGBqZPnw4XFxe59bI7UbI/A0BqaioMDAwwbtw4KCsr88lGRLKzswH8t7RynTp1kJaWhkOHDqFy5crCjYKaNWuiS5cuSExMFCZZqqurQyKRyJVvZuLRu3dv6OrqYvz48UhKSsK2bdvg7+8POzs7rF27Fvr6+rhw4QKANxehFStWFN7bw/1bPCQSCVRUVODg4IDAwEBcunQJpaWl+PXXX7FixQosXLgQq1atQkhICFJSUt77Gdy/WXnHV6hf2Pr161G7dm1kZGQIj6t3794Ne3t7REZG4syZM/jtt98wcOBA4aJST08PwLsJBPv+7dmzB9OmTcO9e/cgkUigr68PQL56lizBkMW3bdu2GDVqlNzn8MlGHEJCQtC6dWtcunRJSPBdXFzg7OyMpKQk/PHHH3KVWurUqYPatWu/07e5r4vDnTt3cPXqVSQmJgJ4U2a7X79+OHv2LBwcHDBz5kzs2LEDPXr0ABHh6dOnePLkCQD5GPPNIHEICQnB9u3bhZ+HDx8OV1dXtGjRAs2bN4eHhwcCAwNRs2ZN1KpVCxUqVEBOTk4ZtpixssO3RL6gzZs3Y8qUKdi+fbtQ8x8ADA0NERoaiuzsbEgkEmhrawMACgsLkZ2dDXNzcwD/HRrBxOHp06eYMGECKlasCA0NDYwdOxampqYA5C8e3i7l161bN2RkZODq1atl0WT2D23fvh3Z2dkYO3Ys1q5dixYtWgAAFi1ahOLiYqxduxY//PADhg4dChMTE0ybNg1aWlpcrlWEQkNDsXjxYpSWliIlJQXr16+Hr68vJk+eDC8vL6Snp6NixYpCn3/16hWsra1hYWFRxi1nn2PLli0YPXo0Dh06JCwzNjZGcHAwPDw8UFJSAjMzM9SrVw/Am/mNxsbGcu98YUyR8IvkvpDAwED4+voiIiICLi4uyMjIQH5+PjIyMlCzZk0haQDeJA4pKSnw9/fH06dPceXKFX68LULZ2dno2LEjjIyMkJ6ejg4dOsDPz++dC4ioqCjMmDEDBgYGePDgAW7evMkTpkXK0dER+vr6kEgkSE5Oxrp169C6dWth/erVq3H48GGcOnUKdnZ20NDQwOnTp6GqqspzmkQkNDQUY8aMwebNm9G4cWMcOHAAa9euxe3bt4UnxjL5+fl49eoVvL29kZGRgdjYWH6iKDKbN2/GuHHjsGPHDgwYMOC928hu8JWUlCAvLw/9+/cHESE6Opr7NVNIfPXyBdy9exfTp09Hu3bt4OLigjt37sDT0xMvXrzA7du34ejoiEGDBgkvFbp79y62bdsGiUQiV52DTzriQUTQ0dGBra0tRo8ejYsXL2Lz5s3Q1NTEiBEjEB4ejpkzZwJ4c2cyMTERzZs35+RB5Lp27QqJRIJ27dphzpw5mDhxItasWYMdO3ZgxowZmDhxIry8vPDgwQNoamqiZs2aPIFWZC5cuIClS5di8+bNGDJkCAAgMzMTf/75pzCUqV69esJwxStXrmDixIlQVlYWkgc+novH0aNHMWbMGERERMDNzQ03b95EaGgokpOTYWJiAjc3N7Rp00YodHHo0CFs3boVjx8/xpUrV4Q5LpxEMEXD/+K/AH19fcyZMwdJSUnw8PBAnz590KxZM6xbtw4nT56EiooKAgICEBsbCwCwsbGBn58foqOjhYtJPtmIi2yIkqamJqKiouDr6wtPT08cOXIEzZs3R1BQkLBt+/btMWXKFMTGxnLyIHLq6uo4cuQIbG1tMXfuXFSvXh2dO3fG8ePHhaEsOjo6qF+/PiwtLXkCrQhpaWmhb9++6Nq1q7BsyZIlOH36NMaOHYsuXbrA19cXDx8+BPBmTtO8efNw7tw5Pp6LjKzSUq1atXD58mUkJiaiT58+iI+Ph6amJn7//XdMnz4dO3fuBBFBRUUF1tbW6NKlC5diZqwM3j1RLr169YrWrVtHhoaG5OnpSYWFhcK6W7dukbGxMS1fvvyd/fglUuIki+/q1aupX79+wnIjIyPS09MjX19fevToERHJx5hfJiVOsnjHx8eTvb29sNzCwoKqVKlCjRo1osuXLxMRvziqPHj7hXDz5s0jCwsL+vPPP6m4uJguXbpEampqFBoa+s5+b79xnH2/3u6jWVlZtHHjRqpfvz6pqKjQ1KlTKScnR1jn6OhIbdq0eW9sOd5MkfFtsc8ku4sse3Spp6eHwYMHo1q1ajAzM4OamhqAN0NdrKysYGpqiqdPn77zOXznQhzi4+Px5MkTEBEcHByE+LZr1w7nz59HUVERmjZtirp166Jdu3aIiorCvHnz8OOPP8LIyEj4HL4TLQ5nzpxBcnIynj59ismTJ0NHRwfAm9KsUqkUiYmJGDJkCGrUqIGJEyciLCwMLi4uOHbsmNx7QJg45Obmori4WBiWVLFiRaFMb6dOnTBmzBhUrVoVANC0aVPY2Njg3r1773wOP3kQh4KCAmhqaqKgoAA6OjoYPHgwSkpKkJKSAl9fX1SoUAFSqRQ6OjqYN28eWrRogWvXrqFx48ZyBTI43kyR8dXMZzh06BCuXLkiVOCRJRGVKlVCz549oampKWwrkUjw8uVLlJaWok6dOmXYava5goKC8OOPP0JJSQnKysro0KEDNm7cCGVlZWGSrKmpKaytrXHgwAHo6OhAKpXir7/+QpUqVcq6+ewTBQYGYvbs2bCyskJaWhrCw8ORkJAgvN8hOzsbTZs2Rdu2bbF3717o6+tDU1MTtWvXFl4CycQjLCwMW7ZswaNHj1C/fn24urrC3d1deGeLvb293PaPHz+GhoYGH89F6tdff8XevXtx//59tG3bFmPGjEHNmjWFuUuyqoiym3tPnjyBra0tTExMuEoiY2/hKkyfaP/+/ejbty8sLCzg6ekJPz8/6Ovrv3cSVUlJCTIzM+Hp6YmMjAzExMTwHQuR+e233+Dh4YGQkBA0bdoUkZGRwvs8ZImil5cXsrKyEBAQIJcw0H+qdvAEO/H4/fffMWDAAISFhcHe3h4pKSkYOHAgjh07BjMzMwBvKrZERUVh8+bNck+XZHgCrXj8+uuvGDJkCObMmQNjY2Ps2rULmZmZaNCgAQICAqCuri48bSYiFBYWol+/fsjKysLp06c5ziITFBSECRMmYNq0aXjw4AHi4+Ph4+Pzznt5ZAoKCjBgwACoqalhz549nEAw9hZOID5BWloahg0bhrZt2yI3Nxfnzp1D7969MW7cOOjr68u9x6G0tBQbN27E/v378fr1a5w/fx6qqqp8cSESRITi4mKMGTMG1apVw08//QQASElJgZ+fH3x8fFBUVARXV1eoqKggJycHFStWBAC5hIH43R6ismzZMly5cgUREREA3gxt6dixI1xcXPDgwQOMGDECzZo1Q1FRkdwwRY6xuBARSktLMWbMGOjp6WHFihUA3pRk3bRpE3bu3AkbGxts27YNampqKCgowO7du7Fz5068fPkS//rXv/h4LjKHDx/GiBEjsHHjRvTp0wcA4Orqivbt22PcuHEoKioSbgplZ2fj6NGjCAkJwYMHD4QJ03wziLH/4p7wCQwMDNC9e3e4urpizZo16NChAw4cOIB169bh1atXkEgkwhuIlZWV0bx5c/Ts2RMXLlzg6hwiI5FIoKamhqdPnyI+Pl5Y7u/vj2vXrmHhwoX48ccfYWNjg8LCQiF5AOTntfCFpbg8ffoUMTExQj/28PDAo0ePcP36ddy8eRP29vY4e/Ys1NTUhG04xuIjkUigoqKCZ8+e4fbt28JyTU1NjBkzBsOHD8ft27exatUqIdnQ0tKCtbU1Ll26xMdzkSkoKMDNmzfh5+cHR0dHYXlGRgb27t2Lxo0bo0+fPrhw4QIAoKioCPv374e6ujpXW2LsA/gJxCcgIuTl5cm9eXLy5Mk4e/YsnJ2dMX78eOjr6yMjIwPa2trCHUqAhzWIiSxWUqkUAQEB2LZtG5SVlaGlpYUHDx7gxIkTqFKlCl6/fo1evXqhU6dOWL16dVk3m30BSUlJcHV1xbNnz4SJshcuXICJiQmUlJTg5OSEFy9e4Ny5c3wxIWJSqRQSiQQ///wzjh49isDAQLn5Kzk5OZg4cSJu3Ljx3qGnfDwXn7t370JNTQ01atQA8OalkMnJyViyZAkyMzNx6tQpJCcnIzo6GsbGxsjOzkaFChX4PS6MfQD3iL9x79494WRhbm4uPOKUHVBWrlyJyZMn4+DBg1BSUkL//v0xYsQINGzYEBs2bBCGN/DJRhyOHTuGZ8+ewdnZGXp6ehg6dChMTU3x6tUr/PbbbxgxYgRq164NANDQ0ICxsbFQrYWJz61bt5CTkwMtLS3UrVsXdevWxfnz53Hjxg0cO3YMpaWlMDU1RUFBATQ0NNCgQQMkJiZy8iBSsuO2LH5DhgzBmjVrMH/+fGzatEl4y7S2tjamT58Oa2trXLhwAW3atJH7HD6ei0NoaChSU1Mxf/58WFpaCstzc3NRqVIlnDhxAhYWFgCAypUrY/To0cjMzISxsbFQeY3f48LY+/FZ8P8IDQ1Fr1690L17dzRo0ACnT58WTjyyt0cDwMqVK9GxY0fs27cPrVq1QmZmpnBHmoc3iEdgYCD69u2LvLw85OXlAQB0dXXh7OyMoUOHoqCgAGlpaXL7FBYWcqUlkQoJCYGjoyMGDhyIevXqYfv27VBSUoKBgQHatWuHzMxMXLt2DcCbZFEqleLKlSvCHUwmLnv37sXo0aPRtWtXLF26FAkJCTA3N8dvv/2GQ4cOYdy4cfjrr7+E7YuKimBjYyM3PJGJR3BwMIYPH461a9fi6tWrwnKpVIoKFSogNDQUFhYWwnm8UqVKsLS0hK6urtzn8M0Cxt6PhzB9wO7duzFq1CgEBASgWrVqCAsLQ0pKCk6fPi1U5JBIJMLTiWfPnsHa2hp16tRBTEwMVFRU+LGniJw+fRr9+/fH2rVrMWjQICF2OTk50NbWRklJCSZNmoQbN26gT58+qFu3LlasWIHHjx/j0qVLHGeRiYyMhI+PDzZt2oSGDRti165d2LVrF27cuAENDQ0AwL59+zB//nw0aNAA9vb22Lt3L54/f47Lly/LHQPY9y8sLAze3t4YP348bt++jYyMDNy6dQthYWHo0qULTp8+jd69e6NFixbo0qULGjVqhFWrVuHVq1eIi4vji0iR2bx5M8aOHYs5c+YgIiICY8eOxZgxYz5Y4EJWXUtdXR2RkZHcrxn7GN/qjXVikpWVRV27dqUlS5YIy0JCQsjb25tu375NycnJcttnZmZSgwYNqE6dOsKbhvmNw+KyYsUKcnNzIyKi5ORk8vDwoPbt25O9vT1FR0cTEdG9e/fI0dGRTExMqH79+tSrVy8qKioiIn4jqZgUFhZS3759adasWcKy33//nQYMGEAXLlygCxcuUGFhIeXm5tLq1avJ1taW2rRpQx4eHkK/5niLR25uLnXu3Jl+/vlnYdn169fJy8uLVFRUhP5969YtGjBgANWtW5dsbW2pR48eQv9++23y7Pu2fv16UlNTo99++42IiPz8/MjExIRevnz5zrb5+fkUHx9P3bt3p0aNGgn9m+PN2N/jBOI9nj9/TmZmZhQYGCgs69GjBxkZGZG1tTVpaGjQ/Pnz5Q4yCxYsoMLCQiLi5EFMZDEcPXo0+fv7U0lJCVWvXp38/Pxo5syZ5OnpSRKJhEJCQojoTbKYkpJCd+7cIalUSkQcb7HJzs6mevXq0YIFC4RlTk5OZGBgQA0bNiR1dXXy9PSknJwcKikpoby8PHr16pWwLcdbXDIzM8nc3JwCAgLklj979ox8fHxIW1ubLly4QERvLihfv35N6enp3L9F6PLly6StrU2RkZHCspiYGKpVqxaFhYURkXxycOLECRo6dCg5OjoKySLHm7GPw0OYPsDT0xMRERGYMWMGTpw4gcePH2PPnj0wMTHBqVOnMHjwYJw4cQKdOnWS24+HLYnT6tWrsW7dOnh7eyMxMRE7duwQHnXPnz8fq1atwpUrV1CrVi25/bguuDjNmjULS5cuhbe3N5KSkvDkyRPs378fdevWRVxcHLp27Yrg4GAMGjRIbj/iYUui5O7ujlevXiEsLExuTkNqaiomTJgAfX19bNmyRSiSIcP9W1zu37+P/Px81KlTR66vduzYEUpKSjh58uQ7+1y9ehUNGzbkakuMfSI+Mr7l7Wo6c+fOxfjx4wG8eanMqlWrYGdnhypVqmDgwIGwsrKSm5glwwcfcQgNDcXChQuFn7t06QJra2sEBwcLFw2yyXVubm7Q19fHs2fP3vkcvrgQD1k8AWDevHlYuXIl6tevDyLCnDlz0KBBAygrK8Pe3h6NGjXC9evX3/kMTh7EqUOHDkhPT0dYWBhycnKE5RYWFmjbti1iYmJQWFj4zn7cv8VBVvTCzMwMderUAQBhjiIALFiwADdu3EBkZKSwj+zeaePGjaGkpMTVlhj7RHx0BHDnzh0AEO5AAEDNmjWxZMkSjB07FpmZmdDW1ha2f/HiBTQ0NFCtWrUyaS/7Z2TVOVavXi0kgfXq1UOHDh3w/PlznD17Fvfu3RNKNerp6aFSpUpculGkEhMTAbwpvSnr3+rq6pg4cSJ8fHyQnZ0NfX19AG8uOrKyslBSUgIzM7OyajL7B86fP48tW7Zg48aNiI2NBQD4+PjAzs4OAQEBCAsLQ0ZGhrB906ZNYWBggIKCgrJqMvsH9uzZg8mTJyM1NfWddbJjdq1atVCjRg2cOnUKwPufJHKyyNgnKsPhU9+FnTt3koaGBi1cuFBY9r8TJPv160eurq509epVunnzJvXu3ZtatmzJEylFaNOmTaSiokILFiwgGxubd8ZFL1myhExNTalevXoUFRVFx48fp169epG9vT1PrBOhnTt3kkQioTFjxgjL/rffenl5Ub169ejcuXN0/vx5cnFxoWbNmvFYaBEKDAwkIyMjsre3J0tLS7KzsxMm0xIRDRs2jBo1akSjRo2iK1euUFJSEnXt2pW6du0qzHlg4lBaWkpPnjyhqlWrkkQioVGjRtHDhw/l1r8tNDSUVFVV6fLly9+6qYyVSwqdQJw8eZLMzc2pXbt2VL9+ffrxxx+FdW8ffIKCgqhDhw4kkUjI1taW2rZty9V3ROhjq3Ps2bOHXF1dSV1dnezs7MjBwYGrsYhQTEwMWVlZkbOzM1WvXp18fX2FdW/321OnTpGTkxNJJBJq1KiRXLy5f4vHwYMHycDAgMLDw6m0tJQSExOpb9++NGXKFLnkYPHixdS5c2ch3i1atOD+LWITJ06kuXPnkoaGBg0ZMoTS0tLk1sv68OPHj8nMzIxWrFhRBq1krPxR2ASiqKiIpkyZQsOGDaOLFy/S3LlzqU6dOvTTTz/JbSOTmppKhw4dotjYWOEkw3coxeNjqnO8HW8iopSUFHr+/DlXYxGh4uJiWr58OY0YMYISEhIoKCiIqlSpIpdEvB3v3NxciomJocTERO7fIpSZmUkeHh40depUueVLly4la2trKigokEsOCgoK6F//+hfdvHmT4y1SUqmUSktLydXVlSIjI+ny5cukpqZGPj4+dO/ePfL19aX09HS5fbZs2cI3BRj7QhR2xpCqqir8/f2RlJSE5s2bw8TEBFKpFGFhYQCA2bNnQ1VVVajKULNmTdSsWVPYnydciYuhoSEuXbokV52jbdu2MDExQVBQENzd3aGqqipXdcXS0lLYn+MtLioqKhg6dChu376Nhg0bCm+cnTVrFgBgw4YNQv9WVlaGlpYW2rZtK+zP8RYXJSUl2NjYwNbWFsB/x7jXr19fGOv+9hh3dXV1NGvWTPiZ4y0+EokEEokEPXr0QGJiIvr164eLFy+iRYsW2LNnDxo0aCDMXZSdx318fABAeAEsY+zzKfSsoerVq6NLly7Cn0ePHg03NzeEhYXh559/BgBkZWVh69atchWaAJ5wJTampqawtrYG8P+rc3worhxvcSEiVKlSRUgKtLW1MWDAACxevBiRkZHw8/MDAOTk5GD58uVIT0+X25/jLS66urrw8PBAt27d5JYbGRlBTU0NxcXFwjLZRNq3cbzFS1tbG0ePHgXwpqKSqakpcnJyYGxsjOzsbADvVkfk5IGxf06hbrkkJSUhIyMDr1+/Rq9evQDIv7fB2NgYI0eOhEQiwc6dO5Gbm4vY2FikpqZixIgRZdl09hlk8X716hWcnJyExEFZWfm91Tnc3Ny4zr+IFRYWQl1d/YO1+3V0dODm5gaJRIJZs2YhPz8fqampSE1NxZQpU8qgxeyfkPXvzMxMODs7w9jYWIi9rA9nZ2fj9evXUFdXBwD06NED6enpiI+P535eTlhbWwsV02xtbWFhYYFVq1ahf//+yMvLw7Zt21ClSpUybiVj5VDZjqD6doKCgsja2posLS2pcuXK1LVr1w9u+/jxY5o8eTJJJBJq1qyZMFaaq3SIx6fEm6tziF9QUBDZ2NjQ48ePiej/T4bNycmh1atXk0Qi4Qm0IvWx/fvYsWNkYWFBubm55OTkRNbW1nw8L2devXpFjRo1IhUVFWrTpo0w7+HkyZPUvn177teMfSUKkUDs2bOHtLW1KSIigpKTkyk2NpbMzc0/WI0hJyeHbG1tqUmTJsLEOp5gJx6fGm+uziFuR48epcqVK5Ouri5ZW1v/bRLx+vVratKkCTVu3Jj7twh9Sv+Oj4+nBg0aUNOmTcnS0lJIHjje5Ud+fj5NnDiRvL296cmTJ0T0bvU0TiIY+/LK/RCmBw8eICAgAD///DP69+8P4M1QBzs7O9y+ffud7aVSKRYtWoTS0lJcvHgRKioq/Hp7EfnUeANAtWrVMHv2bHh5eX3LprIv4OXLlzhw4AD69++P4cOHY9KkSWjbti1iY2NRrVq1d4YzERG2b98ODQ0NnD59mvu3yHxq/87JyUFiYiJsbW2RnJwsVxiDlQ8aGhqYNWsWtLS0UKFCBQD/neNA/xmSynNcGPvyyn2vqlChgtzr7YE3FTiaN2+OtLQ0AJCbYKekpIQJEybgzz//5JONCH1qvGWTqX18fKCsrCz8zMTBwMAA9vb2GDRoEJo1a4bt27ejWrVqaNu2LdLT06GkpAQiEraXSCRwd3fHH3/8wf1bhD61fxsbG2PevHm4ePEix1tk3u63f8fQ0FBIHt7G81wY+3ok9Cm9VKSePHkCIyMjAP+9I7F8+XIcO3YMJ06cELZ7/fo19PT0hJ8/NBmTfd8+Nt5ZWVnQ1dUtq2ayf4jeM+GdiJCamophw4YhPT0d586dg5GREZ4/fy6UbNbS0gLA/VusPrZ/Z2dnQ0dHR/iZkwfxeLtvZ2RkoFKlSmXcIsbY/1KIs+fbJxtZvlRaWip3h6N169aYOnWq3H58cSFOHxtvrrwjbu9LHiQSCSwtLRESEiI8ibh27RqcnJywZs0aaGpqCttz/xanj+3f/v7+cvtx8iAOUqlU6NsBAQGYPn06bt269bf7KcC9UMa+Kwp1Bn17LKSsrB8AdOvWDRkZGVi/fn1ZNY19BRxvxfJ2QlGrVi3s2LEDVapUQePGjZGTk4M9e/bwkIZy5O/6d0BAQFk1jX2mt58KXr9+HXFxcYiMjERAQABSU1M/uN/bTyw2btyI0aNHf5P2MqbIFCqBeJusXryTkxPu3r2L69evQ01NDSUlJWXdNPYVcLwVj5aWFnJzc9GyZUtcvXpVGAPPyh/u3+WDLHmYNGkS+vXrB11dXbRt2xbr1q3DypUrkZKS8s4+bycPmzdvxsyZM+Hg4PBN282YIlLYZ7pZWVk4e/YsmjdvztU5FADHW7EUFhZi0aJFyM3NxeXLl7naUjnH/bv8OHnyJLZv346jR4+iWbNmAICQkBD4+/uDiDB58mRYWloCgPBiUOBN8jB9+nQEBgaib9++ZdZ+xhRFuTi6vm8y5d/p1q0bkpKSEBwczBcXIsPxViyfE291dXU4Ozvjl19+gbKyMsdbRLh/KzapVAodHR0YGBgI/xaGDx+O4uJijBo1ChoaGhgzZgxq164tJA9btmzBtGnTEBQUxMkDY9+I6KswfW61huLiYqiqqgIAioqKoKam9tXayL4cjrdi+Zx4/+8FKF9Migf3b8XyvkpoJ06cQO/evXHmzBk0a9YMBQUF0NDQQGZmJurXrw8iwvDhwzFnzhxoampi69at8PX1RUREBPr06VNGvwljikfUcyA+t1qDVCoVTjYA+GQjEhxvxfK58f5fnDyIA/dvxfJ28rB27VosXLgQAODg4AAnJyc4Ozvj4cOH0NDQAPBmWKKLiwv8/f2xbNkyXLp0CQCQnp6OPXv2cPLA2Dcm2gTin1RrkO3H1RrEg+OtWLgai2Lh/q14ZHGbOnUqli9fDolEgvv37wMAFi5ciAYNGqBRo0bYtm0bduzYgWHDhuHmzZuYOnUqatWqhaNHjwIApkyZAldX1zL7PRhTWCRy/v7+ZGVlRWPGjCFHR0eSSCTk6+tLd+7ceWdbqVQq/HnTpk2kp6dHkZGR37K57B/ieCsWjrdi4XgrlsjISKpatSpdvHjxnXWPHj2icePGUc2aNalu3brk4OBAhYWFRERkZ2dHmzZt+tbNZYy9RdQJxIkTJ6hSpUr0r3/9S1gWHBxM+vr6NGbMGEpJSRGWl5SUCH+WnWz27t37TdvL/hmOt2LheCsWjrfi+fnnn6l3795ERFRaWkpERMXFxXLbPHz4kLKysoSfZ8+eTaampnT37t1v1k7G2LtEPTiYqzUoFo63YuF4KxaOt+LJzMzEvXv3hEnwRAQVFRUUFhbi2LFjcHZ2homJCQDg2rVr2LRpE/bu3Ytjx47BwsKijFvPmGITzRwIqVT6zjKJRILnz5/j5cuXkEgkKCgoAAD069cP1apVQ3h4OIKDg5Gfnw8A2Lp1K/z8/BAcHMwnm+8cx1uxcLwVC8dbsbwv3gBQt25dZGZm4siRI8jPzxfmLxUUFGDZsmUIDw8XtjUwMECnTp0QFxcHW1vbb9JuxtiHiSKB4GoNioXjrVg43oqF461Y6K2J7gcOHMD+/fvx+++/AwC8vLxgbW2NKVOmYOfOnbh16xaSkpIwaNAglJSUwM3NTfgcY2Nj9O3bF7Vq1SqT34Mx9j/KcvzUp5oyZQqZmJjQwoUL6d69e0REdOvWLerSpQtVrFiRtm7dSqGhodS1a1fq1KkTERFZW1vTzJkziYgoNze3zNrOPh3HW7FwvBULx1uxTJ8+nXR0dMjKyop0dXWFOBIRDRw4kBo2bEhKSkrUuHFjat26NRUVFRGR/HwXxtj3QzQJBFdrUCwcb8XC8VYsHO/yT1YlSyqV0uPHj6lDhw509epVSklJoaCgIFJTU6Px48cL29+5c4eOHz9Oly5d+uCEasbY90M0k6hv376Nli1bonnz5sIjcNkbZqtXr461a9di2rRp0NPTg46ODgDghx9+wIsXL9ClS5cybj37VBxvxcLxViwc7/Lt7WFqGRkZePr0KSwtLVGrVi1UqFABpqamUFNTw4gRI6CkpIRVq1ahVq1acsOTpFIpvwSSse+YaHonV2tQLBxvxcLxViwc7/KJ/lM9S5Y8zJ49G4cPHwYRobi4GJmZmahQoQJUVVXRv39/AMDIkSORk5ODrVu3yn2W7DMYY9+n766HcrUGxcLxViwcb8XC8VYssjgCQHBwMMLCwjBs2DC4uLjgwYMHWLhwoVBFS5ZErF69GikpKSCismo2Y+wzSOg76rWyuxfAm2oNUqkU2trawiPrrl27IjU1FTNmzEC7du1QUlKCqVOnIiMjA+fOnRNqg//vZ7HvE8dbsXC8FQvHW3G0aNECEydOxKBBgwAAJ06cwIULF2BmZgYPDw8AQHR0NPr27Ythw4bhl19+gaamJgCgtLRUiDXHmTER+daTLj4GV2tQLBxvxcLxViwc7/LNy8uLbG1thYnPz58/J4lEQhKJhJYuXSq3bVRUFGlpaZGfnx9X0WJM5L6LORD0n7sORIQnT57g4sWLiImJgba2Nv744w+MHj0aubm5WLNmDXbv3o2UlBSkpaWhYsWKsLOzk5uAx75/HG/FwvFWLBxvxVFaWoonT56gc+fOUFJSQkBAABwdHREfH4/27dvj5MmTcHNzQ82aNQEAPXr0wK+//oqePXvC3NwcU6ZMKePfgDH2ucr8CM3VGhQLx1uxcLwVC8dbsRQXF6NevXq4dOkSevbsiYsXL6JHjx5o1KgRjh8/Dnt7e8yZMweLFy9GjRo1AADdu3dHXFwcmjZtWsatZ4z9E2V2lCau1qBQON6KheOtWDjeiklDQwOzZs1C8+bN8eDBA8yZM0d42tC8eXOcOXMGHTp0gEQiwaJFi4QkomXLlgDAT5oYE7EyO1JztQbFwvFWLBxvxcLxViyy6lqlpaW4ceMG0tPT0bZtW5w6dQo7duwQtmvZsiXOnDmD/fv3Y/To0Xj27Jnc53DywJiIfdspF0TNmzenXbt2CT///vvv9OOPP1JoaKiwLCoqijQ1NWn06NGUl5cnLH97Up3sLZfs+8bxViwcb8XC8VY8ssnSRET37t2j/Px8ysrKoufPn5OrqyvZ29vTjh075PY5e/YsdejQQW5fxpi4fdMEgqs1KBaOt2LheCsWjrdimzlzJllbW1PlypVp0qRJlJKSQo8ePaI+ffqQvb09hYWFvXc/TiIYKx++2RCm91VryM3NRXx8PHR1dXHy5EmkpaUJ28uqNQQEBCAgIOBbNZN9IRxvxcLxViwcb8Xz9ksBIyMjERoaiiVLlmD8+PGIjY3F5MmT8fr1a6xbtw6GhoYIDAx8Z34LwHNcGCs3vlWmkp+fT1OnTqUOHTpQjx49qFKlSpSamkpERBcvXiR1dXVyd3enBw8eyO13/vx5Ki4u/lbNZF8Ix1uxcLwVC8dbcZ09e5bGjx9PgYGBwrJDhw5Rhw4dyNnZmW7cuEGPHz+mDh06kJ+fXxm2lDH2NX3TIUyZmZlUu3ZtUldXp59++klu3fnz50ldXZ2GDBnyzkmHiPikI0Icb8XC8VYsHG/Fk56eTpaWlqSrq0urVq2SWydLIlxcXCghIYFevHjBw5UYK8e++rNErtagWDjeioXjrVg43orNyMgI+/btg5GREaKionD9+nVhXa9evTB16lTcuXMHO3fuhIGBAZSUlOSGPjHGyo+vmkC8/VKhv/76C3Z2dnj8+DHCw8Ohp6eHbdu2ISwsTNi+ZcuWiIqKQl5eHipXrvw1m8a+Ao63YuF4KxaONwOAhg0bYs+ePXjx4gXWrVuHpKQkYV3Pnj2xZcsWLFq0SFjGcx4YK58kRF+/CPesWbOwb98+vHz5EkOHDoWvry80NTUxbtw4vHjxAiNHjoS7u/s7+719wmLiwfFWLBxvxcLxZgAQHx8Pb29vNGnSBBMnToSNjY3c+tLSUigrK5dR6xhjX9tXSSDePlFERkbC398f69evx/Xr13H48GFUq1YNixcvhp6eHsaPH4+MjAwMGjQIPj4+X7op7BvgeCsWjrdi4XizD4mPj8eoUaNgZmaGZcuWCW+hZoyVf1/ldpDsZPPHH38gNjYWCxcuhIuLC+bMmYM5c+bg9evXmDFjhlDyjYiQkJDwNZrCvgGOt2LheCsWjjf7EFtbW6xfvx46OjowMzMr6+Ywxr6hrzaE6cmTJ2jbti2eP3+OBQsWYOLEicK6w4cPY+XKldDX18eCBQtgbGyMihUr8uNtEeN4KxaOt2LheLP/h4ggkUh4mBpjCuSr9XSu1qBYON6KheOtWDje7P+RSCQgIk4eGFMgX30SdUJCAjw9PdG0aVNMmDAB9erVE9bFxcWhRYsWPNGqHOF4KxaOt2LheDPGGAO+URUmrtagWDjeioXjrVg43owxxr5JAgFwtQZFw/FWLBxvxcLxZowxxfbNBixytQbFwvFWLBxvxcLxZowxxfbNnkDIcLUGxcLxViwcb8XC8WaMMcX0zRMI4L8nHaYYON6KheOtWDjejDGmeMokgWCMMcYYY4yJEz9zZowxxhhjjH00TiAYY4wxxhhjH40TCMYYY4wxxthH4wSCMcYYY4wx9tE4gWCMMcYYY4x9NE4gGGPsC/Dw8MCiRYvKuhmi0bJlS/z6669l3QzGGGOfgRMIxli5MXz4cLi4uMgt27t3LzQ0NLBy5cqv9r0JCQmIiorC+PHjhWUdOnSARCKBRCKBhoYGbGxsEBAQ8EW+LyQkBPr6+p+83fz589G4ceMv0oZ/6ocffsCMGTMglUrLuimMMcY+EScQjLFya9u2bXB3d8fGjRsxefLkr/Y969atg5ubG7S1teWW+/j4ID09HTdu3ED//v3h5+eH3bt3f7V2iEmPHj2QnZ2N6Ojosm4KY4yxT8QJBGOsXFq2bBnGjRuH8PBweHp6CssPHDgAOzs7aGhowMLCAgsWLEBJSQkAwMvLC7169ZL7nOLiYlSpUgWBgYHv/Z7S0lLs3bsXTk5O76zT0tKCkZERLCwsMH/+fNSuXRsHDx4EAEyfPh1WVlbQ0tKChYUF5syZg+LiYmHfhIQEdOzYETo6OtDV1UWTJk1w+fJlnDlzBp6ennj9+rXwhGP+/Pl/+/cREhKCBQsWICEhQdgvJCQEAPDq1St4e3vD0NAQurq66NSpExISEoR9ZU8ugoKCYGpqCm1tbfj6+qK0tBTLli2DkZERqlSpgp9//lnYh4gwf/58mJqaQl1dHdWrV5d7QqOsrIyePXsiPDz8b9vOGGPs+6JS1g1gjLEvbfr06QgICMDhw4fRuXNnYXlMTAyGDh2KtWvXol27drh79y5GjhwJAJg3bx68vb1hb2+P9PR0VKtWDQBw+PBh5OXlYcCAAe/9rmvXruH169do2rTp37ZLU1MTRUVFAAAdHR2EhISgevXquH79Onx8fKCjo4Np06YBANzd3WFra4uNGzdCWVkZV69ehaqqKlq3bo3Vq1dj7ty5uHXrFgC88+TjfQYMGIDExEQcPXoUJ06cAADo6ekBANzc3KCpqYno6Gjo6elh8+bN6Ny5M27fvo1KlSoBAO7evYvo6GgcPXoUd+/eRb9+/ZCamgorKyucPXsWcXFx8PLygoODA1q0aIFff/0Vq1atQnh4OOrVq4cnT57IJSUA0Lx5cyxZsuRv284YY+w7Q4wxVk4MGzaM1NTUCACdPHnynfWdO3emRYsWyS3bsWMHVatWTfjZxsaGli5dKvzs5OREw4cP/+B37t+/n5SVlUkqlcotb9++PU2YMIGIiEpKSmjHjh0EgNavX//ez1m+fDk1adJE+FlHR4dCQkLeu21wcDDp6el9sE0f2m7evHnUqFEjuW1iYmJIV1eXCgoK5JZbWlrS5s2bhf20tLQoKytLWN+tWzcyNzen0tJSYZm1tTUtXryYiIhWrlxJVlZWVFRU9MH2HThwgJSUlOQ+gzHG2PePhzAxxsqVhg0bwtzcHPPmzUNOTo7cuoSEBCxcuBDa2trCf7J5Cnl5eQAAb29vBAcHAwCePn2K6OhoeHl5ffD78vPzoa6uDolE8s66gIAAaGtrQ1NTEz4+PvD398eYMWMAABEREWjTpg2MjIygra2NH374AQ8ePBD2nTRpEry9veHg4IAlS5bg7t27//jv5n0SEhKQk5MDAwMDub+XtLQ0ue80NzeHjo6O8HPVqlVhY2MDJSUluWXPnj0D8OapRn5+PiwsLODj44P9+/cLQ8VkNDU1IZVKUVhY+FV+N8YYY18HJxCMsXLF2NgYZ86cwaNHj9C9e3dkZ2cL63JycrBgwQJcvXpV+O/69eu4c+cONDQ0AABDhw5Famoqzp8/j7CwMNSsWRPt2rX74PdVrlwZeXl5wtCkt7m7u+Pq1atIS0tDbm4ufvnlFygpKeH8+fNwd3dHz549cfjwYcTHx2P27NlynzF//nwkJSXB0dERp06dgo2NDfbv3/8F/6b++3dSrVo1ub+Tq1ev4tatW5g6daqwnaqqqtx+EonkvctkVZVq1KiBW7duISAgAJqamvD19YW9vb3cPI+MjAxUqFABmpqaX/z3Yowx9vXwHAjGWLljZmaGs2fPomPHjujevTuOHj0KHR0d2NnZ4datW6hVq9YH9zUwMICLiwuCg4Nx/vx5uQnY7yMri3rjxo13SqTq6em997vi4uJgZmaG2bNnC8vu37//znZWVlawsrKCv78/Bg0ahODgYLi6ukJNTQ2lpaX/t13v87797Ozs8OTJE6ioqMDc3PyTP/P/0dTUhJOTE5ycnODn54c6derg+vXrsLOzAwAkJibC1tb2i34nY4yxr4+fQDDGyqUaNWrgzJkzePbsGbp164asrCzMnTsXoaGhWLBgAZKSkpCcnIzw8HD88MMPcvt6e3tj+/btSE5OxrBhw/7v9xgaGsLOzg6xsbEf3bbatWvjwYMHCA8Px927d7F27Vq5pwv5+fkYO3Yszpw5g/v37+PcuXO4dOkS6tatC+DNcKKcnBycPHkSL168EIZf/R1zc3OkpaXh6tWrePHiBQoLC+Hg4IBWrVrBxcUFx48fx7179xAXF4fZs2fj8uXLH/07/a+QkBAEBgYiMTERqampCAsLg6amJszMzIRtYmJi0LVr18/+DsYYY2WDEwjGWLllYmKCM2fO4MWLF+jWrRtatWqFw4cP4/jx42jWrBlatmyJVatWyV3UAoCDgwOqVauGbt26oXr16n/7Pd7e3ti5c+dHt8vZ2Rn+/v4YO3YsGjdujLi4OMyZM0dYr6ysjJcvX2Lo0KGwsrJC//790aNHDyxYsAAA0Lp1a4wePRoDBgyAoaEhli1b9lHf27dvX3Tv3h0dO3aEoaEhdu/eDYlEgqioKNjb28PT0xNWVlYYOHAg7t+/j6pVq3707/S/9PX1sXXrVrRp0wYNGzbEiRMncOjQIRgYGAAAHj16hLi4uL99wsMYY+z7IyEiKutGMMbY9yQnJwfGxsYIDg5Gnz59/nb7/Px8WFtbIyIiAq1atfoGLRS/6dOnIzMzE1u2bCnrpjDGGPtEPAeCMcb+QyqV4sWLF1i5ciX09fXh7Oz8UftpamoiNDQUL168+MotLD+qVKmCSZMmlXUzGGOMfQZ+AsEYY/9x79491KxZEyYmJggJCZF7CR1jjDHG3uAEgjHGGGOMMfbReBI1Y4wxxhhj7KNxAsEYY4wxxhj7aJxAMMYYY4wxxj4aJxCMMcYYY4yxj8YJBGOMMcYYY+yjcQLBGGOMMcYY+2icQDDGGGOMMcY+GicQjDHGGGOMsY/2bxe4zRGNulGxAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Define the Custom Layer (Captures Weights)\n",
    "class VisualizableTransformerLayer(nn.TransformerEncoderLayer):\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n",
    "        # Standard self-attention but force need_weights=True\n",
    "        src2, attn_weights = self.self_attn(\n",
    "            src, src, src,\n",
    "            attn_mask=src_mask,\n",
    "            key_padding_mask=src_key_padding_mask,\n",
    "            need_weights=True,\n",
    "            is_causal=is_causal\n",
    "        )\n",
    "        # SAVE WEIGHTS for visualization\n",
    "        self.attn_weights = attn_weights.detach().cpu()\n",
    "\n",
    "        # Rest of the standard transformer block\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src\n",
    "\n",
    "# 2. Define the Model Class (Matches your TRAINED model architecture)\n",
    "class SASRecViz(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int = 128, max_len: int = 50,\n",
    "                 num_layers: int = 2, num_heads: int = 2, hidden_dim: int = 256,\n",
    "                 dropout: float = 0.1, pretrained_emb: Optional[np.ndarray] = None):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_len = max_len\n",
    "        self.item_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.pos_embedding = nn.Embedding(max_len, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # USE CUSTOM LAYER HERE\n",
    "        encoder_layer = VisualizableTransformerLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim,\n",
    "            dropout=dropout, batch_first=True, activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # MATCHING THE TRAINED MODEL (Single LayerNorm)\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, seq_len = seq.shape\n",
    "        positions = torch.arange(seq_len, device=seq.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        item_emb = self.item_embedding(seq)\n",
    "        pos_emb = self.pos_embedding(positions)\n",
    "        x = self.dropout(item_emb + pos_emb)\n",
    "        causal_mask = nn.Transformer.generate_square_subsequent_mask(seq_len, device=seq.device)\n",
    "        padding_mask = (seq == 0)\n",
    "        x = self.transformer(x, mask=causal_mask, src_key_padding_mask=padding_mask)\n",
    "        x = self.ln(x)\n",
    "        x_last = x[:, -1, :]\n",
    "        logits = self.fc(x_last)\n",
    "        return logits\n",
    "\n",
    "# 3. Transfer Weights\n",
    "print(\"Creating visualization model...\")\n",
    "viz_model = SASRecViz(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=EMBEDDING_DIM,\n",
    "    max_len=MAX_SEQ_LENGTH,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "print(\"Transferring trained weights...\")\n",
    "viz_model.load_state_dict(model.state_dict(), strict=True)\n",
    "print(\"Success! Weights transferred.\")\n",
    "\n",
    "# 4. Visualization Function (ROBUST SHAPE HANDLING)\n",
    "def visualize_attention(model, sample_seq, idx_to_item, layer_idx=0, head_idx=0):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare input\n",
    "    seq_tensor = torch.tensor([sample_seq], dtype=torch.long).to(device)\n",
    "\n",
    "    # Forward pass (populates attn_weights)\n",
    "    with torch.no_grad():\n",
    "        _ = model(seq_tensor)\n",
    "\n",
    "    # Get attention weights directly\n",
    "    try:\n",
    "        attn_weights = model.transformer.layers[layer_idx].attn_weights\n",
    "        # Expected shape: [batch_size, seq_len, seq_len] (averaged heads)\n",
    "        # OR [batch_size, num_heads, seq_len, seq_len] (if average_attn_weights=False)\n",
    "\n",
    "        attn = attn_weights[0] # Get first batch -> [seq_len, seq_len] OR [num_heads, seq_len, seq_len]\n",
    "\n",
    "        # Handle different shapes\n",
    "        if attn.dim() == 3:\n",
    "            # Has head dimension: [num_heads, seq_len, seq_len]\n",
    "            attn = attn[head_idx]\n",
    "        elif attn.dim() == 2:\n",
    "            # Already averaged over heads: [seq_len, seq_len]\n",
    "            if head_idx > 0:\n",
    "                print(\"Note: Attention weights are averaged across heads by PyTorch.\")\n",
    "            pass # attn is already [seq_len, seq_len]\n",
    "\n",
    "        attn = attn.numpy()\n",
    "\n",
    "    except AttributeError:\n",
    "        print(\"Error: Model not compatible.\")\n",
    "        return\n",
    "\n",
    "    # Filter for actual items\n",
    "    actual_items = [idx for idx in sample_seq if idx != 0]\n",
    "    seq_len = len(sample_seq)\n",
    "    start_idx = seq_len - len(actual_items)\n",
    "\n",
    "    # Slice the attention matrix\n",
    "    attn = attn[start_idx:, start_idx:]\n",
    "\n",
    "    # Get item names\n",
    "    item_labels = [idx_to_item.get(idx, f\"[{idx}]\")[:15] for idx in actual_items]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(attn, xticklabels=item_labels, yticklabels=item_labels, cmap='Blues')\n",
    "    plt.title(f'Attention Heatmap (Layer {layer_idx})')\n",
    "    plt.xlabel('Key (Past Items)')\n",
    "    plt.ylabel('Query (Current Position)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "# 5. Run Visualization\n",
    "sample_batch = next(iter(test_loader))\n",
    "target_seq = None\n",
    "for seq in sample_batch[0]:\n",
    "    seq_list = seq.tolist()\n",
    "    if len([x for x in seq_list if x != 0]) >= 5:\n",
    "        target_seq = seq_list\n",
    "        break\n",
    "\n",
    "if target_seq:\n",
    "    print(\"Visualizing...\")\n",
    "    visualize_attention(viz_model, target_seq, idx_to_item)\n",
    "else:\n",
    "    print(\"No suitable sequence found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3aa3cf",
   "metadata": {
    "id": "0b3aa3cf"
   },
   "source": [
    "---\n",
    "## 7. Interactive Production Demo\n",
    "\n",
    "This section launches a **Gradio Dashboard** to interact with the trained model.\n",
    "Features:\n",
    "1. **User DNA**: Visualizes user preferences using a Radar Chart.\n",
    "2. **Time Machine**: Allows you to inject items into history to see how predictions change.\n",
    "3. **Explainability**: Shows \"Why\" the model made a prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dqQkskf9v6cB",
   "metadata": {
    "executionInfo": {
     "elapsed": 8399,
     "status": "ok",
     "timestamp": 1766480397679,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "dqQkskf9v6cB"
   },
   "outputs": [],
   "source": [
    "# Install dependencies for the dashboard\n",
    "!pip install -q gradio plotly pandas torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bdf64f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "executionInfo": {
     "elapsed": 161534,
     "status": "ok",
     "timestamp": 1766481815289,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "8bdf64f2",
    "outputId": "912578ba-e525-40d7-9983-fcd80909df54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models\\sequential_recommender\\best_model.pt...\n",
      "  Detected vocab size: 456187\n",
      "✅ Model loaded.\n",
      "Building metadata maps...\n",
      "Mapped 201,430 item names to indices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_21336\\657310372.py:357: UserWarning:\n",
      "\n",
      "The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme. Please pass these parameters to launch() instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching demo...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://9f9e804c82e32c536a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9f9e804c82e32c536a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\Documents\\GitHub\\customer-transaction\\.conda\\lib\\site-packages\\torch\\nn\\functional.py:6044: UserWarning:\n",
      "\n",
      "Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ CRITICAL: Model output contains NaNs! This causes 0.0% confidence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\Documents\\GitHub\\customer-transaction\\.conda\\lib\\site-packages\\torch\\nn\\functional.py:6044: UserWarning:\n",
      "\n",
      "Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ CRITICAL: Model output contains NaNs! This causes 0.0% confidence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\Documents\\GitHub\\customer-transaction\\.conda\\lib\\site-packages\\torch\\nn\\functional.py:6044: UserWarning:\n",
      "\n",
      "Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ CRITICAL: Model output contains NaNs! This causes 0.0% confidence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\Documents\\GitHub\\customer-transaction\\.conda\\lib\\site-packages\\torch\\nn\\functional.py:6044: UserWarning:\n",
      "\n",
      "Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ CRITICAL: Model output contains NaNs! This causes 0.0% confidence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\Documents\\GitHub\\customer-transaction\\.conda\\lib\\site-packages\\torch\\nn\\functional.py:6044: UserWarning:\n",
      "\n",
      "Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ CRITICAL: Model output contains NaNs! This causes 0.0% confidence.\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://9f9e804c82e32c536a.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "from typing import Optional\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "if 'CLEANED_DATA_DIR' not in globals(): CLEANED_DATA_DIR = 'cleaned_data'\n",
    "if 'MAX_SEQ_LENGTH' not in globals(): MAX_SEQ_LENGTH = 50\n",
    "if 'EMBEDDING_DIM' not in globals(): EMBEDDING_DIM = 128\n",
    "if 'NUM_LAYERS' not in globals(): NUM_LAYERS = 2\n",
    "if 'NUM_HEADS' not in globals(): NUM_HEADS = 2\n",
    "if 'HIDDEN_DIM' not in globals(): HIDDEN_DIM = 256\n",
    "if 'DROPOUT' not in globals(): DROPOUT = 0.2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 1. MODEL DEFINITION ---\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int = 128, max_len: int = 50,\n",
    "                 num_layers: int = 2, num_heads: int = 2, hidden_dim: int = 256,\n",
    "                 dropout: float = 0.1, pretrained_emb: Optional[np.ndarray] = None):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_len = max_len\n",
    "        self.item_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.pos_embedding = nn.Embedding(max_len, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim,\n",
    "            dropout=dropout, batch_first=True, activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, seq_len = seq.shape\n",
    "        positions = torch.arange(seq_len, device=seq.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        item_emb = self.item_embedding(seq)\n",
    "        pos_emb = self.pos_embedding(positions)\n",
    "        x = self.dropout(item_emb + pos_emb)\n",
    "        causal_mask = nn.Transformer.generate_square_subsequent_mask(seq_len, device=seq.device)\n",
    "        \n",
    "        # FIX: Ensure padding_mask is BoolTensor to avoid warning\n",
    "        padding_mask = (seq == 0).bool()\n",
    "        \n",
    "        x = self.transformer(x, mask=causal_mask, src_key_padding_mask=padding_mask)\n",
    "        x = self.ln(x)\n",
    "        x_last = x[:, -1, :]\n",
    "        logits = self.fc(x_last)\n",
    "        return logits\n",
    "\n",
    "# --- 2. MODEL LOADING & DIAGNOSTICS ---\n",
    "demo_model = None\n",
    "\n",
    "# Try in-memory first\n",
    "if 'viz_model' in globals():\n",
    "    print(\"Using in-memory 'viz_model'\")\n",
    "    demo_model = viz_model\n",
    "elif 'model' in globals():\n",
    "    print(\"Using in-memory 'model'\")\n",
    "    demo_model = model\n",
    "\n",
    "if demo_model is None:\n",
    "    model_path = os.path.join('models', 'sequential_recommender', 'best_model.pt')\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading model from {model_path}...\")\n",
    "        try:\n",
    "            state_dict = torch.load(model_path, map_location=device)\n",
    "            \n",
    "            # DIAGNOSTIC: Check for NaNs in weights\n",
    "            has_nan = False\n",
    "            for k, v in state_dict.items():\n",
    "                if torch.isnan(v).any():\n",
    "                    print(f\"❌ CRITICAL: Found NaNs in checkpoint weight: {k}\")\n",
    "                    has_nan = True\n",
    "            if has_nan:\n",
    "                print(\"⚠️ The saved model is corrupted (contains NaNs). Retraining is required.\")\n",
    "            \n",
    "            # Determine Vocab Size\n",
    "            if 'fc.weight' in state_dict:\n",
    "                chk_vocab_size = state_dict['fc.weight'].shape[0]\n",
    "                print(f\"  Detected vocab size: {chk_vocab_size}\")\n",
    "            else:\n",
    "                print(\"  Warning: 'fc.weight' missing. Guessing vocab size...\")\n",
    "                vocab_path = os.path.join('models', 'item_embeddings', 'item_vocabulary.parquet')\n",
    "                vocab_df = pd.read_parquet(vocab_path)\n",
    "                chk_vocab_size = len(vocab_df) + 1\n",
    "            \n",
    "            loaded_model = SASRec(\n",
    "                vocab_size=chk_vocab_size,\n",
    "                embed_dim=EMBEDDING_DIM,\n",
    "                max_len=MAX_SEQ_LENGTH,\n",
    "                num_layers=NUM_LAYERS,\n",
    "                num_heads=NUM_HEADS,\n",
    "                hidden_dim=HIDDEN_DIM,\n",
    "                dropout=DROPOUT\n",
    "            ).to(device)\n",
    "            \n",
    "            loaded_model.load_state_dict(state_dict, strict=False)\n",
    "            loaded_model.eval()\n",
    "            demo_model = loaded_model\n",
    "            print(\"✅ Model loaded.\")\n",
    "            \n",
    "            # DIAGNOSTIC: Check loaded weights\n",
    "            if torch.isnan(demo_model.fc.weight).any():\n",
    "                print(\"❌ Loaded model has NaNs in FC layer!\")\n",
    "            if demo_model.fc.weight.sum().item() == 0:\n",
    "                print(\"❌ Loaded model FC layer is all ZEROS!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "    else:\n",
    "        print(f\"Model file not found at {model_path}\")\n",
    "\n",
    "# --- 3. DATA LOADING ---\n",
    "if 'test_seqs' not in globals() or 'idx_to_item' not in globals():\n",
    "    print(\"Loading data...\")\n",
    "    try:\n",
    "        vocab_path = os.path.join('models', 'item_embeddings', 'item_vocabulary.parquet')\n",
    "        vocab_df = pd.read_parquet(vocab_path)\n",
    "        item_to_idx = {item: idx + 1 for item, idx in zip(vocab_df['item_id'], vocab_df['index'])}\n",
    "        idx_to_item = {idx: item for item, idx in item_to_idx.items()}\n",
    "        del vocab_df\n",
    "        gc.collect()\n",
    "        \n",
    "        # Load Events\n",
    "        retail_path = os.path.join(CLEANED_DATA_DIR, \"retail_events_clean.parquet\")\n",
    "        marketplace_path = os.path.join(CLEANED_DATA_DIR, \"marketplace_events_clean.parquet\")\n",
    "        \n",
    "        dfs = []\n",
    "        if os.path.exists(retail_path): dfs.append(pd.read_parquet(retail_path, columns=['user_id', 'item_id', 'timestamp']))\n",
    "        if os.path.exists(marketplace_path): dfs.append(pd.read_parquet(marketplace_path, columns=['user_id', 'item_id', 'timestamp']))\n",
    "        \n",
    "        if dfs:\n",
    "            events = pd.concat(dfs, ignore_index=True)\n",
    "            events['item_idx'] = events['item_id'].map(item_to_idx).fillna(0).astype(np.int32)\n",
    "            events = events[events['item_idx'] != 0]\n",
    "            events = events.sort_values(['user_id', 'timestamp'])\n",
    "            \n",
    "            counts = events['user_id'].value_counts()\n",
    "            valid_users = counts[counts >= 5].index \n",
    "            events = events[events['user_id'].isin(valid_users)]\n",
    "            \n",
    "            user_sequences = events.groupby('user_id')['item_idx'].apply(list).to_dict()\n",
    "            \n",
    "            if len(user_sequences) > 1000:\n",
    "                import random\n",
    "                sampled_keys = random.sample(list(user_sequences.keys()), 1000)\n",
    "                test_seqs = {k: user_sequences[k] for k in sampled_keys}\n",
    "            else:\n",
    "                test_seqs = user_sequences\n",
    "            \n",
    "            del events, dfs\n",
    "            gc.collect()\n",
    "        else:\n",
    "            test_seqs = {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        test_seqs = {}\n",
    "        idx_to_item = {}\n",
    "\n",
    "# --- 4. METADATA & ROBUST LOOKUP MAP ---\n",
    "def build_maps():\n",
    "    print(\"Building metadata maps...\")\n",
    "    meta_map = {}\n",
    "    name_to_idx_map = {} # Direct Name -> Int Index\n",
    "    \n",
    "    def load_items(filename):\n",
    "        path = os.path.join(CLEANED_DATA_DIR, filename)\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                df = pd.read_parquet(path)\n",
    "                for _, row in df.iterrows():\n",
    "                    iid_str = str(row['item_id'])\n",
    "                    name = f\"{row['category']} - {row['subcategory']}\"\n",
    "                    meta_map[iid_str] = {\n",
    "                        'category': row['category'],\n",
    "                        'subcategory': row['subcategory'],\n",
    "                        'name': name\n",
    "                    }\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "    \n",
    "    load_items('retail_items_clean.parquet')\n",
    "    load_items('marketplace_items_clean.parquet')\n",
    "    \n",
    "    # Build Name -> Index Map\n",
    "    # Iterate through ALL known indices to find their names\n",
    "    count = 0\n",
    "    for idx, item_id in idx_to_item.items():\n",
    "        iid_str = str(item_id)\n",
    "        if iid_str in meta_map:\n",
    "            name = meta_map[iid_str]['name']\n",
    "            name_to_idx_map[name] = idx\n",
    "            count += 1\n",
    "            \n",
    "    print(f\"Mapped {count:,} item names to indices.\")\n",
    "    return meta_map, name_to_idx_map\n",
    "\n",
    "if 'item_meta_map' not in globals() or len(item_meta_map) == 0:\n",
    "    item_meta_map, name_to_idx_map = build_maps()\n",
    "elif 'name_to_idx_map' not in globals():\n",
    "    # Rebuild just the index map if needed\n",
    "    _, name_to_idx_map = build_maps()\n",
    "\n",
    "# --- 5. VISUALIZATION COMPONENTS ---\n",
    "def get_item_info(item_idx):\n",
    "    item_id = idx_to_item.get(item_idx, \"Unknown\")\n",
    "    if item_id == \"Unknown\": return {\"name\": \"Unknown Item\", \"category\": \"Unknown\", \"subcategory\": \"\"}\n",
    "    if item_id == 0: return {\"name\": \"Padding\", \"category\": \"System\", \"subcategory\": \"\"}\n",
    "    meta = item_meta_map.get(str(item_id))\n",
    "    if meta: return meta\n",
    "    return {\"name\": f\"Item {item_id}\", \"category\": \"Unknown\", \"subcategory\": \"\"}\n",
    "\n",
    "def render_card_html(item_idx, rank=None, prob=None, is_ground_truth=False, is_injected=False):\n",
    "    info = get_item_info(item_idx)\n",
    "    name = info['name']\n",
    "    category = info['category']\n",
    "    subcategory = info['subcategory']\n",
    "    item_id = idx_to_item.get(item_idx, \"\")\n",
    "    \n",
    "    is_retail = \"fmcg\" in str(item_id)\n",
    "    color = \"#e3f2fd\" if is_retail else \"#fff3e0\"\n",
    "    if is_injected: color = \"#e8f5e9\"\n",
    "    icon = \"🛍️\" if is_retail else \"🤝\"\n",
    "    if is_injected: icon = \"💉\"\n",
    "    border = \"2px solid #2196f3\" if is_ground_truth else \"1px solid #ddd\"\n",
    "    if is_injected: border = \"2px dashed #4caf50\"\n",
    "    \n",
    "    badge = \"\"\n",
    "    if is_ground_truth: badge = \"<div style='background: #2196f3; color: white; font-size: 0.7em; padding: 2px 4px; border-radius: 4px; margin-top: 4px;'>ACTUAL NEXT</div>\"\n",
    "    if is_injected: badge = \"<div style='background: #4caf50; color: white; font-size: 0.7em; padding: 2px 4px; border-radius: 4px; margin-top: 4px;'>INJECTED</div>\"\n",
    "    \n",
    "    prob_html = \"\"\n",
    "    if prob is not None:\n",
    "        if prob < 0.001: prob_str = \"<0.1%\"\n",
    "        else: prob_str = f\"{prob:.1%}\"\n",
    "        prob_html = f\"<div style='font-size: 0.8em; color: #666;'>Conf: {prob_str}</div>\"\n",
    "    rank_html = f\"<div style='font-weight: bold; color: #333;'>#{rank}</div>\" if rank is not None else \"\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "    <div style=\"background-color: {color}; border: {border}; border-radius: 8px; padding: 10px; margin: 5px; width: 150px; display: inline-block; vertical-align: top; box-shadow: 0 2px 4px rgba(0,0,0,0.1); font-family: sans-serif;\">\n",
    "        <div style=\"display: flex; justify-content: space-between; align_items: center; margin-bottom: 5px;\">\n",
    "            <span style=\"font-size: 1.2em;\">{icon}</span>\n",
    "            {rank_html}\n",
    "        </div>\n",
    "        <div style=\"font-weight: bold; font-size: 0.85em; color: #2c3e50; margin-bottom: 2px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;\" title=\"{category}\">{category}</div>\n",
    "        <div style=\"font-size: 0.75em; color: #7f8c8d; margin-bottom: 5px; height: 2.4em; overflow: hidden; display: -webkit-box; -webkit-line-clamp: 2; -webkit-box-orient: vertical;\" title=\"{subcategory}\">{subcategory}</div>\n",
    "        {prob_html}\n",
    "        {badge}\n",
    "        <div style=\"font-size: 0.65em; color: #bdc3c7; margin-top: 5px;\">{item_id}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "def plot_persona_radar(history_items):\n",
    "    categories = []\n",
    "    for idx in history_items:\n",
    "        if idx == 0: continue\n",
    "        info = get_item_info(idx)\n",
    "        if info['category'] != \"Unknown\": categories.append(info['category'])\n",
    "    if not categories: return None\n",
    "    df_counts = pd.DataFrame(categories, columns=['Category'])['Category'].value_counts().reset_index()\n",
    "    df_counts.columns = ['Category', 'Count']\n",
    "    df_counts = df_counts.head(6)\n",
    "    df_counts['CategoryShort'] = df_counts['Category'].apply(lambda x: x[:15] + '...' if len(x) > 15 else x)\n",
    "    fig = px.line_polar(df_counts, r='Count', theta='CategoryShort', line_close=True, title=\"User Persona DNA\", template=\"plotly_dark\")\n",
    "    fig.update_traces(fill='toself')\n",
    "    fig.update_layout(polar=dict(radialaxis=dict(visible=True, showticklabels=True)))\n",
    "    return fig\n",
    "\n",
    "# --- 6. PREDICTION LOGIC ---\n",
    "def predict_user_journey(user_id_str, injected_item_name, temperature):\n",
    "    if demo_model is None: return \"Model not loaded\", \"\", \"\", None\n",
    "    try: user_id = int(user_id_str)\n",
    "    except: return \"Invalid User ID\", \"\", \"\", None\n",
    "    if user_id not in test_seqs: return \"User not found\", \"\", \"\", None\n",
    "        \n",
    "    original_seq = test_seqs[user_id]\n",
    "    current_seq = list(original_seq)\n",
    "    ground_truth_idx = current_seq[-1]\n",
    "    input_seq = current_seq[:-1]\n",
    "    \n",
    "    injected_idx = None\n",
    "    if injected_item_name and injected_item_name != \"None\":\n",
    "        # ROBUST LOOKUP\n",
    "        injected_idx = name_to_idx_map.get(injected_item_name)\n",
    "        if injected_idx: \n",
    "            input_seq.append(injected_idx)\n",
    "        else:\n",
    "            print(f\"Warning: Could not find index for injected item: {injected_item_name}\")\n",
    "            \n",
    "    seq_window = input_seq[-MAX_SEQ_LENGTH:]\n",
    "    pad_len = MAX_SEQ_LENGTH - len(seq_window)\n",
    "    padded_input = [0] * pad_len + seq_window\n",
    "    seq_tensor = torch.tensor([padded_input], dtype=torch.long).to(device)\n",
    "    \n",
    "    demo_model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = demo_model(seq_tensor)\n",
    "        \n",
    "        # DIAGNOSTIC: Check for NaNs\n",
    "        if torch.isnan(logits).any():\n",
    "            print(\"❌ CRITICAL: Model output contains NaNs! This causes 0.0% confidence.\")\n",
    "            # Fallback: Replace NaNs with large negative number to ignore\n",
    "            logits = torch.nan_to_num(logits, -1e9)\n",
    "        else:\n",
    "            # Debug Stats\n",
    "            if temperature == 0.5:\n",
    "                print(f\"Logits Stats: Mean={logits.mean().item():.4f}, Std={logits.std().item():.4f}\")\n",
    "\n",
    "        if temperature <= 0: temperature = 0.01 \n",
    "        logits = logits / temperature\n",
    "        \n",
    "        probs = F.softmax(logits[0], dim=0)\n",
    "        top_probs, top_indices = torch.topk(probs, k=5)\n",
    "        \n",
    "    history_html = \"<div style='white-space: nowrap; overflow-x: auto; padding-bottom: 10px;'>\"\n",
    "    display_seq = input_seq[-10:]\n",
    "    for i, idx in enumerate(display_seq):\n",
    "        is_inj = False\n",
    "        if injected_idx and idx == injected_idx and i == len(display_seq) - 1:\n",
    "            is_inj = True\n",
    "        history_html += render_card_html(idx, is_injected=is_inj)\n",
    "    history_html += \"</div>\"\n",
    "    \n",
    "    predictions_html = \"<div style='white-space: nowrap; overflow-x: auto; padding-bottom: 10px;'>\"\n",
    "    for i, (idx, prob) in enumerate(zip(top_indices, top_probs)):\n",
    "        is_gt = (idx.item() == ground_truth_idx)\n",
    "        predictions_html += render_card_html(idx.item(), rank=i+1, prob=prob.item(), is_ground_truth=is_gt)\n",
    "    predictions_html += \"</div>\"\n",
    "    \n",
    "    hist_cats = [get_item_info(i)['category'] for i in input_seq[-10:] if i != 0]\n",
    "    pred_cats = [get_item_info(i.item())['category'] for i in top_indices]\n",
    "    from collections import Counter\n",
    "    top_hist = Counter(hist_cats).most_common(1)[0][0] if hist_cats else \"Unknown\"\n",
    "    top_pred = Counter(pred_cats).most_common(1)[0][0] if pred_cats else \"Unknown\"\n",
    "    \n",
    "    explanation = f\"User history dominated by **{top_hist}**.\"\n",
    "    if top_hist == top_pred: explanation += f\" Model predicts more **{top_pred}**, reinforcing preference.\"\n",
    "    else: explanation += f\" Model predicts **{top_pred}**, suggesting a shift.\"\n",
    "    if injected_item_name and injected_item_name != \"None\": explanation += f\" (Influenced by injection: {injected_item_name})\"\n",
    "\n",
    "    return history_html, predictions_html, explanation, plot_persona_radar(input_seq)\n",
    "\n",
    "# --- 7. LAUNCH INTERFACE ---\n",
    "popular_names = list(name_to_idx_map.keys())[:100] # Use keys from the valid map\n",
    "popular_names.sort()\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# 🛍️ SASRec Interactive Dashboard (Debug Mode)\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            user_ids = list(test_seqs.keys())[:20] if test_seqs else []\n",
    "            default_user = str(user_ids[0]) if user_ids else \"\"\n",
    "            user_dropdown = gr.Dropdown(choices=[str(u) for u in user_ids], label=\"Select User\", value=default_user)\n",
    "            injection_dropdown = gr.Dropdown(choices=[\"None\"] + popular_names, label=\"Time Machine: Add Item\", value=\"None\")\n",
    "            temp_slider = gr.Slider(minimum=0.1, maximum=2.0, value=0.5, step=0.1, label=\"Model Confidence (Temperature)\")\n",
    "            radar_output = gr.Plot(label=\"User Persona\")\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"### 📜 History (Last 10 Items)\")\n",
    "            history_output = gr.HTML()\n",
    "            gr.Markdown(\"### 🔮 Predictions\")\n",
    "            prediction_output = gr.HTML()\n",
    "            explanation_output = gr.Textbox(label=\"Insight\")\n",
    "            \n",
    "    inputs = [user_dropdown, injection_dropdown, temp_slider]\n",
    "    outputs = [history_output, prediction_output, explanation_output, radar_output]\n",
    "    \n",
    "    user_dropdown.change(fn=predict_user_journey, inputs=inputs, outputs=outputs)\n",
    "    injection_dropdown.change(fn=predict_user_journey, inputs=inputs, outputs=outputs)\n",
    "    temp_slider.change(fn=predict_user_journey, inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    if user_ids: demo.load(fn=predict_user_journey, inputs=inputs, outputs=outputs)\n",
    "\n",
    "print(\"Launching demo...\")\n",
    "demo.launch(debug=True, share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0dbefc",
   "metadata": {
    "id": "6e0dbefc"
   },
   "source": [
    "---\n",
    "## 8. Summary & Conclusion\n",
    "\n",
    "### What We Built\n",
    "A **production-ready Sequential Recommender System** using the SASRec architecture:\n",
    "- Trained on 9.2M events from 286K users\n",
    "- Leverages pre-trained item embeddings (456K items)\n",
    "- Optimized for Google Colab Free Tier constraints\n",
    "\n",
    "### Key Results\n",
    "The model should show significant lift over random baseline:\n",
    "- **HR@10**: Typically 5-15% (vs. random ~0.002%)\n",
    "- **Catalog Coverage**: Diverse recommendations across catalog\n",
    "- **Cross-Domain**: Links Retail and Marketplace behaviors\n",
    "\n",
    "### Artifacts Saved\n",
    "- `models/sequential_recommender/best_model.pt` - Trained model weights\n",
    "- `models/sequential_recommender/training_history.png` - Loss curves\n",
    "- `models/sequential_recommender/attention_heatmap.png` - Attention visualization\n",
    "\n",
    "### Next Steps\n",
    "1. **A/B Testing**: Deploy to production and measure lift in click-through rate\n",
    "2. **Online Learning**: Update model with real-time user feedback\n",
    "3. **Multi-Task Learning**: Jointly predict purchase probability\n",
    "4. **Scale Up**: Train on full dataset with larger GPU (A100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc1953d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1766481581038,
     "user": {
      "displayName": "Seishin JuIchi",
      "userId": "11341335325583765023"
     },
     "user_tz": -480
    },
    "id": "cc1953d1",
    "outputId": "11cb3431-0137-4444-b7e1-69cf889efb8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SEQUENTIAL RECOMMENDER TRAINING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Artifacts saved to: models/sequential_recommender\n",
      "- best_model.pt: Trained model weights (117,511,675 parameters)\n",
      "- training_history.png: Loss curves\n",
      "- attention_heatmap.png: Attention visualization\n",
      "\n",
      "Final Performance:\n",
      "- HR@10: 5.00%\n",
      "- NDCG@10: 0.0266\n",
      "- Catalog Coverage: 2.7%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SEQUENTIAL RECOMMENDER TRAINING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Artifacts saved to: {OUTPUT_DIR}\n",
    "- best_model.pt: Trained model weights ({total_params:,} parameters)\n",
    "- training_history.png: Loss curves\n",
    "- attention_heatmap.png: Attention visualization\n",
    "\n",
    "Final Performance:\n",
    "- HR@10: {test_metrics['HR@10']*100:.2f}%\n",
    "- NDCG@10: {test_metrics['NDCG@10']:.4f}\n",
    "- Catalog Coverage: {coverage:.1f}%\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1ZIHlpSAdRs8MpKSdENHlHDiJW9RqiHkx",
     "timestamp": 1766482352158
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
